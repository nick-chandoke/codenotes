* instead of retaining relations of ordered structures, index them; when they reflect a desired order, add an index to each element, then perform whatever operations you want, then sort by the indices. if you must retain nesting (i.e. relations of relations) in the result R, then hopefully there's a way to express that easily enough by a multidimensional index, or index that's a sequence. as a last resort, you can store a uid for each element, and a separate structure S that stores the relations of uids, then use S to restructure R.
  ** in fact, a really nice coding style would be to express all data as graphs, and have a function `shape` that uses a graph of uids to shape any _set_ of vertices into a like structure. i imagine that a common idiom would be `dup [ ... ] with-shape`
  ** the separation of data from shape is one of the excellences of array languages. it allows us to elegantly subset, and to relate subsets.
  ** in sql, shape is given by relations (joins) of data; any data may be considered basically as an index simply by being in the join predicate. for efficiency, attributes may be ``INDEX``ed, but this does not affect semantics. sql's model of "sets of totally-ordered primivite data which may be shaped by that order" is most beautiful. recognize that this description entails JOINs, which are always done by comparison, i.e. by total ordering, including equivalence. to impart arbitrary order to data, simply impart an attribute whose values are arbitrary ordinals.
    *** one of sql's very few shortcomings is that it has no function to treat a set as a seq by incrementing or decrementing indices greater or less than an insertion index when, respectively, inserting or removing a subsequence.
  ** both sql and array langs support the description, "if my computation only concerns the elements and not their shape, then i shouldn't have to specify their shape!" `[ [ ... ] map ] map` _is_ pretty dumb!

.reactive programming is just declarative programming & incremental design

i started off with the idea of making a function on a sequence into one that works incrementally i.e. that, when new data arrives, updates only as many data as it must. this is to make it support an "increment" operation such that only the minimum subset of state/data is computed upon. the "incremental update" scenario has 3 parts: the trigger event, the updated part, and the non-updated part. more generally, it's just a system of triggers. much like incrementing a number and overflow causing increment of the next-highest digit, any system is one part affecting others upon a certain event. this is just reactive programming, or, as i like to call it, "programming", since it's the same damn thing! to say "A triggers B" is to say "upon event A (either io or evaluation of an arbitrarily-delimited computation), `... [ B ] when`". reactive programming is just declarative programming, which is just to describe all computations as a set of edges, thereby implying a graph, rather than specifying the graph as a DAG with loops i.e. as a program i.e. a SEQUENCE of instructions where some of the instructions are loops (thus making cycles) or combinators (thus being a DAG)!

`map` relates a computation to each individual element of a set. `fold` generalizes `map` & `filter`: it still relates a computation to each individual element, but then it relates its output to prior outputs. `filter` is implied if the accumulator remains unchanged after the current element is considered. therefore `map` & `filter` are merely convenience words for `fold`. if we assume reductive programming, then this is fine. however, if we consider programs by a set of fundamental primitives, then fold is certainly one, and thus map & filter become obviated, as they are in prolog: filter is implied by a predicate failing or succeeding (namely returning a[n empty] set), and map is implicit because sets are implicit; a computation over a non-set is implicitly mapped over a set if given a set. k is an apl that handles null sets well, which makes it handle the empty set like prolog or sql.

if we consider "incremental" to mean "add into a structure", then if that operation is distinction/boundary-preserving, then we may define a "decrement" operation that removes subsets given by those boundaries.

* the university of calgary made an at least prototype language called "charity" in which ALL computation is expressed as metamorphisms. such a system would obviously enable first-class incremental design, but then again, so would simply streaming data & mutating state in a loop.
* the link:https://mercurylang.org/about.html[mercury] language is like prolog with haskell's type system

the case that drove me to consider incremental design is stockbot backtesting: i have historical data which is natural to store as a sequence, where each element thereof contains a timestamp. i ultimately want to produce a subsequence [(timestamp, flag value)]. a fold or stateful loop is necessary for this; or i can use loopless array ops a la apl to generate masks and relate items, or do something similar a la sql. anyway, these methods, at least as they're implemented or expressed in common code idioms, are not compatible with a "live" version which is a loop that awaits data from an input stream (namely a websocket, here) then tests whether it emits a flag value which corresponds to an io action to perform. the trouble is that words like `group-by`, `accumulate`, `map`, &c all take in a sequence and output a sequence. granted, in factor, replacing some of these words is easy; just use `each` with an effect that pushes onto a vector/list and/or performs an action with; however necessary for live action, this is unconventional and less elegant to express for historical computations. and for some words, like `group-by`, the translation into code that, rather than `( in-seq -- out-seq )` has effect `( cur-state in-item -- )`, is not trivial.

.the kicker

words like `group-by` are effectively defined as `[ ... ] accumulate` rather than being given as the quotation for us to use with `accumulate` or some other combinator, such as `each` i.e. `group-by`:

. acts on the whole input sequence at once i.e. does not allow us to stop the fold early, returning the current state
. does not give us access to its accumulator/state
