= k
nic chandoke's notes
:toc:

k3 & k6 much differ. this document details k6 & ngn/k yet. a section comparing k3 & k6 will be added. it's been implied that k3 & k4 are practically interchangeable, as are k5 & k6.

.terminology & notation

* i'm using prolog arity notation: an operator followed by a slash followed by arity e.g. `./3` is the `.` verb as it acts when given 3 args.
* somewhat borrowing from forth/factor, i use the word "word" to refer to k tokens without regard to whether they're verbs, adverbs, nouns, gerunds, or whatever have you.

== about k

* k is a very good example of the genius that comes from refining a language over time without regard to backwards compatibility
* canonically, tiny language implementation, built for speed & brevity, and rebuilt from scratch often
* especially overloaded; even an operator with a given arity may have many entirely different definitions depending on its arguments' types.
* nomenclature is same as j

=== k vs j

k is categorically better than j:

* vectors instead of arrays
  ** no boxing
  ** no rank system; simply use adverbs to iterate
  ** 1st-class functions can be in vectors plainly. no particular system like gerunds. you can stright-up do `(*{4+x},3 4)@64`
* dicts (i'm unsure if these are inferior to vectors of arbitrary-type/shape elements. at least dict-fn-vec equivalence is good.)
* tables (ngn/k)
* namespacing is dead simple. just `\d NS` to change the namespace to `NS`, and prefix its vars with `NS.`; or `\d .` to set the global namespace
* fewer, overloaded verbs is better than more verbs many of which have a colon, which is harder to read
* `#/2` combines j's `$/2` and j's `#/2`
* verbs can actually be defined with more than 2 args
* more-sensible verbs both by notation and functionality e.g:
  ** `f\` instead of `f^:a:`, which is a more consistent mnemonic and syntactically plainer
  ** `#` instead of `{` & `}`
* there's no function composition in k...not sure if that's better or worse. j's fncomp was good but flawed; i'm unsure whether such things should be boldy discarded, or retained despite that they only offer convenience rather than a robust programming code.
* k is easily learned in a weekend
* because j verbs aren't 1st-class, j has a special tacit dsl. b/c k verbs are 1st-class, there's no need for a dsl; we can just define combinators such as `fork2:{[f;g;h;x;y] g[f[x;y];h[x;y]]}`. that being said, (ngn/)k _does_ have a dsl, described below.

.differences from j

* user-defined k verbs can have only one valence. this asymmetry against builtin k verbs is odd but not necessarily bad. then again, user-defined k verbs can have up to 8 args.
* in k's grammar, all the following are nouns: parenthesized exprs, lambdas, identifiers.
* no modifier trains, rank system, boxing, framing fill, &c
* j's `@` & `&` (bind/curry) are implicit in k.

k's trains differ from j's:

.k trains
[options="header"]
|===========================================================
| name                 | juxtaposition seq | definition
| "projection" (curry) | N V               | `(xf)y` <=> `xfy`
| composition          | N/V ... V         | `(fg...h)[x;y]` <=> `fg...(xhy)`. `(fg)xy` cannot be applied in-place e.g. ```(5+)(*)[6;7]``` is valid (47) but ```7(5+)(*)6``` is a type error. example from link:https://ngn.codeberg.page/txt/tacitjk.pdf[ngn's pdf]: ```(1-_%*)[x;y] <=> 1-_%*[x;y] <=> 1-_%x*y```
|===========================================================

projections are denoted as m-exprs with args missing e.g. `-[1;]` to mean dyad `-` with left arg bound to `1`. you commonly see projections of dicts or arrays, too. for arrays, all elements of omitted axis are retrieved. for dicts, . notice that m-exprs support projections but `.` does not. dict projection example: ```(`z`y!((`a`b`c!"jkl");(`a`b`d!10 20 40)))[;`b`d]``` returns ````z`y!("k ";20 40)```.

these terms are used in ngn/k's quickref.

NOTE: k trains are ambivalent e.g. `(1+2*!)10` returns `1 3 5 7 9 11 13 15 17 19`. `(1+2*!)[,3;,10]` returns `(,3)!,21`

k' trains' utility: refactorabilit, brevity, composition (enables effectively lambdas with lexical scoping).

* hook as a k train: `f/1 g\`. `1 g\` produces a 2-vector `(x;g x)`; then fold `f` over (insert between) those 2 args.
* fork as a k train: `g/(f;h)@\:`. it applies each of `f` & `h` to the argvec, returning a 2-vector, then folds `g` over (inserts between) those results.
* `({10+x};(20+))@\:15` returns `25 35`

verbs in j but not k; i wonder how to implement these in k:

* key (group by): `{(!x),'.x}@="hello"`
* rotate & shift (in k3 but not k6). these are just index transforms with mod, max, or min. one implementation, from the ngn/k tutorial: `{,/|![#y;0,x]_y}`
* is `=` equivalent for j & k. j uses logical vectors whereas k uses indexes.
* k has no support for complex numbers? kinda whack. `%-2` gives `-0n`.
* no `E.` in k? `E:{((#y)':x)?y}`. (ratpack) parsers are better, though, since they generalize from mere equality to powerful patterns.

=== implementations

i'm going to consider this only after i become familiar with ngn/k. i'll use it as my _de facto_ k before i choose another, just because it's said to be good, and it's accessible, easy, small. it's perfectly sufficient for using and learning k. i can choose practical versions later, after becoming familiar enough with k to immediately appreciate nuances among implementations.

[options="header"]
|=======================================================================================================
| name                                                 | impl lang | k ver | notes
| link:https://github.com/ktye/i[i]                    | go        | ?     | -
| link:https://anaseto.codeberg.page/goal-docs/[goal]  | go        | -     |
| link:https://codeberg.org/ngn/k[ngn/k]               | c         | 6     | unmaintained since jan 2024
| link:https://github.com/kevinlawler/kona/wiki[kona]  | c         | 3     | 1st open k, so good wiki
| link:https://t3x.org/klong/klong-ref.txt.html[klong] | c         | -     |
| link:https://github.com/zholos/kuc/[kuc]             | c         | 5     |
| link:https://github.com/JohnEarnest/ok/[oK]          | js        | 5,6   |
|=======================================================================================================

=== why/when to use k (motivation)

measured by criteria in `~/codenotes/langs.adoc`, k scores high. it isn't ideal, but it's close. about the only real issue with it is that it's semi-concatenative; fortunately in practice this is probably tolerable if you style your code well, especially with k being so terse. to be determined.

* any dataflow programs that require at most the simplest io/environment patterns: writing to or reading all of a file descriptor, cmdline args, envvars.
* like prolog, encourages no special systems. e.g. no prolog nor k user would care for a sqlite interface, because k or prolog already can store relations fine in files, and efficiently & elegantly work with relations. no libraries for particular types, because prolog or k users dispense with types, since relations necessarily represent any type, but more capably & symmetricaly.
* dataflow notation, or if you've been using character-stream based interfaces enough to be tired of typing loads of shit, without typos, often redundantly many times
  ** it's really cool to be able to memorize programs or use low interfaces such as a smart phone, small keyboard, or just pen & paper to develop code. pen & paper isn't too much worse than the interactive repl, since the repl doesn't have a debugger anyway.

the whitney design argument about seeing all code in one place is good. however, to accomplish this by making code syntax terse assumes that we're displaying text in the common manner in a text editor. because text is a much poorer code than graphical ones, and should generally be so deprecated anyway, the terse syntax argument is moot.

*an important reason to use k* is to become familiar with its primitives: sets, seqs, maps. k is all the good primitives and structures. regardless of whether you use k, everyone should master designing k programs so that they can use those designs in _all_ programming, hopefully in a tacit, readable, metaprogrammable, virtual-operation language. it's also small enough (20 prims, and short code) that you can reason about it in your mind.

=== my opinion of k, now using it after i've become most used to factor

* k's ridiculous overloading is awesome. it's not an issue as long as the operator's context is clear, which is true when using literals or conventions that preface variables with a single character denoting their types.
* parsing is easy (but takes some practice) as long as i can read rtl, notice verb-adverb pairs, and know that left args are delimited; i don't want to ever deal with operator associativity levels. those suck. reading from the right is odd, too, since it makes newlines special syntax.
  ** consider this arbitrary k code: ```:m:(("forward";"down";"up")~/:\:d[;0])*\:d[;1]``` i tried copying then evaluating ```d[;0])*\:d[;1]``` to see what its value was, to try to visualize what's happening, only to find that it's malformed: there's a mismatched right parenthesis! fair enough, but not nearly as readable as factor. it's the same parsing as we see in factor: parse from one side, then parse a delimited subprogram, then consider them together. the same code, in concatenative style: `d [;1] d [;0] ( "forward" "down" "up" ) ~/:\: *\: m: :`. the whitespace makes confident parsing by eye much faster & easier! the dis/association is immediately obvious. refactoring is a load easier, too; if seeing the parens is already error prone, imagine what hell refactoring is; if you mismatch a parenthesis, then you're screwed! and because of k's extreme overloading, your mistake program may give a _totally_ different result from what you'd expected, so identifying what the refactoring mistake was would be very difficult & painful. the concatenative syntax shows that the code can be factored in the beginning, too: `d [;1] d [;0]` becomes `d [;1] [;0] bi`. we can then remove the input, `d`, and have a subprogram disassociated from any arguments. it also shows that parts of the program are related by `d` commonly and are computed next-together; the delimiting/separating parens of the original k expression suggest separation of `d[;0]` & `d[;1]`, and it's not obvious to think that they're computed next-together.
    *** still better than m-exprs, though

TODO: why doesn't this happen in good factor code? when i was new to factor, my code was horrible because i was doing manual loops, but also that i would build-up the stack in complicated ways, leaving a complex stack to be consumed by various subprocesses such that my code didn't permit easy refactoring, which is analagous to this unreadable k. i think it's because i used stack words instead of combinators and quotations. *one thing's certain: programs are easier to consider as incremental state changes than as gargantuan monoliths of nested subexpressions.* compared to factor, maybe the k code is weird b/c the parenthesized part is an expression rather than a program, and that the parenthesized expression is an argument to a verb rather than an adverb?

anyway, other booboo about the k code:

* perhaps, tracking order in which ast is evaluated is difficult, which would be an issue for non-pure code.
* though we usually read from right to left, this code is more easily read from left to right, since the left arg to `*\:` is more complex.
* parsing-out `~`, `/:`, and `\:`, among an arbitrary line of such code, is ugly. i don't care if the computer can do it; i'm a human, and such coding is unnatural and thus error-prone, stressful, and inefficient for me.

==== k vs factor

if k were purely tacit / concatenative, and readable, then it'd be perfect. k is tolerable, especially with syntax highlighting and judicious spacing. k is semi-concatinative: it supports trains and mostly reads in one direction. it accepts parameters inline, but rarely more than two, and when it uses two, it often does not require parentheses, which makes refactoring easier. if k were purely tacit, then statements would be able to span multiple lines, and the dyadic syntax wouldn't exist anymore. it has nested expressions, but nesting does not commonly go very deep. when it does, it's good style to refactor it into a subexpression or helper function. the nesting/monolith problem can be, as it can be in factor, solved by instead defining many small words. in both these langs defining words is low-overhead: in factor it's `: name effect def ;` and in k it's `name:{def}` (if 3 or fewer parameters) or `name:{}`. in both cases, definition is just a literal program but wrapped in delimiters then associated with a name. even in scheme, where this _can_ be done, it rarely is: usually we say `(define (name . params) def)` instead of `(define name (λ (params) def))`. scheme sucks because: 1. these are two significantly different syntaxes; 2. even the shorter syntax is non-ergonomically verbose.

===== applicative vs stack

* relating whole to various parts: the following pads strs to have equal length: `{((|/#'x)$)'x}` or `{(|/#'x)$\:x}`. it's `$` left-curried with the maximum length, mapped over the input array. in a stack lang it would be `.#|/$` (where `.` is `dup`) which is easier to reason about how to code from scratch, and shorter, and more readable. this is the reduction of the literal factor code `dup [ length ] map maximum [ 32 <padded-tail> >string ] curry map` once we replace `length` by `#`, `maximum` by `|`, `32 <padded-tail>` by `$`; and remove `map` because we assume an array paradigm, and remove `curry` because it's no longer necessary once we remove `map`; and once we assume a parser that restricts which words you can define such that whitespace isn't needed to delimit tokens. i really didn't expect the stack version to even be better necessarily, let alone _that_ much better! guess the stack really does always win.

===== array paradigm

arrays are available in factor of course. however, thinking in terms of arrays is particular, regardless of the language, and this thinking is encouraged by k &al apls. "thinking array" means:

====== attribute independence

instead of a sequence of tuples, a tuple of sequences, which is expressed as a tuple, since each object represents an array. ideally, however, we should define it altogether as a relation whose index is a tuple: (attribute name,numerical index). then in k we can say `rel[;4]` to get all attributes at `4`, or ```rel[`a;]``` to get all attribute `a`. we'd ideally use predicates, e.g. `rel(a>5,i=4)` but this is easily enough effectively done in k when we store relations as a vector of vectors e.g:

[source,k]
----
rel:(("dave";10;`M);("john";12;`M);("travis";20;`M);("stacy";13;`F);("holly";20;`F))
{(12<x[;1])|`F=x[;2]}#rel /the set of females union the set of people over 12 y/o
(("travis";20;`M)
 ("stacy";13;`F)
 ("holly";20;`F))
----

commonly we perform operations on arrays, then compose those results, rather than composing functions then iterating once through a multi-attribute/dimension vector.

''''

.aside: function arity

how _exactly_ to decide which parameters fns take? the following are considerations & observations that seek to answer.

. is it better for fn to take params, or have them one param but pattern match it into subsets?
. are variadic fns worth anything? even factor can use macros to inline fns and assert their stack effect statically. it'd be nice to not have to specify a number to e.g. `nmap`, but w/e.
  .. are variadic fns useful only for coding ergonomics i.e. are they always fns known at runtime?
. sql's model of queries essentially being pattern-matching fns of relations is good. a sql table can be made by reading json, so tables can be added dynamically, which is good.
. higher-order fns are bad: they parameterize arbitrary parts of the computation and require those parts to have specific inputs & outputs, and are thereby limited. inevitably a user will eventually want to parameterize a different part of the computation, or to accept different inputs, or have more outputs used by the higher-order fn somehow. modifying functions is impractical, whereas modifying data is ubiquitous, so better to have functions be so small that any fewer inputs would make the function degenerate. this is the method of greatest flexibility. perhaps it's appropriate, then, for k to have mostly unary & binary operations, plus some few triadic & quaternary fns. it's because those fns are practically fundamental and couldn't be defined by fewer distinct inputs.
  .. higher-order fns tend to create frameworks, which are overconstrained, difficult to design & amend/extend. these difficult endeavors are foolish & unnecessary, not noble. this is *a significant part of why k is so good: where in other langs functions would be defined & called, in k we just dispense with defining fns, instead inlining their definitions and calling them "idioms." when everything's inline, then each arbitrary part is effortlessly modifiable.*
  .. factor demonstrates that higher-order fns are practically just to splice programs into other programs, quite (though not _exactly_) like scheme's `,@`
. fns should return many outputs, to preserve its computation. the user may decide to discard those outputs, rather than the function deciding to discard them by simply not returning them. returning multiple outputs is much easier if we pattern match elegantly. for stacks, it'd be inelegant to use `ndrop`, `nip`,  &c frequently. in applicative langs, it'd be ugly for many multi-parameter positional bindings to feature many holes. eliding outputs is best done in sql: rather than using binding clauses, the outputs are named by the function. one may rename them (and indeed must occasionally do that to disambiguate). anyway, the lack of binding clause and ability to tacitly refer to variables is excellent.

''''

* k has subexpressions. factor has only subprograms, b/c it's purely tacit.
* needing to "lookahead" to the left of a verb to determine whether it's unary or binary is initially bad, but it feels natural after a week or so of studying k daily. it's no trickier than reading stack-lang code. consider `quicksort:{$[2>#?x;x;,/o'x@&'~:\x<*1?x]}`. it's short enough to glace it, so do so. you see `$[` which means conditional, so start reading from the left, looking for semicolons. for each long subexpression, start at its right. the "else" clause is the only trick part. starting from the right, i see `x`, then `?`, so i would like to think `?x` but i must lookahead to the next token to see that it's a noun, `1`, so now i've parsed code into an actual semantic value, `1?x`; then ```*```'s meaning is unknown until i read the following token,.... later, idk if `\` is a unary or binary adverb until i tokenize code on its left. (btw, don't mistake `:\` for the adverb `\:`; and if you're curious about how quicksort works, see the explanation in <<_examples>> below.) lookahead is generally troublesome, but it's practically fine in k because any one non-M-expr token is at most triadic. that k has no "flip" (selfie) is tragic, though, as left argument expressions can be parenthesis forests. summary: k's grammar is fine once you quickly get used to it, but it's still not ideal. being concatenative and having selfie are both good solutions.
* where k beats factor (in practice; factor has strictly greater capability):
  ** terse: avoids shit that isn't strictly encoding the program logic itself. needing to type multiple characters is a needless pain just like needing to compile, or scaffold a project, or any other assumed, imposed constraint that could theoretically be removed or modified without affecting the program itself. we are humans coding; our needs are important, and our coding methods must reflect that! the code itself is generated by our methods, and is so related to them; it's appropriate for us, as one aspect of our method, to choose codes that suit our ability to code them and reason about them!
  ** overloaded: each verb is a concept with multiple varieties as it's applied to specific contexts (nouns). this is a natural separation and combination of verbs and nouns, which makes reasoning about program design easy. it also avoids trying to name conceputally similar or homomorphic operations e.g. in factor the separate words `remove` for sequences and `delete` for sets, despite them being the same damn thing! but nope, due to types, they aren't interchangeable!
  ** powerful mechanisms for relating structures' elements
  ** seqs, fns, and maps are all act the same.
  ** dictionary/vector symmetry
* where factor beats k:
  ** walker (debugger)
  ** concatenative. in a nutshell: incremental data pipeline construction, spilicable & (re)factorable programs
* both have excellent documentation. factor's is interactive at the cost of requiring you to run a gui, and is vast & complex, whereas link:https://codeberg.org/ngn/k/src/branch/master/repl.k[k's] is accessible since it's just text, and is succinct.
* to be able to collect intermediate values from any loop is cool. the backslash words do this.
* very optimized, small implementations are very cool: they afford codes that would otherwise be too inefficient. still, though, mostly virtual operations afford that.
* the stack's excellence is questionable because function parameterization is questionable. having separate inputs instead of one which is pattern-matched against is questionable.

===== common factor patterns done in k

k is semantically scheme [lisp] but with apl-ish syntax. scheme, prolog, factor, and probably all other homoiconic languages are prefectly general and equivalent in their capability; no hacks are required, and all paradigms can be defined by these languages. thus k is as capable as factor. here are some common "powerful" factor idioms translated to k.

[options="header"]
|============================================================
| factor                       | k                  | comment
| `7 [ 10 * ] [ 5 swap - ] bi` | `((10*);(5-))@\:7` | k uses only seqs, whereas factor has a false dichotomy of seqs vs the stack. k's better b/c no swap and only one structure. also if i use `7 8 9` instead of just `7` then i'd have to change the factor code to include `map`, but no such need in k.
|============================================================

== k notes

=== environment

* `\l <path>` runs the k code at the given path

=== semantics

*scope like j. scope is not nested:*

[source,k]
----
{v:4;{x+v}@x} 6 /inner lambda does not inherit outer lambda's namespace!
'value
 {x+v}
    ^
 {v:4;{x+v}@x}
           ^
 {v:4;{x+v}@x} 6
               ^
{v::4;{x+v}@x} 6 /globally define v
10
v                /v retains its last binding, regardless of context!
4
----

so you have to pass all your shit as arguments to inner lambdas: `{v:4;{[x;v] x+v}.(x;v)} 6`. *what elegance!* hopefully there's a great benefit for this restriction so that my sarcasm is actually inappropriate. besides: fortunately this is not common in k, since k is mostly semi-concatenative; and this is a problem only when introducing proper lambdas, not curried functions (aka "projection"). `{v:4;(v+)@x}6` works fine.

* statements evaluate ltr, but each statement evaluates rtl 
* vector—not array—language.
  ** dicts are just pairs of vectors. they are ordered. all vectors are implicitly dicts with natural number keys.
  ** ngn/k supports tables, a structure from in k7, k9, and q, and not part of the k6 standard. tables are lists of dicts or flipped dicts e.g. ```(`a`b!)@/:(1 2; 3 4)``` or ```+`a`b!(1 2 3;2 3 4)``` respectively. they're equivalent. the repl prints them as flipped dicts with `!` in m-expr form. as the code denotes, tables are maps from symbols to vectors—an isomorphism of sql relations. tables' particular use, aside from perhaps being efficient for their operations, is that they may be indexed by column name or row number e.g. the above table may be indexed by `@0 0 1` to produce a table with a repeated row, or ```@`a`b```` to get `(1 3; 2 4)`, or ```[`a;1]``` to get `3`, etc.
* no rational type. only floats :(
* an n-dim vector maps n coordinates to its unique elt
* scalars are exactly 0-dim vectors. an empty vector can be used to index into a scalar.
* like j, verbs may be _atomic_: they apply to all atoms of a vector
* scalars are broadcast
* functions are 1st-class e.g. `x (*(+;*))\: y` computes `x+\:y`; the adverb accepts a verb/gerund. in k, all verbs are gerunds; they're only actually applied in certain grammatical contexts or if manually invoked by `@` or `.`.
  ** *this demonstrates a very beautiful and powerful description of k's grammar: k programs are just a bunch of juxtaposed symbols evaluated in context!* for example, `'` is a symbol, and has things on its left and right. when the left is of the "function" type, then `'` means "each" and evaluates to a function. if left is of any other type, then `'` means "interval index" and evaluates to a vector. in the case when it evaluates to a function, then the function is evaluated in its context e.g. `x,'y` evaluates as follows: `y` is a thing; it remains so. `'` can be many things depending on what, if anything, is given on its left or right. in this case, there's a `,` on the left and a thing on the right; thus it evaluates to the token `,'`, leaving the thing on the right. now we have `x ,' y`; `,'` is a thing that evaluates depending on what, if anything, is given to its left or right. in this case, both are given, so it point-wise associates them and applies its operation to each pair, collecting all those results in a list. were left not given or if left were a function, then it would apply `,` to each of right, producing a value, which would be left to left to decide how to evaluate it. if right were omitted but left were provided and weren't a function, then `left,'` would evaluate to a left-curried version of `,'`. this is the same pattern that we see in e.g. scheme, but where function application is decided by each token's contextual rules rather than being specified by the programmer in every invocation context, and with extreme focus on ad-hoc rules determined by types, and where functions may lack left or right arguments. this system is similar to haskell's auto-currying, but concatenative: like a thing atop the stack taking an argument that, if a function, consumes it and leaves a composed function on the stack, and so on—though really term rewriting is a more appropriate model.
* functions and indexing are one operation. this is appropriate when we consider functions as maps from dom to cod i.e. (10+)@12 can be equivalently interpreted as "the map that adds 10, indexed at 12" (an interpretation which i strongly encourage) or "pass 12 to the function that returns 10 plus its input." this enables `{10+x} 5` to work; `{10+x}` is not a verb; it's a noun! thus `{10+x} 5` satisfies the subgrammar, "noun noun". juxtaposed nouns are evaluated as "index left noun by using right noun as index". because of function-dict equivalence, to access a function as a map is to invoke it on its argument.

TODO:
* what are "prototypes?" the link:https://wiki.cor.fyi/wiki/Ngn/k[k wiki] says that ngn/k partially supports prototypes. kona hasn't tables but has prototypes.

==== really cool k semantics to incorporate in other langs

* funcall/index duality. `@` is "index x at y" or "call x with argvec y"
* functions are implicitly quoted simply by parenthecizing them e.g. `(-),1` returns 2-element vector `(-;3)`; this is because k's grammar is contextual, and a verb by itself (without args) is considered as a noun; thus, because in the parenthecized `-` is a noun and thus `,` joins two nouns into a vector.
  ** to invoke the essentially-quoted verb, use `@`
* contextual grammar and thus contextual evaluation of deferred/quoted expressions
* a single variable can refer to a set e.g. in `{4+x}`, `x` can refer to a vector. ideally it would, like in prolog, refer to a (constrained) set. as an honorable mention, sql variables also refer to sets.

hopefully rank must be explicit in k. rank should always be explicit as a general coding convention. k's `each` probably does that.

.beautiful dictionary/vector symmetry

each'ing (a monadic verb) over a vector applies to a vector's elements, not its indices. likewise, eaching over a dict applies to its values, leaving its keys in tact e.g. `{5+x}'`a`b`c!1 2 3` returns ``a`b`c!6 7 8`.

[source,k]
&`rita`bob`sue`adam`frank!0 0 1 0 1      / keys which have a value of 1: `sue`frank
(`bob`adam`sue`rita!23 54 12 82)?12      / find key by value: `sue. if vals were ordered, then we'd be able to use X'
&5=`bob`adam`sue`rita!5 1 5 3            / all keys having a value 5: `bob`sue
|\`rita`bob`sue`adam`frank!12 7 87 32 11 / returns `rita`bob`sue`adam`frank!12 12 87 87 87

=== types

types are here listed with a common shorthand:

[options="header"]
|======================================================
| sym               | name                | empty value
| c                 | char                |
| i                 | int                 | 0
| n                 | number (int\|float) | 0[.0]
| s                 | symbol              |
| a                 | atom                |
| d                 | dict                |
| f                 | monadic func        |
| F                 | dyadic func         |
| any of x, y, or z | any                 | <n/a>
|======================================================

excepting `F`, a lowercase letter means a scalar, and a capital one a vector; e.g. `C` means a string and X or means "a vector of anything."

these symbols are used by cast ($/2) and type (@/1).

=== syntax

* right-associative
* conditional branching: `:[p1;f1;p2;f2;...;else]`
  ** dollar sign may be used instead of colon
  ** the empty values are the only falsy values in k: number: `0`; array: `()`; character: `0x00` i.e. "\0"; symbol: ```````; function: `::`, dict: `()!()`. all others are truthy. *`0N` is truthy! use `^:` to convert it to a false*
  ** prefixing a clause with `:` will make it return immediately, ignoring the clause's remaining computation
* newlines behave identically to semicolons. this enables you to directly code pretty-print matrices: one row per line.
* literals:
  ** empty list: `!0`
  ** character: `0xHH` where HH is a number in hexadecimal
  ** null: `0N`. *null is truthy*.
  ** `[stmt1;...]` is progn [lisp] i.e. all statements except the last are evaluated only for side effects, and the last statement's value is returned from the whole bracked expression list. this is the same as the comma operator in c.
  ** symbol: ````sym```
  ** vector: `(a;b;...)`
  ** generally list literals are sequences of homogenous-type data literals.
    *** the following must be parenthesized and its elements must be delimited by semicolons:
      **** hetrogeneous lists' of literals
      **** lists of non-literal nouns
      **** lists of lambdas (this prevents applying the lambdas to each other)
    *** exception: logical vector literal: [0|1]*b e.g. `10010b`
  ** dicts, at least in ngn/k, must be constructed by `!/2`. i think that i've seen other k6 impls use `[k:v;...]` syntax where symbol keys are not prefixed by grave accent.
  ** function:
    *** `{[arg1;...] definition}`
    *** in ngn/k, to bind to a symbol (single non-ascii character, it seems) to a definition, parenthesize it e.g. `(⁂):(10+)` which can be invoked like `⁂!6`. afaik you cannot define ambivalent functions. however, there is special support for defining 2-character symbols where the 2nd symbol is `:` but this has nothing to do with arity. e.g. `(⁂):(10+);(⁂:):{%x%y}` to define an inline monad, `⁂`, and an inline dyad `⁂:` invokable as e.g. `20⁂:10` or `⁂4`. of course, conventionally you'd define verbs ending in `:` as monadic, and a corresponding non-`:` one as dyadic.
    *** `{...}`. unary fns arg (on the right side) is called `x`, but in binary functions, `y` is the right arg, and `x` is the left! if you use `z` then you must invoke by an argument vector anyway e.g. in `{z%y+x}[30;20;10]`, `x`=30, `y`=20, `z`=10.
    *** fns may use semicolons; then they're the progn but parameterized by xyz
  ** negative literals are as in most langs: hyphen immediately followed by a number literal
* slash begins line comment
* `o` is like apl ∇ e.g. `{$[x<2;x;+/o'x-1 2]}9` returns 34. technically `o` is a special noun, not a special syntax. thus it can be used infix-dyadically or with the usual function application/indexing operators/syntaxes. of course, then, `o` is used commonly for recursion. however, maybe it can be used to return the current fn to another fn, for e.g. fn callback sequences; i'm yet unsure. idk if `o` captures the current continuation (or if k even uses continuations as they're in scheme or factor) or what.
* binding identifiers to values:
  ** `a:v` binds identifier `a` to value `v`
  ** `(a b c):v` binds identifiers `a`, `b`, and `c` to 0th, 1st, & 2nd values of `v`
  ** `aV:v` binds identifier `a` to `aVv` where `V` is a dyad
  ** "unpack": `(v;...):y` pattern matches/binds e.g. `(b;(c;d)):(2 3;4 5)` binds `b` to `1 2`, `c` to 4, and `d` to 5.
* juxtaposed nouns (`y x`) or `y[x]` evaluate as `y@x`. multi-parameter function punning also works: `x[i;j;...]` is the same as `x.(i;j;...)`
  ** omitting an index on a side of a semicolon means "all" e.g. `("abc";"DEF")[;1]` returns `"bE"`
  ** selecting multiple indices at depth (a mix of amend & drill): `(4 5#!20)[(0 1;1 2)]`. the parenthesis make this one vector index rather than multiple nested indices.
* setting a value at a given index: `m[i;j;...]: v`. `m[i][j]...:v` is illegal. drill is better.

you can put into a dict `d` by the following syntax: `d[`k1`k2`...]:v1 v2...`.

TODO: understand indexing exactly. `(4 5#!20)[0 1][1 2]` differs from `(4 5#!20)[0 1;1 2]` and isn't indxing at depth (so says xpqz). he may certainly be correct, as idk what semicolon means.

=== verbs

NOTE: suffix `:` forces an ambivalent verb's monadic form.

* verbs may be left- or right-atomic, or apply to the whole argument (in j this is rank infinity or rank _1).
* in this table, i mean `x` as the left arg and `y` as the right.
* useful verbs—the ones that help you design dataflow programs—are in bold

to be explicit i'll use `R` & `L` instead of `x` & `y`, unless `x` & `y`'s (or other symbols') positions are explicitly given. `x` is always the 1st arg; in a monad, the 1st (and single) arg is on the right; in a dyad, it's on the left.

the following table's verbosity is between link:https://github.com/JohnEarnest/ok/blob/gh-pages/docs/Manual.md#verb-reference[oK's verb table] and the <<_ngn_quick_reference>>.

[options="header"]
|=============================================================================================================================================================================================================================
| symbol     | monad                                                   | dyad
| `s:x`      | identity                                                | almost always used as _bind local_ (`s` is an identifier.) also, if `s` is a datum literal, then `s:x` returns `x` i.e. it's the "right" function, which is useful in the verbs "amend" or "drill"; this use of right is necessarily useless inline, but the right-curried version is useful. rather, its utility is that when its right arg is curried, then it's the constant fn.
| `::`       | identity (literally, `::` is the monadic form of `:`)   | bind global
| `,`        | make singleton of +1-dim                                | *concat or dict union* (merges per key, discarding the left dict's value in lieu of the right's)
| `<f\|i>#x` | *count*                                                 | *1. shape: truncate or repeat to make given length & shape, starting from the end if `i<0`; or 2. if `x` is a dict: select entries by (symbol or char) keys `i`; or 3. filter `x` by `f` [applied to its values]* (generally `f` returns a natural which is the count; 0 & 1 are the most common). *see notes & examples below.*
| `+`        | transpose                                               | add
| `-`        | neg                                                     | sub
| `*`        | first val (atom)                                        | mul
| `%`        | sqrt                                                    | div
| `!`        | i. (0D) / permutations (1D); or dict's *keys*           | dict of `keys!vals`, or `div` if `num<0`, or `mod` if `num>0`; *div & mod are `denom!num`*
| `&`        | *n non-0's* ("where")                                   | min (implicitly boolean AND)
| `\|`       | reverse                                                 | max (implicitly boolean OR)
| `<` & `>`  | *grade* [keys by their values] up or down; or <<_io>>   | less or greater than
| `=`        | partition into nub & idxs; or identity matrix           | atomic equality
| `~`        | `(=0)`                                                  | match (same shape, values, *and types*)
| `^`        | `null?`                                                 | set `x`'s nulls to `y`, or *`Y` without any of `X`'s elts*
| `_`        | floor or `>lower`                                       | *`i_X`: drop [from end if `i<0`]; `Y_i`: `Y` without ith elt; `I_X`: split `X` at `I` (which must be monotonically increasing) into non-overlapping substrs*; `f_X`: filter-out
| `$`        | convert elts to strs                                    | x:ℤ, y:str: pad on right (or left if x<0); type cast (see below)
| `?`        | *nub* or _n_ floats on [0,1]                            | *find R in L*, return idx; or n rand vals of set given by y. x<0=>pick w/o replacement, in which case `\|x\|>=#Y` => length error, where Y is the set described by y. or `0N?X` to shuffle `X`.
| `\` & `/`  | while (adverb)                                          | C/C: *join*. C\C: *split*; as in j: I/I decode, I\I encode. behavior about shaping transcodes varies among k implemenations.
| `.`        | eval k syntax string, or get a dict's *vals*            | call `y` with argvec `x`
| `@`        | type                                                    | *`y` at `x`*
| `'`        | each (adverb)                                           | `L` must be ordered-asc list. returns greatest `i` s.t. `L[i]<=R` or -1 if `R<L[0]`.
|=============================================================================================================================================================================================================================

mnemonics:

* `\` & `/` are just 'transcode"; the side that they're leading toward is the coding direction: `\` is like `<-`: `2\14` transcodes `14` (implicitly in base 10) into base `2`. `/` is of course the inverse.
* aain, `\` & `/`, in the case of join vs split, think of `/` as fold `x` into `y`; this is join. then `\` is its dual.

.colon madness

when you see a colon in code, it's one of 3 things:

. definition (identifier on the left)
. one of these adverbs: window (`':`) or each left/right (`\:` or `/:`).
. force a verb to be monadic (builtin verb on the left)

or just the identity function, `::`.

never would one intentionally write `x:y` to mean "return right argument", since one could always simply put `y` instead.

==== `#/2`

===== reshape

* can columnize e.g. `0N 10!21` which is like j's `_2]\` but instead of filling, it leaves the last row ragged
* if one of left's values is `0N`, then that axis length is computed by the length and other axes' lengths
* `i#x` shapes `x` to have `i` shape. it is not like j's `#`! e.g. `1 0 1 0 1#"hello"` returns `,0#,,0#,," "`! `{1 0 1 0 1}#"hello"` returns `"hlo"`! `i` is a shape vector as would be used in j's `$/2` e.g. `3 2 2#"cat"` produces:

-------------
(("ca";"tc")
 ("at";"ca")
 ("tc";"at"))
-------------

which has shape `3 2 2`, which is attained by shaping the 1D array, `(*/3 2 2)#"cat"`. thus we see that `#/2` is useful for systematically nesting.

===== filter

* `f#x` is just a combination of `&` & `@`: `p#` is equivalent to `{x@&px}`. this is a reason why `&` is called "where". like how `<` is useful for sorting multiple vectors by a common order, so is `&` useful for filtering multiple vectors by a common filter.
* `f` is applied to `x`, not each of `x`'s elts! e.g. `(0=2!)#!10` computes the mask `(0=2!)@!10` then applies it pointwise to `!10`. this is significant in e.g. `{`M=x[;2]}#(("dave";10;`M);("john";12;`M);("stacy";13;`F);("holly";20;`F))`
  ** this k3 example that apparently works in k3 but not in ngn/k: ```{x~|x}#("racecar";"nope";"bob")``` gives `0#,"       ". i have no idea what that means, but apparently it's length is 0. anyway, `({x~|x}')#("racecar";"nope";"bob")` is correct in k6. i suspect that i'll often use this pattern of filtering with a predicate that's been each'd.

.each

each makes verbs 1:1. in some sense, atomic verbs become non-atomic, and non-atomic verbs become atomic.

''''

* `Y'X` is equivalent to `-1++/X>/:Y`
* eval (`./1`) is slow
* freq, which replaced group in later versions of k, is `#'=`.
* joins are implicit in k e.g. `(`a`b`d!3 2 5) ,' `a`b`c!1 2 3` produces ``a`b`d`c!(3 1;2 2;5 0N;0N 3)` and replacing `,/` by ```*``` or ```*/``` (they're equivalent given ```*```'s rank) gives ``a`b`d`c!3 4 5 3`; we can see that default values are used as they are in fold. this is called `assoc-merge` in factor.
* in factor, window is called "clumps". "groups" is to split at every n. in k: `{(&0=y!!#x)_x}`
* oK has a builtin, `x in y`, which is just `~^y?x`
* `&` gives n indices for each index whose value isn't 0. we can define it as `{,/x#'!#x}`, or for dicts: `{,/x#'!x}`
* to get a better understanding of the permutation ("odometer") `!`, look at its transpose
* `X'` isn't an adverb because it doesn't modify a verb. if it's technically implemented in the parser as an adverb, then that's a hack, not a reflection of actual logical truth.
* is there really no ≤/≥? to be fair, those aren't really helpful; for integers, just +1 or -1, and floats aren't precise anyway, so equality is an infinitesimal difference anyway! instead of `gte 0` you can do `>1e-9`.
  ** or, rather, ≤ is "not greater than": `~>`
* there's a floor but no ceiling! this is ok: ceiling is so defined in factor: `: ceiling ( x -- y ) neg floor neg ;` indeed, even floor isn't a primitive in factor.
* reshape with `0N` means "unbounded" e.g. `0N 3#!10`
* example i/o: `myFD:<`"/path/to/file.txt"` then `>myFD` to close it.
* `=/1` isn't useful. link:https://gist.github.com/chrispsn/3450fe6172a7cc441d0819379ed3a32a[it was also replaced by a function called "frequency"]
  ** btw, i think that the article suggests special token `(&:)?`to mean run-length encoding, which is the inverse of unary `&`; in some versions/implementations of k, `?` following a gerund (verb-as-a-noun) means "inverse" like how `^:_1` is "inverse" in j.
  ** its keys aren't sorted in ngn/k. check your implementation's docs to see if they sort it, and consider whether you want to write implementation-specific code.

others:

------------------------------------------------------------------
.S get       a:1;.`a -> 1   b.c:2;.`b`c -> 2 / like j's reflex, ~m
/ unary or binary (with right arg) amend
@[x;y;f]   amend  @["ABC";1;_:] -> "AbC"   @[2 3;1;{-x}] -> 2 -3
@[x;y;F;z] amend  @["abc";1;:;"x"] -> "axc"   @[2 3;0;+;4] -> 6 3
/ drill is the same but accepts deep indices. it obviates amend. i guess that amend exists because it's more efficient, or b/c it works for multiple args without each right (/:)
.[x;y;f]   drill  .[("AB";"CD");1 0;_:] -> ("AB";"cD")
.[x;y;F;z] drill  .[("ab";"cd");1 0;:;"x"] -> ("ab";"xd")
.[f;y;f]   try    .[+;1 2;"E:",] -> 3   .[+;1,`2;"E:",] -> "E:typ"
/ splice removes a substring and replaces it with a string. if the substring is empty, then you're only inserting. it's a simultaneous removal & insertion. very good design.
?[x;y;z]   splice ?["abcd";1 3;"xyz"] -> "axyzd"
------------------------------------------------------------------

.io

TODO: add "seek" verb to ngn/k. takes a lambda from current position.

* `[x]n:i y`, where `n` is `0` or `1` for lines or bytes and `i` is an io descriptor, is a verb. the unary case reads from `y`. the binary case writes `y` to `x`.
* when ``````` is on the left, then it's stdout; when on the right, it means stdin: ````0:("lines";"vines")```, ````1:"hello"```, ```name:1:`;name```. of course, you can use standard POSIX file descriptors `1` and `0` for stdout and stdin respectively. otherwise file descriptors may be gotten from `<:`
* other io descriptors are strings:
  ** file paths, which may be absolute, or relative to the directory in which the k interpreter is running
  ** `"[host]:port"` where `host` defaults to `127.0.0.1`. *this does not support http(s)! it's tcp only!* if you want the usual www funcs, then interface k with cURL or something, somehow.

example:

[source,k]
----
h:<`"/home/nic/myfile" / open handle
`1:1:h                 / 1:h reads from h into a string; `1: prints it to stdout
                       / b/c we read h entirely, further reading from it will return ""
>h                     / close handle
----

.serialization

because ngn/k always prints k source code, serialization is implicit. to convert to a string properly, use ````k@```. to serialize as json, use ````j@```. to read json, use ````j?```.

.namespaces & modules

. to load (run/eval) a k file, use `\l <PATH>`
. use `\d <NS>` to set the namespace until the next `\d`.
  .. `\d .` returns to the default namespace
. to refer to an identifier of a particular namespace, prefix the identifier by the namespace and a dot e.g. `myns.myvar`.

=== adverbs

the following are verbs given in terms of adverbs and an argument of a given type. i use brackets to mean optional, angle brackets to mean required, and `\|` to mean "or".

there are 3 kinds of abverbs: unrelated-element loops; related-element loops; window loops.

[options="header"]
|============================================================================================================================
| symbol w/types        | functionality
| `[y]<F\|f>'x`         | pointwise relation, or apply `f` to each elt of `x`. broadcasts atoms `y` or `x` to shape of `x` or `y`.
| `y F<\\|/>:x`         | relate entire `y` with each `x`, or vice versa.
| `[x]F</\>`            | left fold or scan with init val `x` or default value. unlike in j, scans are as efficient as folds.
| `[i\|p] f</\|\>x`     | apply `f` to `x` `i` times, or until it fails `p`, or until the value converges or returns to the inital. the scanny version's output (nearly) always contains the initial value and the 1st value that failed the predicate e.g. `{(x!)(1+)\1}` returns the sequence `[1..x]` and `(<1)(1+)\1` returns `1 2`. the "nearly" part is that, stranegly, if you use the predicate `{0}` (or `{x:0}`) then you're guaranteed to get a singleton result. the foldy version is equivalent to taking the last of the scan. see below for the general case: n-ary `f`.
| `i [f]':x`, `[y]F':x` | [apply `f` to each] `i`-window of `x`, or apply `F` to each 2-window of `x` [with initial value `y` for the 1st window]. there cannot be a space between `':` and its left arg.
|============================================================================================================================

each left vs right mnemonic: `\:` iterates over the LHS elts. if you picture the (back)slash as a person, then they'd fall toward the side that is iterated over.

.general, n-ary while

description: `f\[i;y1;...;yn]`

preconditions:

* `f` in `n-adic`
* all `y` have equal length

behavior:

if `i` is an integer, then apply _f^∘i^_ (iterated fn), collecting results. if `i<n` then the ``i``'th argument is returned alone. the following code demonstrates the usual case, `n>i`:

[source,k]
----------------------------------------------------------------------------------
{y," ",x," ","f"}\[5;"x";"y"] / prints successive applications in postfix notation
("x"
 "y"                 / i=0. f\[0;"x";"y"] returns "x". ACC is "x".
 "y x f"             / i=1. f\[1;"x";"y"] returns "y". ACC is "xy".
 "y x f y f"         / i=2. f\[2;"x";"y"] returns `f.ACC`.
 "y x f y f y x f f" / i=3. `ACC:f.-n#ACC`. this is the general case
 "y x f y f y x f f y x f y f f")
----------------------------------------------------------------------------------

the final case is re-written in its applicative form as `f(f(y,f(x,y)),f(f(x,y),f(y,f(x,y))))`, which is represented by this tree:

--------------------------
     (    f    )
    /           \
   |           ( f )
   |          /     \
   f         f   |   f
  / \       / \  |  / \
 y   f     x   y | y   f
    / \          |    / \
   x   y         |   x   y
--------------------------

this is a binary tree becasue `f` is binary. at each level, the left branch is a sub-branch of the right.

NOTE: it may seem backwards that the first iteration is `y x f` instead of `x y f`. it is correct, though, in that `x` is the argument nearest to `f`, and if we were to omit `y`, then we'd have `x f` i.e. `f(x)`, the unary case. if we use this convention, then the rest of the iterations naturally agree.

as stated, the general case comes when `i=3`. `-n#` (here `n=2`) is the negative of ``f``'s arity; we apply `f` to the last _n_ of ``ACC``'s elts on each iteration for which `~n<i`.

if `i` is a list, then `i` is an initial value. returned is `f.(,x),Y[;n]` where `Y` is `(y0;...;yn)`:

---------------------------
{x,y,z}\["ABC";"123";"abc"]
("ABC1a"
 "ABC1a2b"
 "ABC1a2b3c")
---------------------------

i'm curious to find a use for this pattern.

of course we can exchange `\` for `/` to return only the final result.

.implicit disambiguation/parsing of `[x]F</\>` vs `[i\|p]f</\>`

the ambiguity is whether ```*``` is monadic or dyadic; this determines whether to apply the lambda/predicate afterward, or whether to use it as a "while" clause. as far as i've noticed, this is the only ambiguous grammar.

theoretically, token sequence `A B /` (or `\`) must be parsed thusly if `B` is an ambivalent verb (`B` being a noun would imply the verb form of `/` or `\` (split/join or encode/decode):

. if `A` is a verb then (probably) the "while" form is assumed. idk if it's theoretically possible to have a lambda be a fold's initial value.
  .. in ngn/k, ```{0=2!x}*/1 2 3``` gives a type error whereas ```{0=2!x}(*/1 2 3)``` returns `1` because 6 is even.
. else if `A` is a non-integral noun then it must be a fold's initial value
. else if `A` is an integer then it could be a fold's initial value or a number of times to apply a unary fn
  .. apparently ngn/k assumes the fold case: ```4+/,1 2``` returns `5 6`. `4+:/,1 2` returns `,1 2`—the input transposed 4 times.

.each right/left examples
-------------------------
10 20 30,\:1 2 3 / map (,1 2 3) over 10 20 30
(10 1 2 3
 20 1 2 3
 30 1 2 3)

10 20 30,/:1 2 3 / map (10 20 30,) over 1 2 3
(10 20 30 1
 10 20 30 2
 10 20 30 3)

/ composed each's:

10 20 30,\:/:1 2 3
((10 1;20 1;30 1)
 (10 2;20 2;30 2)
 (10 3;20 3;30 3))

10 20 30,/:\:1 2 3
((10 1;10 2;10 3)
 (20 1;20 2;20 3)
 (30 1;30 2;30 3))
-------------------------

NOTE: you cannot have a space between argument and `/`, since in that case `/...` will be treated as a comment

TODO: how does the parser distinguish between `if/` and `xF/` where `x`=`i`? maybe it tries the dyadic version first, else tries monadic?

=== ngn quick-reference

backslash commands, when evaluated in the repl, are supposed to print their corresponding reference docs e.g. `\+` prints verbs. for me, however, they all print `'nyi`, so i can't get the reference in the repl, so i've put part the reference here that i haven't already covered in the above notes. the followig is copied from `repl.k` from the ngn/k repo:

---------------------------------------------------------------------------------------
\   help               \\         exit
\a  license(AGPLv3)    \l file.k  load
\0  types              \d foo.bar set namespace; restore with  \d .
\+  verbs              \t:n expr  time(elapsed milliseconds after n runs)
\:  I/O verbs          \v         variables
\'  adverbs            \f         functions
\`  symbols            \cd path   change directory
\h  summary            \other     command(through /bin/sh)
--------------------------------------------------------------------------------
\0
Types: / as returned by monadic @
list atom
 `A        generic list   ()   ,"ab"   (0;`1;"2";{3};%)
 `I   `i   int            0N -9223372036854775807 01b
 `F   `f   float          -0w -0.0 0.0 0w 1.2e308 0n
 `C   `c   char           "a"   0x6263   "d\0\"\n\r\t"
 `S   `s   symbol         `   `a   `"file.txt"   `b`cd`"ef"
 `M   `m   table&dict     +`a`b!(0 1;"23")   (0#`)!()
      `o   lambda         {1+x*y#z}  {[a;b]+/*/2#,a,b}
      `p   projection     1+   {z}[0;1]   @[;i;;]
      `q   composition    *|:   {1+x*y}@
      `r   derived verb   +/   2\   {y,x}':
      `u   monadic verb   +:   0::
      `v   dyadic  verb   +   0:
      `w   adverb         '   /:
      `x   external func
--------------------------------------------------------------------------------
\+
Verbs:    : + - * % ! & | < > = ~ , ^ # _ $ ? @ . 0: 1:
notation: [c]har [i]nt [n]umber(int|float|char) [s]ymbol [a]tom [d]ict
          [f]unc(monad) [F]unc(dyad) [xyz]any / this notation is distinct from the types given above
special:  var:y     set    a:1;a -> 1
          var::y    global a:1;{a::2}[];a -> 2
          (v;..):y  unpack (b;(c;d)):(2 3;4 5);c -> 4 / it seems that there's no "rest" matching like in scheme (`. xs`) so if you want to parse (1;2 3 4) into (a;(b.rst)), you'd do (a;b):(1;2 3 4);rst:1_b;b:*b; you'd probably just inline *b and 1_b anyway, though.
          :x        return {:x+1;2}[3] -> 4
          :[x;y;..] cond   :[0;`a;"\0";`b;`;`c;();`d;`e] -> `e
          o[..]     recur  {:[x<2;x;+/o'x-1 2]}9 -> 34
          [..]      progn  [0;1;2;3] -> 3

 !S ns keys   a.b.c:1;a.b.d:2;!`a`b -> `c`d
 &I where     &3 -> 0 0 0   &1 0 1 4 2 -> 0 2 3 3 3 3 4 4
 &x deepwhere &(0 1 0;1 0 0;1 1 1) -> (0 1 2 2 2;1 0 0 1 2)
 <s open      fd:<`"/path/to/file.txt"
 >i close     >fd
 ~x not       ~(0 2;``a;"a \0";::;{}) -> (1 0;1 0;0 0 1;1;0) / TODO: what does :: in a vector mean?
 ,x enlist    ,`a!1 -> +(,`a)!,,1 / TODO: wtf is this literal? a projection?
d,d merge     (`a`b!0 1),`b`c!2 3 -> `a`b`c!0 2 3
X_d drop keys `a`c_`a`b`c!0 1 2 -> (,`b)!,1
 $x string    $(12;"ab";`cd;+) -> ("12";(,"a";,"b");"cd";,"+")
s$y cast      `c$97 -> "a"   `i$-1.2 -> -1   `$"a" -> `a
s$y int       `I$"-12" -> -12
i?x deal      -3?1000 -> 11 398 293 /guaranteed distinct
 @x type      @1 -> `i   @"ab" -> `C   @() -> `A   @(@) -> `v
 .S get       a:1;.`a -> 1   b.c:2;.`b`c -> 2
x.y apply(n)  {x*y+1}. 2 3 -> 8   (`a`b`c;`d`e`f). 1 0 -> `d
--------------------------------------------------------------------------------
\`
Special symbols:
   `j?C parse json   `j?"{\"a\":1,\"b\":[true,\"c\"]}" -> `a`b!(1.0;(1;,"c"))
   `k@x pretty-print `k("ab";2 3) -> "(\"ab\";2 3)"
   `p@C parse k
 `hex@C hexadecimal  `hex"ab" -> "6162"
 `pri@i primes       `pri 20  ->  2 3 5 7 11 13 17 19
   `x@x fork-exec    `x(("/bin/wc";"-l");"a\nbc\nd\n") -> "3\n" / i have no idea what the syntax is for this nor how it works. from this very specific example, all i can see is that k can execute programs when given their full path, and at least one argument, and a string which is passed as stdin, and it seems that the output must conform to a particular format...? `x(("/usr/bin/grep";"-E";"-o";"x ");"a x bc\nd\n") works but replacing "x " by "x" gives a domain error!
   `t[] current time (microseconds)
`argv[] list of cmd line args (also in global variable x)
 `env[] dict of env variables
`prng[] `prng@I get/set pseudo-random number generator internal state
                     s:`prng[];r:9?0;`prng s;r~9?0 -> 1
        `prng@0 use current time to set state
 `err@C throw error
 `sin@N trigonometry `sin 12.34 -> -0.22444212919135995
 `exp@N exponential  `exp 1 -> 2.7182818284590455
  `ln@N logarithm    `ln 2 -> 0.6931471805599453
`exit@i exit
--------------------------------------------------------------------------------
I/ decode    24 60 60/1 2 3 -> 3723   2/1 1 0 1 -> 13
I\ encode    24 60 60\3723 -> 1 2 3   2\13 -> 1 1 0 1
F': eachprior -':12 13 11 17 14 -> 12 1 -2 6 -3 / swaps then applies
--------------------------------------------------------------------------------
?[a;i;b]     splice
@[x;i;[f;]y] amend
.[x;i;[f;]y] drill
grammar:  E:E;e|e e:nve|te| t:n|v v:tA|V n:t[E]|(E)|{E}|N
limits: 8 args, 16 locals, 256 bytecode, 2048 stack
---------------------------------------------------------------------------------------

looks like there's no way to just pass to a command line without parsing its output.

* "trace" means to print a value without affecting the computation. it's denoted by a backslash preceeded by whitespace. it's useful for debugging.

* note the similarity of `.` & `@` in drill/amend and application: `@` accepts one arg or one level of nesting, whereas `.` accepts multiple. indeed: `"cats"@0 1` returns "ca" while `("cats";"mice").1 0` returns "m", and (10*)@1 2 3 returns `10 20 30`
* multiline comments start with a slash alone on a line and end with a backslash alone on a line

=== tools

==== repl

* `\+` is supposed (by xpqz) to list verbs, but does not; it prints `'nyi`.

=== examples

[source,k]
----------------------------------------
quicksort:{$[2>#?x;x;,/o'x@&'~:\x<*1?x]}
----------------------------------------

. `x<*1?x` picks a random element from sequence `x` then compares it to each of ``x``'s elements e.g. `*1?"hello"` may pick `"l"` in which case `x<*1?x` evaluates to `1 1 0 0 0`. if `"e"` is picked then we get `0 0 0 0 0`.
. `~:\` couples each logical element with its inverse e.g. `~:\0` becomes `0 1`, `~:\1` becomes `1 0`, and `~:\0 1 0` becomes `(0 1 0; 1 0 1)`. how this works: 1. the initial value is always included in the output list; 2. the 1st value that fails the test is also always included as the last element of the output list. thus the output of `~:\0` starts with `0` then `~0` is 1 so the loop continues and flips again, thus producing the starting value `0`, so the loop terminates, having accumulated `0 1`. `~:\1` starts with `1`, then `~1` is 0, so the loop stops, having accumulated the starting value and the 1st failed value.
. `&'` converts logical vectors to integers where `1` is set ("where")
. `x@` indexes into the input sequence

e.g. if we pick `"l"` then `~:\1 1 0 0 0` evaluates to `(1 1 0 0 0 ; 0 0 1 1 1)`, then applying `&'` to that gives `(0 1; 2 3 4)`, then applying `"hello"@` to that gives `("he";"llo")`.

=== technique of coding in k

TODO: consider:

* link:https://github.com/JohnEarnest/ok/blob/gh-pages/docs/Programming.md[common dataflow patterns effectively expressed in k]
* link:https://github.com/kevinlawler/kona/wiki/Idioms[*k3* idioms]

only the following verbs actually concern relation; the rest are arithmetic, type stuff, or special like binding to an identifier:

[horizontal]
.relational quickref
`#`:: count, shape, filter/replicate
`_`:: drop [from end], remove, split at idxs
`?`:: nub, find, splice (ins/del/ovr substr)
`/\`:: join, split
`@`/`.`:: val@idx, or variant of struct with modified val@idx
`/`:: fold, while, converge
`^`:: without
`<>`:: sort
`|`:: reverse
`'`:: interval index / bin search
`&`:: non-0's
`':`:: window

they're approximately listed in the order that i expect, from most common to least common.

==== thinking "array"

the common test for good array code is that you use few adverbs (higher-order fns), and their argument verbs (functions) are small. in many langs, control flow devices are part of the language. in freer langs such as factor, they're simply higher-order functions. in k also, they are higher-order functions. this is good, because now we need only this one rule to avoid both adverbs generally and control flow particularly. avoid nesting. verbs are flat; adverbs are not. one may freely use verbs, but adverbs must be used wisely. as much as possible, *put verbs on the right of adverbs, not on the left.*

TODO: put this fact in a good section: "encode" with "where": "encode" maps permutations to indices. each permutation is 0...n, i.e. a base n-number. encode is a polynomial/linear equation, too, then, b/c it's `+/d^n`. odometer (`!`) represents cycles and modular arithmetic. modular arithmetic approximates a sawtooth wave. it can (though i'm not sure that it ever should) represent nested loop iterations, too: e.g. `!2 4` represents an outer loop runnig for two iterations and its inner one for 4 iterations. this generalizes the nested-`for` control flow pattern from a builtin language feature to a 1st-class map from "iteration index" to iteration value. operations on the result of odometer is equivalent to a `for` loop none of whose "header" subexpressions are mutated by/in its body. odometer is also multidimensional indices. all these are the same thing as regrouping [counting]. get to the (r-1)th digit, then incrementing regroups i.e. increments the next most significant digit. this generalizes modualar arithmetic by endowing a regrouping context. odometer does not handle mixed radix. compare ```+!14 3``` to ```(3\)'!14```. the former is [0,14) zipped with [0,3). the latter is the first 14 naturals expressed in base 3. ```+!4 3``` equals ```(4 3\)'!12``` i.e. iota with encode generalizes odometer to mixed radix. *more generally is the group theory thing that the natural numbers can code anything.* array langs are particularly apt with this! (TODO: i mention this same thing right after the folling example; clean that up)

this loop prints the map from input index `i` to each iteration's output value:

.test.c
[source,c]
----
#include <stdio.h>
#include <math.h>
int main(int argc, char** args){
  int i;float j,v;
  for(i=0,j=i;i<12;i++,v=(float)i*1.7,j+=v)
    if((int)truncf(j)%2==0) printf("%i\t%f\t%f\n",i,j,v);
    else                    printf("%i\t-\t\t-\n",i);
  return 0;
}
----

.`cc -lm test.c && ./a.out`
-------------------------
0   0.000000    0.000000
1   -           -
2   -           -
3   10.200001   5.100000
4   -           -
5   -           -
6   -           -
7   -           -
8   -           -
9   76.500000   15.300000
10  -           -
11  112.199997  18.700001
-------------------------

the lines with hyphens are those where those indices map to nothing. alternatively they could be said to not be in the map. in c, the map is produced by iteration, and (i,j,v) is computed for each iteration. we could say that `i` is the index and the map maps from `i` to `print(j,v)`. `print` can be replaced by any action/function. we could instead say that it's a map from `(i,j)` to `v`, or to `(j,v)` or whatever. this is the case because `(i,j,v)` is a relation [sql or prolog] i.e. that it can be indexed by any subset of its values to return the whole set of values.

i express it in k:

[source,k]
------------------------------
j:+\v:1.7*i:!12
m:i!+(j;v)
`0:(\t/)'$i,'({~2!_x[;0]}#m)@i
------------------------------

prints

-----------------------------
0   0.0    0.0
1   0n     0n
2   0n     0n
3   10.2   5.1
4   0n     0n
5   0n     0n
6   0n     0n
7   0n     0n
8   0n     0n
9   76.5   15.299999999999999
10  0n     0n
11  112.2  18.7
-----------------------------

notice that in k there are many easy ways to build-up the map, since i'm dealing exclusively with data and not at all with control flow. i express the loop as a dictionary from `i` to `(j,v)`, filter by the values, associate the indices with the values all as a table, then format and print. the point is not in the elegance nor how exactly i express the map; the point is that any loop can be expressed as a map from iteration number to iteration value, and that maps are data and so can be composed, edited, etc as freely as data can be, whereas loops are not 1st-class objects and are not nearly as mutable nor composable.

this also demonstrates the scan/while equivalence discussed later in these notes. notice how `j` was computed as a scan; emergent loop values (here, `j` being mutated—incremented by `v`—on each iteration) are computed & stored as scans, then used in a later array operation.

*generally we translate control structures to maps from iteration number to that iteration's output. loops are maps from iteration number to output, and conditional branches are maps from branch number to body.*

''''

start with the minimum needed to code anything: 0 & 1. this generalizes in two equivalent directions: becoming a sequence of 0's & 1's, or staying one number and increasing in maximum value i.e. 0, 1, 2, 3, ...to infinity. of course any programmer knows that they're the same: 1110 bin is the same as 14 dec. they should be seen as the same: it's just value itself, expressed by a sequence of digits; the digits' meaning is exclusively determined by the radix.

we borrow the group/galois theory brilliance that anything can be represented by natural numbers, then combine it with the fact that all natural numbers are equivalent to sequences of arbitrary-radix numbers which is equivalent to modular arithmetic, combined with that all programs are maps, then suddenly everything is a map from naturals to outputs, and apls/k excel(s) at working with that structure!

TODO: in the name of arithmetic, push for powerful arithmetic being used in programming e.g. clifford algebras, convolution matrices, polynomials, en/decode. these conspicuous primitives obviously, greatly-should be discussed thoroughly so that people can actually USE THEM!

===== mapping/association

* we don't map; it's implicit. for 1:n, it's implicit via broadcasting else explicit via `/:` or `\:`. for 1:1, it's implicit else explicit via `'`
* rather than writing loops, we use scan or fold. see the following section for discussion & examples
* symmetric relation is broadcasting. asymmetric relation is pointwise association. asymmetric relation generalizes pointwise. k makes it easy to merge relations e.g. numbers divisible by 3 or 2: `~~+/((3!);(2!))@\:!10`.

example #567 from _k3 idioms_ is worth study. it's like link:https://code.jsoftware.com/wiki/Vocabulary/curlyrt[j's `}`]: it uses selection vector `g` to determine which row to extract from:

[source,k]
----------
x:`hot`white`short`old
y:`cold`black`tall`young
g:1 0 0 1
(x,'y)./:(!#g),'g
`cold`white`short`young
----------

===== exploit common arithmetic relations

numbers have many symmetries & asymmetries. we can exploit these greatly. not only do they generalize well, but they're terse and fast because arithmetic is fast, and on digital processors, integer arithmetic is especially fast.

alternation:: pow(-1,n). don't use it, though, since it isn't directly accessible in k6, and it's floating point. use `(n!)` instead, which generalizes and uses integer arithmetic.
replace `x` by `y` where `p(x)`:: `x+y*px`
choice:: `choices@f[x]` e.g. `("sell";"buy";stay)@sgn` where `sgn:((x>0)-x<0}`

using (multi)linear algebra to express computations is very good when applicable.

one of apls' greatest properties is that they rely greatly on arithmetic to determine selection vectors, rather than relying on higher-order functions & predicates, which are inefficient, inflexible, and must be defined. no one will ever design any system as perfect as arithmetic. when programs/logic are encoded as matrices, then _programs_ are enabled all their power: empty elements, broadcasting, boolean algebra / set union, negation, intersection.

===== storage

store a list of records. this way you can use fold, stencil, etc to properly relate sequenced elements. consider the following stock candle operations:

[source,k]
----------
/    H  L  C  V  / pretend that these are valid hlcv values
dat:(28 9  16 12
     10 12 14 18
     9  10 18 16)
>':dat / compare each candle's hlcv to its prior
(0 0 0 0
 0 1 0 1
 0 0 1 0)
(|/>)':dat / candles any of whose hlcv was higher than its predecessor. returns same-length vector; 1st elt is 1 as a default value b/c the 1st elt has no prior.
1 1 1
(|/>)':dat[;0 2] / same, but consider only high & close
1 0 1
----------

to stitch tables (to add attributes to a list of records): `X,'Y` or `+(X;Y)`, which are equivalent up to distinction:

[source,k]
-----------------------
X:3 4#!10
Y:3 4#24+!12
X,'Y
(0 1 2 3 24 25 26 27
 4 5 6 7 28 29 30 31
 8 9 0 1 32 33 34 35)
+(X;Y)
((0 1 2 3;24 25 26 27)
 (4 5 6 7;28 29 30 31)
 (8 9 0 1;32 33 34 35))
-----------------------

let only your program's specifications' relations determine how you relate data. in k et al apls, relating data effectively means: 1. whether data are put into a common array; and 2. the composite array's shape; and as in all computational models, 3. coupling data as args of a (2+)-ary relation/fn. for example, if you relate two vectors, then don't put them in a list, since that's redundant; verbs already relate two vectors. so e.g. do `x+y` instead of `+/(x;y)`. don't group `x` & `y` together just because they _can_ be related. a good test of whether to de/couple data is syntax. in the above hlcv example, `>':` is very *terse and implicitly entails all of hlcv.* if i wanted to identify only particular columns, then i must add more syntax, namely in the above example, `[;0 2]`. if instead i wanted to commonly apply verbs to attributes without regard to each other, then it'd be nicer for me to not put them into a common table; i'd rather do `h-l` than `-/hlcv[;0 1]`, and indeed, beautifully, the syntax's verbosity reflects data storage & flow flow elegance. don't strive to de/couple your data; let the coupling naturally reflect the operations that you'll apply to the data.

===== know how morphisms can be rearranged/delayed

* we can factor actions (side effects) out of array ops (see the while example below)
* make stencil operations small & simple. it avoids redundant computation; you don't want to compute a hefty stencil `H` over `4 H':!10`, because that'll compute `H` 4 times for 5 and 6. `4':!10` has 28 items. also it enables you to run any number of variably-sized stencils on one array, and decouples computations from any one stencil. try to avoid stencil; there are usually more elegant, more efficient solutions. for example, moving average can be done as a fold/scan: `{(((y-1)_a)-0,(-y)_a:+\x)%y}`.

==== shape, maps, and conditionality

TODO: merge §conditionality

shape is useful for mapping. shape replaces higher-order functions (and probably `cond`). consider:

[source,factor]
---------------
{ "racecar" "nope" "bob" } dup [ >upper ] map 2array
---------------

and

[source,k]
---------------
0 32 {`c$y-x}'2 3#("racecar";"nope";"bob")
---------------

both return

------------------------------
{ { "racecar" "nope" "bob" }
  { "RACECAR" "NOPE" "BOB" } }
------------------------------

this equivalence relies on identities; in the factor code, there's an implicit `[ ] map` that's missing because it does nothing. however, in the k code, that is seen as adding 0. the factor code is nicer in this case, but this situation generalizes to `nmap` in factor, and a matrix with _n_ rows in k.

given that we have the empty program—called `::` in k—which is an identity under application,...idk, some theorem about numbers and programs being some algebraic structure so we have a sort of equivalence and this makes programs expressible as multidimensional arrays of numbers and we can manipulate the programs just as elegantly/powerfully as "../../coding.adoc" tells, such as representing each k operator by a length 5 bit sequenece, and the rest of the machine word's bits can be used as a bit set where each position being on or off corresponds to some algebraic property being satisfied or not.

then again, a less algebraic perspective is to just say that ```{(4,#x)#x}``` is akin to `ndup`, and `map` is implicit in k unlike in factor. we could easily just do `(::;{`c$x-32})@'2 3#("racecar";"nope";"bob")`.

you can do some interesting things with shape, that basically has to do with modualar arithmetic where the modulus is the input sequence's length. modular arithmetic relates to waves being in/out of phase, or rotation e.g:

--------------
2 6#1 6 5 2 4
(1 6 5 2 4 1
 6 5 2 4 1 6)
--------------

for `y>0`, `rot:{y_(y+#x)#x}`.

===== looping

if you want to iterate through an array with persistent state, producing an array, then use a scan adverb. consider the following factor code:

[source,factor]
------------------------------------------------------------------
! 1 if cross above, -1 if cross below.
: cross ( s1 s2 -- {above/below/f} )
  [ - sgn ] 2map                                             ! (1)
  [ first ] [ rest-slice ] bi                                ! (2)
  [ [ f ] [ 2dup = [ drop f ] [ nip dup ] if ] if-zero ] map ! (3)
  nip f prefix ;                                             ! (4)
------------------------------------------------------------------

`(2)` breaks the seq into a state and a seq. `(3)` is the heart of the computation. it replaces runs of the state by `f` but if the iter elt is not the state, then the state is set to it. the state is thus not updated on each iteration. i can't use `accumulate*` (scan) because it necessarily uses the accumulated/returned value as the "prior" value in successive iterations, which is not the case here. if we express the state changes as a scan then there will commonly be runs of one value e.g. if the state is updated on the 4th iteration, then the first four elements of the scan will be `s s s s'`. so, naturally in the k version, i'll express the computation as a scan to accumulate the state, then a map which corresponds to the map over the sgn seq:

i translate the stateful scan: ```{:[y=0;x;x=y;x;y]}```. ```:[x=y;x;y]``` is the identity function! so the actual translation is ```{:[y=0;x;y]}```, which is arithmetically expressed as ```{y+x*y=0}```. you can reason about that methodically as ```*``` being and/intersection/product/implication, and `+` as being coproduct/or/else. the rest is easy. the whole repl session follows:

[source,k]
---------------
sgn:{(x>0)-x<0}
a:10 11 12 16 18 14 12
b:2  3  7  19 18 14 11
sgn a-b
1 1 1 -1 0 0 1
{y+x*y=0}\a-b
1 1 1 -1 -1 -1 1
/ next, i clearly want to identify the places where the value changes; that's =':
=':{y+x*y=0}\sgn a-b
0 1 1 0 1 1 0
/ whoops. that's not right; i want the inverse:
~=':{y+x*y=0}\sgn a-b
1 0 0 1 0 0 1
/ ok, but now i want to retain the original values; this is my mask. time to apply it to the original.
{x*~=':{y+x*y=0}\x}sgn a-b
/ set the first to 0, because it's always 0. pretty much the same as the factor version's line (4)
@[{x*~=':{y+x*y=0}\x}sgn a-b;0;:;0]
---------------

and done! the actual definiton:

[source,k]
----------
:cross:{@[x*~=':{y+x*y=0}\x;0;:;0]}sgn@-
{@[x*~=':{y+x*y=0}\x;0;:;0]}{(x>0)-x<0}@- / notice the sgn fn's lambda literal definition inlined!
----------

without the `@` between `sgn` & `-`, trying to evaluate `cross[a;b]` gives ````nyi```, which i don't understand. i'd expect that, worst case, `-` would try to use the lambda as its left arg and throw a type error. anyway, whatever. simply restricting my implementation to k primitives & arrays revealed a better algorithm!

.short-circuiting

* return the same value twice when using fixpoint
* modify the output (or another variable) s.t. it fails the "while" condition
* trim then iterate e.g. to effectively accumulate, stopping when sum>30, and printing the accumulator on each iteration: ````0:${#[1+*&30<x;x]}@+\6 11 16 21 50```. compute all the accumulator values, the earliest index whose element fails "while"'s predicate, add 1 to it, and take that many elements, convert them to strings, print them. this example importantly demonstrates two things: 1. terminating a fold early is equivalent to completely looping through its trimmed scan; and 2. performing an action for each iteration is equivalent to performing it for each element of the scan. these are the case only when (what would be) while's predicate does not entail io. in this example, the loop body entailed io, but the predicate depended only on the accumulator, which is of a referentially transparent dataflow. unless there's operator fusion, this means more looping, which is less than ideal, but because array lang primitives so strongly suggest this pattern, the interpreters should fuse into one loop.
* literal short-circuiting via "while", e.g. accumulate until sum>30: ```{30>*x}{(x[0]+x[1;0];1_x[1])}/(0;6 11 16 21 50)``` returns `(33;21 50)`. the fact of storing multiple data is kind of ugly compared to a fold that supports short-circuiting. for more complex loop states, you may want to use amend/drill or the "unpack" syntax.
  ** "while" is necessary only if your loop predicate relies on or incurs side effects, including any that may be executed in "while"'s body e.g. ```(40>){`1:"> ";`I$-1_1:`}\0``` to read-in numbers until you enter one that's greater than 40; here the predicate acts on an object gotten from io.

===== debugging & observation

* use trace ` \` to print arbitrary intermediate values easily
* use scan `\` to print intermediate values of a loop
* use `,` as your verb that you pass to adverbs. because it has rank infinity, it makes behavior clear compared to atomic verbs.

==== (avoiding) cond/jumps

first, if you're unfamiliar with the term "hot code", see the following:

. <https://www.youtube.com/watch?v=bVJ-mWWL7cE>
. <https://www.youtube.com/watch?v=r-TLSBdHe1A>

for speed and more natural program expression.

`cond`/`if` itself is not bad; rather, jumps bad because they retard execution perhaps in their own right, but namely because they're typically conditional, so the program loader must predict which branch will be taken, to load that block of code well in advance of its execution, so that we aren't waiting to load code upon each conditional jump.

i'm unsure whether `if` is slow for stack machines. if `call` [eval] is slow, then `if` is also slow simply because it entials `call`. `if` for a stack machine is linear; it's conditional `nip` or `drop` followed by `call`, and `nip` & `drop` are fast.

generally branching may be expressed as a map from natural numbers to programs (TODO: OR PREDICATES/LOGICAL VALUES?). this model describes `cond`, which generalizes `case`, which generalizes `if-then-else`, which generalizes `if then`. the "case" form can be seen in haskell: `case True -> branch1; False -> branch2;`. `if` without `else` is the same as using the empty program for `branch2`. when predicates are expensive to compute or entail side effects, then nest the maps e.g. instead of `p1->prg1;expensivep2->prg2;else->prg3`, do `p1->prg1;else:(expensivep2->prg2;p3->prg3)`. `else` does not need to be a semantic device; it can be a particular value such as a representation of infinity, or the maximum integer size, or `-1`, which is not a natural number, but is easily expressed by 2's complement. btw, such isomorphisms as this should be studied algebraically. anyway, we evaluate value(s) against predicate(s) to ultimately derive the branch number to take. there are many fine ways to do this: pass a datum to many preds in parallel, unioning their numbers into a set, then choosing the set's minimum branch number. there are solutions specific to parallelization, such as by vector ops or multiple agents running independently; and there are solutions for single-thread/agent or multi-thread all of which must sync on a mutex. design for your purpose: speed or ergonomics. remember that conditional branching is, like all programming, just mapping—just `filter` i.e. predicate intersection. `f(x)` ("f:fn of x") is `f[x]` ("f:map at x") which is a specific case of `xs [ f ] map` since atom `x` is equivalent to singleton `{x}` which generalizes to any set. if we enable `f` to map to an empty value, and assume that empty values are omitted from output, then it's `map-filter`, such as is done in prolog since predicates return values and pattern-match on their inputs, and pattern matching is filtering.

array langs are very apt for associating arguments with predicates: pairing an atom (arg) with a vector (of predicates) broadcasts, and a vector of args with a vector of predicates associates pointwise. if you use `cond` to select values rather than computations, then just run all the computations and use masks to filter aka select values.

===== algebraic consideration from 1st principles

predicates, types, logical values, maps, and the fact that all computation is relations i.e. grouping data into sets, where any datum may belong to multiple seqs/sets.

we consider coproduct & product. these are seen equivalently across types, predicates, sets, and the boolean ring, ℤ/2. consider `(∩ (HashTable k t) t)` which states that variable `t` "satisfies a property" i.e. "matches/satisfies a predicate" aka has a non-null set intersection. adopt the habit of knowing types, (1st-order) predicates, set theory. abstain from higher-order logics; they're prettier at the cost of being more constrained, complex. work with data, not programs. metaprogramming is a mistake; it suggests that code should be considered as data. what ought to be done is avoiding code entirely, using only data. this is what prolog does. true, prolog supports macros (static metaprogramming), but that merely enables custom notations (dsls), which is entirely divorced from program logic.

fixpoint is convergence to idempotency, a property common to boolean rings.

booleans concern satisfaction/sufficiency, difference. these generalize to sets, wherein they're expressed as membership and set difference. 0 & 1 generalize to naturals, which may represent set cardinalities. viewing conditionality in terms of predicates, integers, sets, is refreshing and empowering, because it means that we may use nothing more than sets to define conditionality. given that all other coding is exclusively sequences/sets, this makes conditionality just another aspect of common data ops.

''''

there is a disconnect between theoretical & actual efficiency: where `cond` can save computation, the computation is still slower than doing more-but-faster computation. habitualize looking for fast computation, not fewer computations or fewer data! *code per your specific hardware*, or if you know that you're bound to a vm, then code for that virtual hw. know your hw's primitives, and which are fastest: e.g. on x86, `xor` is faster than `mov`, and avx kicks ass; for ngn/k, `=:` is slow compared to use-case-specific alternatives; in c, malloc is slow. obviously there's some overlap among these, but you get the idea: don't just consider number of ops, or whether you're using primitives; use _fast_ primitives, and use _fast_ ops.

jumping is needed sometimes. in these cases we simply accept its requirement. in most cases, though, conditionality can be expressed without jumps, namely through the single other system afforded to programmers: bit sequence arithmetic. inherently, to operate on a vector is to effectively iterate over its elements, applying an operation on each iteration. this is the same as "do `action` _n_ times", since the sequence length is `n` and constant throughout the iteration. anything done a static number of times can be expressed as a sequence of inline statements, which avoids jumping:

`for(i=I;i<N;i++)action(i);` re-expresses as any of:

* `N I - [ i set action ] times` e.g:
  ** `7 3 dup i set - [ i get . i inc ] times` (concatenative version of stateful increment)
  ** `3 7 over - [ dup . 1 + ] times drop` (stack machine version; `i` tops the stack instead of being in a register.)
* `action(I); action(I+1); ... action(N-1);`

ultimately when this compiles to opcodes, the cpu should easily load the next chunk of instructions without prediction, so long as it has support for repeating a block of instructions a static number of times.

natural numbers generalize booleans. ℤ is effectively equivalent to ℕ.

`0` & `1` work in the linear algebra sense: `{x+y*px}` effectively conditionally adds `y` to `x` where `x` satisfies predicate `p`. `+` generalizes to any function that maps 0 to itself.

cpu opcodes e.g. simd/avx, or just gpu primitives, are our best friend. they natively support very many operations on large logical vectors, such as counting the number of ``1``'s or ``0``'s, or the number of ``0``'s before the first `1`.

when we use bitmasks instead of naturals, then we can leverage native logical vector operations. even better, lvecs, like all seqs, are implicitly sets; thus we can e.g. compute multiple predicates simultaneously (via simd) then union them and effectively do ```*&:``` on it i.e. get the earliest satisfied predicate. the kicker here is that cpus have opcodes that do ```*&:```.

some operations can avoid loops by using other primitives e.g. ```*``` is iterated `+`, and `pow` iterated ```*```. usually they're not direct substitutes, since seq vals are practically never all the same, but certain patterns may be found. the multiple methods of calculating the fibonaccis is a good example: it has closed-form expressions like binet's formula, or the even-simpler `GOLDEN_RATIO swap ^ 5 sqrt / round`.

.particular examples for my study

* rotate: `{,/|![#y;0,x]_y}`
* set all to 0 after 1st 0: `&\`
* count number of consecutive 1's: `{y+x*y}\`
* prettyprint a dict: ```p:{(|/#'x)$x};`0:{(p@$!x){x," ",y}'{:[~100>#x;(97#x),"...";x]}'p(.x)}```. this actually has a bug in that the abbreviation should be done in `p`.

oisín kidney's trie impl that fits in a tweet:
--------------------------------------------------------------
type Trie a b = Cofree (Map a) (Maybe b)
string :: Ord a => [a] -> Lens' (Trie a b) (Maybe b)
string = foldr (\x r -> _unwrap . at x .
                        anon
                          (Nothing :< mempty)
                          (\(v :< m) -> null v && null m) . r)
               _extract
--------------------------------------------------------------

how to write this in k?

what lesson can i learn from my following tweet?:

once i wanted to connect to named kak session if one exists. i intially wrote

[source,sh]
--------------------------------------------------
p=(ps -e | sed -n 's/^kak -s ([^[:space:]]+)\1/p')
if -z "$p"; then kak -c "$p"; else kak -s 1; fi
--------------------------------------------------

but then realized i could just do `kak -c 1 || kak -s 1`. what lesson can i learn from this?

.functional `cond` demonstration

factor-style "cond":

[source,k]
-----------------------------------------------------------
cond:{
  args::x
  assoc::y
  (({~(x[0;0]).args}(1_)/assoc)[0;1]).args / "while" short-circuits. it's "while not head pair's predicate, behead". then apply head's body to args.
}
cond[5;(((7=);{"seven"});((5<);(10*));((~2!);{"even"}))]
-----------------------------------------------------------

instead of handling an "else", it returns the input as-is if no case matches. i wrote this only to show that k is as capable as lisp/factor; there's no reason to not use k's built-in conditional construct.

