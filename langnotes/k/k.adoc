= k
nic chandoke's notes
:toc:

.spring 2025: factor vs k

i like the stack _per se_. i less care about the brevity or non-redundancy that combinators provide, though they're nice, too. mostly, though, i just like that i can put things on the stack, each datum on the stack being its own concept/object, which, because it's on the stack, can be used anywhere; it's like easy, efficient global namespacing, but without the names. consider the `factorprefix` or `solve-quadratic` examples in the factor docs. it's just nice to see data transform one step at a time, and branch off into multiple computations at certain points of execution.

''''''''''''''''''''''''''''''''''''''''''''''

k3 & k6 much differ. this document details k6 & ngn/k yet. a section comparing k3 & k6 will be added. it's been implied that k3 & k4 are practically interchangeable, as are k5 & k6.

.terminology & notation

* i'm using prolog arity notation: an operator followed by a slash followed by arity e.g. `./3` is the `.` verb as it acts when given 3 args.
* somewhat borrowing from forth/factor, i use the word "word" to refer to k tokens without regard to whether they're verbs, adverbs, nouns, gerunds, or whatever have you.

== about k

* k is a very good example of the genius that comes from refining a language over time without regard to backwards compatibility
* canonically, tiny language implementation, built for speed & brevity, and rebuilt from scratch often
* especially overloaded; even an operator with a given arity may have many entirely different definitions depending on its arguments' types.
* nomenclature is same as j

=== k vs j

k is categorically better than j:

* vectors instead of arrays
  ** no boxing
    *** indexing at depth is equivalent to multidimensional indexing, like j's `{::`
  ** no rank system; simply use adverbs to iterate
  ** 1st-class functions can be in vectors plainly. no particular system like gerunds. you can stright-up do `(*{4+x},3 4)@64`
* dicts (i'm unsure if these are inferior to vectors of arbitrary-type/shape elements. at least dict-fn-vec equivalence is good.)
* tables (ngn/k)
* namespacing is dead simple. just `\d NS` to change the namespace to `NS`, and prefix its vars with `NS.`; or `\d .` to set the global namespace
* fewer, overloaded verbs is better than more verbs many of which have a colon, which is harder to read
* `#/2` combines j's `$/2` and j's `#/2`
* verbs can actually be defined with more than 2 args
* more-sensible verbs both by notation and functionality e.g:
  ** `f\` instead of `f^:a:`, which is a more consistent mnemonic and syntactically plainer
  ** `#` instead of `{` & `}`
* there's no function composition in k...not sure if that's better or worse. j's fncomp was good but flawed; i'm unsure whether such things should be boldy discarded, or retained despite that they only offer convenience rather than a robust programming code.
* k is easily learned in a weekend
* because j verbs aren't 1st-class, j has a special tacit dsl. b/c k verbs are 1st-class, there's no need for a dsl; we can just define combinators such as `fork2:{[f;g;h;x;y] g[f[x;y];h[x;y]]}`. that being said, (ngn/)k _does_ have a dsl, described below.
  ** still sucks compared to factor's `bi`, since, by using inline/row-polymorphic combinators, we can access arbitrary depth of the stack (TODO: get an example)

.differences from j

* user-defined k verbs can have only one valence. this asymmetry against builtin k verbs is odd but not necessarily bad. then again, user-defined k verbs can have up to 8 args.
* in k's grammar, all the following are nouns: parenthesized exprs, lambdas, identifiers.
* no modifier trains, rank system, boxing, framing fill, &c
* j's `@` & `&` (bind/curry) are implicit in k.

k's trains differ from j's:

.k trains
[options="header"]
|===========================================================
| name                 | juxtaposition seq | definition
| "projection" (curry) | N V               | `(xf)y` <=> `xfy`
| composition          | N/V ... V         | `(fg...h)[x;y]` <=> `fg...(xhy)`. `(fg)xy` cannot be applied in-place e.g. ```(5+)(*)[6;7]``` is valid (47) but ```7(5+)(*)6``` is a type error. example from link:https://ngn.codeberg.page/txt/tacitjk.pdf[ngn's pdf]: ```(1-_%*)[x;y] <=> 1-_%*[x;y] <=> 1-_%x*y```
|===========================================================

projections are denoted as m-exprs with args missing e.g. `-[1;]` to mean dyad `-` with left arg bound to `1`. you commonly see projections of dicts or arrays, too. for arrays, all elements of omitted axis are retrieved. for dicts, . notice that m-exprs support projections but `.` does not. dict projection example: ```(`z`y!((`a`b`c!"jkl");(`a`b`d!10 20 40)))[;`b`d]``` returns ````z`y!("k ";20 40)```.

NOTE: projections cannot be the leading items in a train. e.g. `(_%[;12])` is illegal. `(_%[;12]@)` is what you want.

these terms are used in ngn/k's quickref.

NOTE: k trains are ambivalent *when used inline* e.g. `(1+2*!)10` returns `1 3 5 7 9 11 13 15 17 19` but `f:(1+2*!);f 10` returns `1+2*![10;]`. `(1+2*!)[,3;,10]` returns `(,3)!,21`

* hook as a k train: `f/1 g\`. `1 g\` produces a 2-vector `(x;g x)`; then fold `f` over (insert between) those 2 args.
* fork as a k train: `g/(f;h)@\:`. it applies each of `f` & `h` to the argvec, returning a 2-vector, then folds `g` over (inserts between) those results.
* `({10+x};(20+))@\:15` returns `25 35`

verbs in j but not k:

* key (group by): `{(!x),'.x}@="hello"`
* rotate & shift are in k3 but not k6. rotate: `{,/|![#y;0,x]_y}`
* k has no support for complex numbers? kinda whack. `%-2` gives `-0n`.
* no `E.`. in k: `E:{((#y)':x)?y}`. (ratpack) parsers are better, though, since they generalize from mere equality to powerful patterns.

=== implementations

i'm going to consider this only after i become familiar with ngn/k. i'll use it as my _de facto_ k before i choose another, just because it's said to be good, and it's accessible, easy, small. it's perfectly sufficient for using and learning k. i can choose practical versions later, after becoming familiar enough with k to immediately appreciate nuances among implementations.

[options="header"]
|=======================================================================================================
| name                                                 | impl lang | k ver | notes
| link:https://github.com/ktye/i[i]                    | go        | ?     | -
| link:https://anaseto.codeberg.page/goal-docs/[goal]  | go        | -     |
| link:https://codeberg.org/ngn/k[ngn/k]               | c         | 6     | unmaintained since jan 2024
| link:https://github.com/kevinlawler/kona/wiki[kona]  | c         | 3     | 1st open k, so good wiki
| link:https://t3x.org/klong/klong-ref.txt.html[klong] | c         | -     |
| link:https://github.com/zholos/kuc/[kuc]             | c         | 5     |
| link:https://github.com/JohnEarnest/ok/[oK]          | js        | 5,6   |
|=======================================================================================================

=== k's goodness

small, simple, powerful language. easy to learn quickly. small implementation code. k codes are short. refactorable, flexible, dynamic, and there are no language constraints that actually constrain you—that you have to hack around. everything you need, nothing you don't (except `=:`). as regular/simple & dynamic as lisp, but without the woes of applicative programming (e.g. needing to put vars everywhere, cumbersome refactoring, and dealing with nested namespaces); and even briefer than other apls, with all their array power plus more, since its single data structure is most elegant. it's easily the most elegant coding system i've seen. other cool perks:

* freakishly fast
* good notation for writing on paper, or memorizing, or just coding in. nice that you can see all your code at once without sacrificing readability.
  ** so terse, in fact, that we can hardly do theoretically better, even using multidimensional arbitrary graphics to represent programs.
* hardly needs libraries. usually we use idioms. see the below section on inline programming.
* you don't have to care about how you store your data. all ways are equally easy to use, terse to code, and fast to compute over.

*an important reason to use k* is to become familiar with its primitives: sets, seqs, maps. k is all the good primitives and structures. regardless of whether you use k, everyone should master designing k programs so that they can use those designs in _all_ programming, hopefully in a tacit, readable, metaprogrammable, virtual-operation language. it's also small enough (20 prims, and short code) that you can reason about it in your mind.

==== k vs factor

[options="header"]
|================================================================================================================================================================================
| k                                                           | factor
| idioms & sequenced data manipulations                       | composed higher-order fns
| fns are mostly defined of primitives, not other fns         | words are defined in terms of _very_ many other words
| programs (λ's) don't nest. programs' asts' max depth is low | nesting quoted programs is ubiquitous
| fast                                                        | usually decently fast
| interpreted                                                 | compiled (interpreted is prohibitively slow)
| elegant, terse syntax                                       | simpler, more-regular, but less-elegant syntax. definitely less terse in text, though comparably terse in tokens.
| simple program model                                        | simple program model
| programs as data, and function arrays, rather than m.p      | metaprogrammable
| one data structure                                          | _many_ separate, uncoordinated data structures
| few, ambivalent fns                                         | many fixed-valence fns
| flat scopes                                                 | scopeless, except that each vocabulary is a flat scope
| surprisingly, totally readable after a week                 | immediately totally readable
| mostly concatenative (mostly read rtl)                      | mostly concatinative (totally concatenative except when using `locals` or `fry`)
| statements read ltr, yet function application reads rtl     | everything ltr
| totally dynamic                                             | static definition & stack checking. can't practically dynamic redefine words.
| fixed syntax                                                | supports defining reader macros
| usually unary or binary fns, often with one arg curried     | same
| instead of combinators, associate data & fn arrays & `v/`   | stack shuffling e.g. `dup g f` for `f(y,g(y))`, and combinators like `cleave` & `spread`
|================================================================================================================================================================================

* in both k and factor, function application and composition are the same; `@` (i.e. juxtaposition) is function composition or application
* refactorability is practically equivalent for k & factor. k code can elect to not use globals, and factor can use dynamic variables. both can use io anywhere. in both langs, pure code without globals is mindlessly refactorable.
* k would benefit from having some combinators. k wouldn't really benefit (insofar as code elegance) from using a stack, however.
* i thought that k would be hard to read, due to its overloaded verbs whose functionality is determined by argument type and count, conditional ltr vs rtl evaluation, adverbs, and the potential of large, parenthecized left arguments. i feared having to look ahead of each verb to see its argument, if any, and evaluate it for its type, to determine its functionality. however, the _potential_ to write bad k code does not make k code bad—just like with factor. a good k coder avoids parentheses by reordering arguments, using mexprs, breaking into multiple lines & variables, using projections or compositions, or factoring the code into arrays of functions paired with arguments. because there are no conjunctions nor modifier trains [j], adverbs are trivially parsed: just keep reading leftward until you hit a verb, and they're left-associative. i found myself efforlessly becoming fluent in k within a couple weeks—reading, writing, refactoring, reasoning in terms of the primitives. it felt good, and coding in k continues to feel good. simply, everything's easy to code in k, and k code is easy to parse & understand. at first, though, with me coming from factor yet having already used j, k looked unreadable to me. the easiest way to learn to parse k is to just try reading it without regard to any technique; let your eyes automatically pick-out clear subexpressions, then look at the rest. having rainbow parens or the ability to select delimited expressions (`m` in kakoune) is often helpful. factor's whitespace-delimited words and quoted programs looked very clean to me, and by contrast, k looked like line-noise—for a few days, and then my brain got good at parsing k and factor looked bloated a.f. there are few syntax patterns that you must "get used to" in factor (`[ ... ] [ ... ] if` is one of them), and there are many patterns that you see in k (e.g. `x[;n]`) but you _do_ get used to them quickly.

ultimately i've decided that k beats factor handily:

. idioms & data are better than defining & invoking higher-order functions
. arrays beat any other structure, and the fact of being able to use them for everything, especially with such excellent primitives, is incomparably good
. k is very easy to use. no compilation, no library system. dead simple, stupid.

the competition between k and forth is much closer.

===== applicative vs stack

relating whole to various parts: the following pads strs to have equal length: `{(|/#'x)$'x}`. it's `$` left-curried with the maximum length, mapped over the input array. in a stack lang it would be `.#'|/$` (where `.` is `dup`) which is easier to reason about how to code from scratch, and shorter, and more readable. this is the reduction of the literal factor code `dup [ length ] map maximum [ 32 <padded-tail> >string ] curry map` once we replace `length` by `#`, `maximum` by `|`, `32 <padded-tail>` by `$`; and remove `map` because we assume an array paradigm, and remove `curry` because it's no longer necessary once we remove `map`; and once we assume a parser that restricts which words you can define such that whitespace isn't needed to delimit tokens. i really didn't expect the stack version to even be better necessarily, let alone _that_ much better! guess the stack really does always win.

===== array paradigm

TODO: merge with _§thinking array_ (which appears much later in the notes)

arrays are available in factor of course. however, thinking in terms of arrays is particular, regardless of the language, and this thinking is encouraged by k &al apls. these sections consider what "thinking array" means.

====== multiple simple array operations

the speed & ease of using array ops, and the relative difficulty of doing anything non-array, encourages us to use these easy methods. consider the task of writing a fn that converts some brownian motion into a simpler, lower-resolution sequence of values sufficiently far from their predecessor i.e. converting to renko, if you're familiar with stock trading. in any non-apl lang, i'd think to use a single fold that has some complex state and returns the desired value. however, in k, it's easier to use a scan which produces increasing numbers where the value is significantly higher, returns the accumulator where it's not significantly different, and returns a number lower where it's significantly lower. then i use `~=:` to mark the places where it actually changes. two loops is not much worse than one, and is astoundingly simpler to reason about and code!

solution in pseudocode:

------------------
renko (z:xs) {
  vec v = singleton(z)
  int u -- renko unit
  for x in xs:
    z=last(v)
    s=sgn(x-z)
    d=iota(floor(abs(x-z)/U))
    v.append(map(\x->z+U*s*x,d))
  return v }
------------------

this pseudocode isn't actually correct, but it's basically right. i translated it into factor then tweaked it until it worked:

in factor:

[source,factor]
--------------------------------------------------------------------
: ¡ ( n -- v ) [ f ] [ [ sgn ] keep [a..b] ] if-zero ; inline ! <iota> that supports negatives, too
: renko ( x -- x ) unclip-slice over length <vector> [ push ] keep
  [ [ last ] [ push-all ] bi-curry
    [ [ [ - abs U /i ¡ ]
        [ tuck - sgn [ + ] [ * u * ] bi-curry* prepose ] 2bi map
      ] compose ] dip compose each ] keep ;
--------------------------------------------------------------------

i translated into factor for two reasons:

. catlangs enable us to easily express programs in reduced, factored form, which allows us to measure programs objectively, consistently, accurately.
. i don't know any other non-apl language that's as decent to use.

anyway, here's how it'd occur to a k programmer to code it: `(*x)+u*¡:'-':_abs (*x)-x` where `abs:{x|-x};sgn:{(x>0)-x<0};(¡:):{(sgn x)*1+!abs x}`. i use `[a..b]` in factor b/c it's a virtual sequence; were i to `map` over an `iota` object, an array literal would be produced. using `[a..b]` with zero twice produces `{ 0 }`, which is not empty. however, in ngn/k, simple arithmetic like adding or multiplying by an iota leaves it in tact as an iota, not using extra memory. because the computation `!0` produces special value `!0` which has 0 length, i don't need to conditionally branch based on whether `x` is zero.

we're prone to quickly coming-up with such solutions in apls is simply that we expect them to look like it; we study patterns of how arrays can code data and how the array primitive operations are used, ultimately leading to idioms & array structures. so when presented with problems, we start guessing about which of these patterns may satisfy, assuming that by simply playing with patterns, with our given knowledge, we'll quickly arrive at a solution. also, at each step of our algorithm, our intermediate values are vectors. everything is vectors, and vector operations are usually not loops. we rarely write complex loop bodies in apls.

to be clear, my point isn't about the _language_; it's about how the language's model & primitives encourage programmers to consider & derive particular solutions. k has a very small set of primitives, so the programmer is _forced_ to use them. the solution that k encouraged us to write can be kinda easily written in factor as well:

[source,factor]
--------------------------------------------------------------------
: ¡ ( n -- v ) [ f ] [ [ sgn ] keep [a..b] ] if-zero ; inline
: renko ( x -- x ) dup first [ swap - abs floor ] [ + ] bi-curry [ u * ] prepose [ map ] curry [ - ¡ ] prepose [ map ] dip 2 clump-map ;
! locals version:
:: renko ( x -- x ) x x first :> h [ h swap - abs floor ] map [ - ¡ [ u * h + ] map ] 2 clump-map ;
--------------------------------------------------------------------

array-based solutions are simpler—less complex. the array model is very limited/strict, as is the set of primitive operators, so of course arraylang code reflects this. most languages are unrestricted, which allows programmers to incrementally develop solutions that all have some similarity, but also uniqueness. haskellers try to mask this duality by simply naming and classifying code patterns, yet the patterns' distinctions and complexity remain. organizing information doesn't reduce its amount; it only makes it easier to understand, not less cumbersome to work with! anyway, as we use codes of lesser complexity (lesser information content) i.e. of higher symmetry/regularity, the difference among languages' ergonomics lessens; the simple solutions are mostly still simply coded regardless of the language. this being said, of course a language should be suited to its data & control flow model, so given that arrays are an excellent data model, it's best to use an array language, since the primitives and their implementations are so tailored! in this case, the factor solution requires me to use `map` manually, and to curry data into the map predicate. in k, i multiply `u` by a vector of iota vectors without a second thought. the fact of nesting being irrelevant to multiplication is coded in the multiplication primitive itself. furthermore, in the actual real-world version of this, `u` is a vector, not a constant; so while the k code that i've written still works for this case too, the factor code would need to be rewritten! so what in k is just `u*` is any of the following in factor: `x u [ * ] curry map`, `x u [ * ] 2map`, and countless other variants depending on the shape of the thing that we're mapping over and how we want to associate elements of `u` with elements of `map`'s input! and that's just _multiplication_ on non-trivially yet pretty simply-structured data! needing to code traversals per shape is a horrible, ubiquitous strain for non-array programmers! it makes refactoring a pain, too.

btw, the actually correct solution is `renko:{[c;U](*c),*|{(lp;acc):x;(lp+0^*|i;acc,,lp+i:z*¡:(sgn d)*_(abs d:y-lp)%z)}/[(*c;());1_c;1_U]}`, which i found after testing then tweaking the above solution. this offers a different consideration of k: because k is basically purely functional because it doesn't support (nested) lexical scoping, i had to use a fold to do what would ideally be expressed as a stateful map over 2 lists:

[source,factor]
--------------------------------
: renko ( c u -- r )
  [ unclip-slice dup rot ] dip rest-slice                     ! [(*c;());1_c;1_U]
  [ [ [ over - [ sgn ] [ abs ] bi ] dip /i * ¡ ] keep ! ¡:(sgn d)*_(abs d:y-lp)%z
    [ * ] curry map                                           ! i:z*
    ! the following operations don't match the order of evaluation seen in the k solution:
    [ ?last 0 or + ] 2keep                                    ! lp+0^*|
    swap [ + ] curry map                                      ! lp+i
  ] 2map
  nip                                                         ! *|
  swap prefix ;                                               ! (*c),
--------------------------------

and without comments:

[source,factor]
--------------------------------
: renko ( c u -- r )
  [ unclip-slice dup rot ] dip rest-slice
  [ [ [ over - [ sgn ] [ abs ] bi ] dip /i * ¡ ] keep [ * ] curry map
    [ ?last 0 or + ] 2keep swap [ + ] curry map
  ] 2map nip swap prefix ;
--------------------------------

pretty efficient, but easier to follow when using k's inline bind form. this program is mostly concatenative, but not totally. we see a `keep` and a `2keep`, but there's hardly any stack shuffling. it's mostly combinators, and none are nested in others (except that they're all in `2map`'s quotation, of course. i see the ugliness of `[ * ] curry map` & `[ + ] curry map` used instead of `lp+i:z*`. note that, in factor, `reduce` is defined as `swapd each`. thus `map` is just `each` plus the effectful operation of pushing the result of applying the mapping fn to the current iteration's element into an accumulation vector. a true beauty of factor is that it seems purely functional, but its semantics are totally imperative & mutative.

stack machines are quite beautiful computation models! they enable easiest access to the most recently used data, _exactly akin_ to, in an ast, the current continuation having easiest access to nearest ancestor nodes in the ast. scheme `(f (g a b) c (h d))` is expressed in factor as `a b g c d h f`. given some factor symbols and their stack effects, we can easily derive a corresponding ast. the more complex that a computation is, the less elegantly the stack machine can express it, where complexity is measured as the asymmetry of its constituent relations, which generalize functions; learn prolog if you must.

mapping retains closes's index-wise associations with other vectors, such as dates; thus our renko renko blocks are implicitly associated with dates just as the closes were. k favors mapping a function `f` over the input array, replacing each element by an array of elements. this allows us to easily derive `A` by `,/f x` while retaining pointwise association with any other vectors: we get the indices of non-falsy elements by `&{:[x;1;0]}'`; then we can use that as a selection vector for all pointwise-associated vectors.

====== attribute independence

instead of a sequence of tuples, a tuple of sequences, which is expressed as a tuple, since each object represents an array. ideally, however, we should define it altogether as a relation whose index is a tuple: (attribute name,numerical index). then in k we can say `rel[;4]` to get all attributes at `4`, or ```rel[`a;]``` to get all attribute `a`. we'd ideally use predicates, e.g. `rel(a>5,i=4)` but this is easily enough effectively done in k when we store relations as a vector of vectors e.g:

[source,k]
----
rel:(("dave";10;`M);("john";12;`M);("travis";20;`M);("stacy";13;`F);("holly";20;`F))
{(12<x[;1])|`F=x[;2]}#rel /the set of females union the set of people over 12 y/o
(("travis";20;`M)
 ("stacy";13;`F)
 ("holly";20;`F))
----

commonly we perform operations on arrays, then compose those results, rather than composing functions then iterating once through a multi-attribute/dimension vector.

k vs sql:

ngn-k beats the crap out of sql because its table (either dict or proper k9 table i.e. seq of same-key dicts) structure is sql but excellently generalized to allow nesting. consider the following:

[source,k]
------------
l: 10 8  9  12
c: 11 9  10 13
h: 15 20 12 14
d:(`h`l`c!(h;l;c))
t:(`TSLA`AAPL!(d*10;d)) / our table. pretend that the sql version has an autoincrement value, i, which is the index, and that because the sql table is flat, it'll have an s for the symbol, too: t(s,i,h,l,c).

t[`TSLA] / select * from t where s="TSLA"
`h`l`c!(150 200 120 140;100 120 90 120;110 180 100 130)

t[`AAPL;`c] / select c from t where s="AAPL"
11 18 10 13

t[;`c] / select c from t
`TSLA`AAPL!(110 180 100 130;11 18 10 13)

/ select i from t where c>(h+l)/2
/ alternative solution: {&x>(y+z)%2}.'t[;`c`h`l]
&'t[;`c]>(t[;`h]+t[;`l])%2
`TSLA`AAPL!(,1;,1)

/ put SPX into the db
t:(t,`SPX!,`h`l`c!{(x+_x%3;x-_x%3;x)}@_1e3*44.2 46 45 47)

/ days where price change was the same sign as spx's price change. good luck coding this is sql.
`SPX_ (>':t[`SPX;`c]) (1_&=)/: \>':'t[;`c]
`TSLA`AAPL!(,3;,3) / the expression's actual output value
------------

each stock symbol is stored exactly once, unlike in a sql table, where it'd be stored per row, yet we get the same behavior as sql, but with all the power that array-based programming provides! rather than working with predicates, i specify one predicate at a time, producing a boolean array, then merge them by folding with min, max, multiplication, etc. the nice things about k tables over sql tables:

* to operate on a dict is to operate on its values s.t. the operation's output retains association with respective keys. the code is the same to do that as to operate on a vector.
* expressions such as the final one above are easy in k but very hard in sql
* unlike sql, i don't need to care how i structure my data. i can structure my data in a table or across many vectors—whatever makes expressing my desired computations most elegant.
* outer joins on keys is implicit when applying a binary operation to two dicts. this is probably not as efficient as sql's joins, since sql's joins (like its indexing & filtering) relies on indexes: maps from index attribute to rowids. sql's full system could be implemented in k fairly easily, but it'd be a bit a work. indexes are sql's core, and can be implemented in k by using grading vectors. the only trick to doing the k implementation well is handling modifying all indexes when tables are mutated. you could just re-grade all indexes each time that the number of records changes, or, when a table's records' values are updated (the number of records does not change) then you can re-grade each updated attribute's grading vector. that sounds inefficient. ideally, like balancing trees, we want mutations to force re-evaluation only of small, local index substructure.

.the filter-sort problem

`select x from x where thres>f x order by f x` where we compute f x only once. in k, filtering (<f x) changes its indices, so we cannot use masks alone to write this query. a primitive which combines sort & filter would be nice. it'd accept an ordered vector of indices which may feature -1's, which indicate that they should be omitted. this is actually not particular to sorting, but to selecting generally. internally this can be implemented as "AND(mask,idxs) under (+1)". also, this design is more apl-like. higher order fns that change length is quite a lisp/haskell design. filtering is a bummer b/c it changes length, which both loses information and changes structure, thus interfering with relations of indices, affecting things like join or sort; however, if we convert a sequence of bits to a set of integers, then changing size does not change the set's structure! this comes at the cost of set lookup not being as fast as parallel traversal of sequences (unless we sort the set and the set of indices to access, and use left inner join, which is not as fast as masks but might be faster than some set intersection algorithms). sql's select statement is synergistic; join (iterated lookup), filter, sort, limit (slice output), are all coded together, and flexibility is supported by clauses of the grammar being optional or required depending on which prior clauses were used. yet is it less flexible than k/apls? if apls were to adopt this synergistic form, would we sacrifice anything? if so, could ew modify the grammar or devise a synergistic system that has all the flexibility/granularity that we desire? bqn's group operator omits -1's from selection vectors—nice.

solution:

[source,k]
-------------------------------------------------------------------------------
a:2 1 3 16 7 / x: input
z:2*a        / f(x): common factor of b & c
b:<z         / sort by f(x)
c:z<7        / filter by cmp(f(x),thres)
a@b^&~c      / select from a where c order by b (technically b set minus not c)
-------------------------------------------------------------------------------

we must use where (`&:`) and intersect (technically set minus, (`^`), but they're equivalent here b/c `b` is a superset of `c`) (or find (`?`), which is equivalent); we cannot do it by masks alone in k.

my original thought was:

[options="header"]
|-------------------------
| x       | y  | y>6 | <<y
| 0 6 5   | 0  | 1   | 0
| 10 4    | 10 | 0   | 4
| 9 2 0 3 | 9  | 0   | 3
| 4 9 9 5 | 4  | 1   | 2
| 5 0 1   | 5  | 1   | 1
|-------------------------

then `(<<a)@&6>a:*:'x` gives `0 2 1` as desired...except that now i need to use that:

[source,k]
----------------------------------------------------------
{@/(x;<<a)@\:&6>a:*:'x}(0 6 5;10 4;9 2 0 3;4 9 9 5; 5 0 1)
(0 6 5
 4 9 9 5
 5 0 1)
----------------------------------------------------------

this is a very sql-like solution. it's an exact translation of `select x from t(x,a) where 6>a order by a`. we pointwise associate each in `x` with its corresponding ordinal, forming an alist `l:[(a,b)]`, then we filter `l`, then sort by `b`. to maintain pointwise relation between `x` & `<<a`, i apply to them both the common transform `(@&6>a)`. then i compute `x@<<a` of the filtered `(x,<<a)` pairs. i'm thinking very sql, here.

ordinals (double grade) vs grade:

[options="header"]
|===================
| x | <<a | <a | 6>a
| p | 2   | 1  | 0
| a | 0   | 2  | 1
| n | 1   | 0  | 1
|===================

just pretend that `6>a` is this mask that i've hardcoded. so `&6>a` is `1 2`. applying the mask gives:

[options="header"]
|===================
| x | <<a | <a | 6>a
| a | 0   | 2  | 1
| n | 1   | 0  | 1
|===================

notice how now the grade features now-invalid index 2, but the ordinals, `<<a`, are still correct & valid indices in the transformed (filtered) space.

an alternative solution (which may be a bit faster) is `{(x@p)@&(6>a)@p:<a:*'x}`. here the common transform `(@p)` is applied to the mask and `x`. then the mask is applied to `x`.

the 1st solution that cameron came-up with is: `{H:x@&t>G:f x;H@<G x?H}`. the curious things is that computing f twice would be O(n) still, but x?H is O(mn) where m<n (b/c H⊂ x).

for dictionaries: `{(p@&(t>a)@p:<a:f x)#x}`

''''

.aside: function arity

how _exactly_ to decide which parameters fns take? the following are considerations & observations that seek to answer.

. is it better for fn to take params, or have them one param but pattern match it into subsets?
. are variadic fns worth anything? even factor can use macros to inline fns and assert their stack effect statically. it'd be nice to not have to specify a number to e.g. `nmap`, but w/e.
  .. are variadic fns useful only for coding ergonomics i.e. are they always fns known at runtime?
. sql's model of queries essentially being pattern-matching fns of relations is good. a sql table can be made by reading json, so tables can be added dynamically, which is good.
. higher-order fns are bad: they parameterize arbitrary parts of the computation and require those parts to have specific inputs & outputs, and are thereby limited. inevitably a user will eventually want to parameterize a different part of the computation, or to accept different inputs, or have more outputs used by the higher-order fn somehow. modifying functions is impractical, whereas modifying data is ubiquitous, so better to have functions be so small that any fewer inputs would make the function degenerate. this is the method of greatest flexibility. perhaps it's appropriate, then, for k to have mostly unary & binary operations, plus some few triadic & quaternary fns. it's because those fns are practically fundamental and couldn't be defined by fewer distinct inputs.
  .. higher-order fns tend to create frameworks, which are overconstrained, difficult to design & amend/extend. these difficult endeavors are foolish & unnecessary, not noble. this is *a significant part of why k is so good: where in other langs functions would be defined & called, in k we just dispense with defining fns, instead inlining their definitions and calling them "idioms." when everything's inline, then each arbitrary part is effortlessly modifiable.*
  .. factor demonstrates that higher-order fns are practically just to splice programs into other programs, quite (though not _exactly_) like scheme's `,@`
  .. many complex higher-order functions exist only to be more efficient, which is necessary because the proglang's execution is literal rather than virtual. an example is factor's `map-concat` which is equivalent to `map concat` but is defined without using either `map` nor `concat` and is more efficient.
. fns should return many outputs, to preserve its computation. the user may decide to discard those outputs, rather than the function deciding to discard them by simply not returning them. returning multiple outputs is much easier if we pattern match elegantly. for stacks, it'd be inelegant to use `ndrop`, `nip`,  &c frequently. in applicative langs, it'd be ugly for many multi-parameter positional bindings to feature many holes. eliding outputs is best done in sql: rather than using binding clauses, the outputs are named by the function. one may rename them (and indeed must occasionally do that to disambiguate). anyway, the lack of binding clause and ability to tacitly refer to variables is excellent.

''''

* k has subexpressions. factor has only subprograms, b/c it's purely tacit.
* needing to "lookahead" to the left of a verb to determine whether it's unary or binary is initially bad, but it feels natural after a week or so of studying k daily. it's no trickier than reading stack-lang code. consider `quicksort:{$[2>#?x;x;,/o'x@&'~:\x<*1?x]}`. it's short enough to glace it, so do so. you see `$[` which means conditional, so start reading from the left, looking for semicolons. for each long subexpression, start at its right. the "else" clause is the only trick part. starting from the right, i see `x`, then `?`, so i would like to think `?x` but i must lookahead to the next token to see that it's a noun, `1`, so now i've parsed code into an actual semantic value, `1?x`; then ```*```'s meaning is unknown until i read the following token,.... later, idk if `\` is a unary or binary adverb until i tokenize code on its left. (btw, don't mistake `:\` for the adverb `\:`; and if you're curious about how quicksort works, see the explanation in <<_examples>> below.) lookahead is generally troublesome, but it's practically fine in k because any one non-M-expr token is at most triadic. that k has no "flip" (selfie) is tragic, though, as left argument expressions can be parenthesis forests. summary: k's grammar is fine once you quickly get used to it, but it's still not ideal. being concatenative and having selfie are both good solutions.
* where k beats factor (in practice; factor has strictly greater capability):
  ** terse: avoids shit that isn't strictly encoding the program logic itself. needing to type multiple characters is a needless pain just like needing to compile, or scaffold a project, or any other assumed, imposed constraint that could theoretically be removed or modified without affecting the program itself. we are humans coding; our needs are important, and our coding methods must reflect that! the code itself is generated by our methods, and is so related to them; it's appropriate for us, as one aspect of our method, to choose codes that suit our ability to code them and reason about them!
  ** overloaded: each verb is a concept with multiple varieties as it's applied to specific contexts (nouns). this is a natural separation and combination of verbs and nouns, which makes reasoning about program design easy. it also avoids trying to name conceputally similar or homomorphic operations e.g. in factor the separate words `remove` for sequences and `delete` for sets, despite them being the same damn thing! but nope, due to types, they aren't interchangeable!
  ** powerful mechanisms for relating structures' elements
  ** seqs, fns, and maps are all act the same.
  ** dictionary/vector symmetry
* where factor beats k:
  ** walker (debugger)
  ** concatenative. in a nutshell: incremental data pipeline construction, spilicable & (re)factorable programs
* both have excellent documentation. factor's is interactive at the cost of requiring you to run a gui, and is vast & complex, whereas link:https://codeberg.org/ngn/k/src/branch/master/repl.k[k's] is accessible since it's just text, and is succinct.
* to be able to collect intermediate values from any loop is cool. the backslash words do this.
* very optimized, small implementations are very cool: they afford codes that would otherwise be too inefficient. still, though, mostly virtual operations afford that.
* the stack's excellence is questionable because function parameterization is questionable. having separate inputs instead of one which is pattern-matched against is questionable.

===== common factor patterns done in k

k is semantically scheme [lisp] but with apl-ish syntax. scheme, prolog, factor, and probably all other homoiconic languages are prefectly general and equivalent in their capability; no hacks are required, and all paradigms can be defined by these languages. thus k is as capable as factor. here are some common "powerful" factor idioms translated to k.

[options="header"]
|============================================================
| factor                       | k                  | comment
| `7 [ 10 * ] [ 5 swap - ] bi` | `((10*);(5-))@\:7` | k uses only seqs, whereas factor has a false dichotomy of seqs vs the stack. k's better b/c no swap and only one structure. also if i use `7 8 9` instead of just `7` then i'd have to change the factor code to include `map`, but no such need in k.
|============================================================

== k notes

=== environment

* `\l <path>` runs the k code at the given path. b/c this is a special directive/syntax, you cannot use comments nor other statements later on the same line

=== semantics

* statements evaluate ltr, but each statement evaluates rtl. mexprs eval rtl e.g. in `f[ \x; \y]` `y` is printed before `x`.
* vector—not array—language.
  ** dicts are just pairs of vectors. they are ordered. all vectors are implicitly dicts with natural number keys.
  ** ngn/k supports tables, a structure from in k7, k9, and q, and not part of the k6 standard. tables are lists of dicts or are expressed as flipped dicts (even though that's not their internal data representation) e.g. ```(`a`b!)@/:(1 2; 3 4)``` or ```+`a`b!(1 2 3;2 3 4)``` respectively. they're equivalent. the repl prints them as flipped dicts with `!` in m-expr form. as the code denotes, tables are maps from symbols to vectors—an isomorphism of sql relations. a simple way to think about tables is that they're the obvious representation of a sequence of dicts all having the same keys; since the keys are common, there's no reason to store them more than once. tables' particular use, aside from perhaps being efficient for their operations, is that they may be indexed by column name or row number e.g. the above table may be indexed by `@0 0 1` to produce a table with a repeated row, or ```@`a`b```` to get `(1 3; 2 4)`, or ```[`a;1]``` to get `3`, etc.
    *** *to merge tables by concatenating dicts (`,/`), they must have the same keys. also, using `,` on two tables does note make a table; it simply replaces values on the left by those on the right, for common keys. however, appending a dict to a list of dicts will leave a table.* e.g. `:tm:{((?,/!'x)#)'x}((`CAT`SXZ!(`h`l`c!10 9 2;`h`l`c!9 -3 7));`CAT`SXZ`SMO!(`h`l`c!26 78 89;`h`l`c!17 25 64;`h`l`c!12 18 14))`
* no rational type. only floats :(
  ** `-1*0.0` is `-0.0`, which is a different value from `0` or `0.0`. yup. YUP....
* an n-dim vector maps n coordinates to its unique elt
* scalars are exactly 0-dim vectors. an empty vector can be used to index into a scalar.
* like j, verbs may be _atomic_: they apply to all atoms of a vector
* scalars are broadcast
* functions are 1st-class e.g. `x (*(+;*))\: y` computes `x+\:y`; the adverb accepts a verb/gerund. in k, all verbs are gerunds; they're only actually applied in certain grammatical contexts or if manually invoked by `@` or `.`.
  ** *this demonstrates a very beautiful and powerful description of k's grammar: k programs are just a bunch of juxtaposed symbols evaluated in context!* for example, `'` is a symbol, and has things on its left and right. when the left is of the "function" type, then `'` means "each" and evaluates to a function. if left is of any other type, then `'` means "interval index" and evaluates to a vector. in the case when it evaluates to a function, then the function is evaluated in its context e.g. `x,'y` evaluates as follows: `y` is a thing; it remains so. `'` can be many things depending on what, if anything, is given on its left or right. in this case, there's a `,` on the left and a thing on the right; thus it evaluates to the token `,'`, leaving the thing on the right. now we have `x ,' y`; `,'` is a thing that evaluates depending on what, if anything, is given to its left or right. in this case, both are given, so it point-wise associates them and applies its operation to each pair, collecting all those results in a list. were left not given or if left were a function, then it would apply `,` to each of right, producing a value, which would be left to left to decide how to evaluate it. if right were omitted but left were provided and weren't a function, then `left,'` would evaluate to a left-curried version of `,'`. this is the same pattern that we see in e.g. scheme, but where function application is decided by each token's contextual rules rather than being specified by the programmer in every invocation context, and with extreme focus on ad-hoc rules determined by types, and where functions may lack left or right arguments. this system is similar to haskell's auto-currying, but concatenative: like a thing atop the stack taking an argument that, if a function, consumes it and leaves a composed function on the stack, and so on—though really term rewriting is a more appropriate model.
* functions and indexing are one operation. this is appropriate when we consider functions as maps from dom to cod i.e. (10+)@12 can be equivalently interpreted as "the map that adds 10, indexed at 12" (an interpretation which i strongly encourage) or "pass 12 to the function that returns 10 plus its input." this enables `{10+x} 5` to work; `{10+x}` is not a verb; it's a noun! thus `{10+x} 5` satisfies the subgrammar, "noun noun". juxtaposed nouns are evaluated as "index left noun by using right noun as index". because of function-dict equivalence, to access a function as a map is to invoke it on its argument.

WARNING: conditional expressions must not be right args to another verb:

[source,k]
-------------------
:[0;`err"hi";"F"]
"F"
0,:[0;`err"hi";"F"]
'hi
 0,:[0;`err"hi";"F"]
           ^
:[0;`err"hi";"F"],0
("F"
 0)
-------------------

unlike statements in a progn, statements in a list, and argument _lists_, are evaluated from the right:

[source,k]
------------
(a:3;b:a+2)
'value
 (a:3;b:a+2)
        ^
(b:a+2;a:3)
5 3

+[k:4;k*5]
'value
 +[k:4;k*5]
       ^
+[k*4;k:5]
25
------------

TODO:
* what are "prototypes?" the link:https://wiki.cor.fyi/wiki/Ngn/k[k wiki] says that ngn/k partially supports prototypes. kona hasn't tables but has prototypes.

we cannot call a function and its returned function (or index into its dictionary) at once, but we can at once index into a dictionary and call its returned function:

[source,k]
----------
/ can't index into a dict returned by a fn
{(x+2)!y+3}[0 1 2; 3 4 5;1]
'rank
 {(x+2)!y+3}[0 1 2; 3 4 5;1]
                           ^
/ but successive indexing works fine, of course
({(x+2)!y+3}.(0 1 2; 3 4 5)).3
7

/ can't index into a fn returned by a fn
{{x*y}[;x+3]}[4;5]
'rank
 {{x*y}[;x+3]}[4;5]
                  ^

/ but again, successive is fine
{{x*y}[;x+3]}[4][5]
35

/ HOWEVER! i _can_ index at once into a dict/list then a fn
(2 4!({x*4};{x+3})).(2;6)
24

/ an invalid index (here 3) returns (::), which is then applied to 6, here
(2 4!({x*4};{x+3})).(3;6)
6
----------

==== maps, lookup, and nullity

[source,k]
----------
m:"abc"!("all";"cats";"are")
m@"zxa"
("   "
 "   "
 "all")
^m@"zxa"
(1 1 1
 1 1 1
 0 0 0)

/ indexing into a dict of vectors at a non-existant key will give you a vector of empty elements the length of the dict's 1st value:

(`a`b`c!("hello";"candy";"bo"))`c
"bo"
(`a`b`c!("hello";"candy";"bo"))`a
"hello"
(`a`b`c!("hello";"candy";"bo"))`d
"     "
(`a`b`c!("helercheorcheuhrcoehcreoulo";"candy";"bo"))`d
"                           "

/ effectively an inner join
merge:{[m;A;B;v]mask:&(~^m@B)[;0];A[mask]v'm@B@mask} / v[A;m@B], where A & B are pointwise-associated vectors. does not pad. if none of B is in !m then merge returns ()
merge[m;("myprop";"size";"val");"axc";{x,"=",y}]
("myprop=all"
 "val=are")
merge[m;("myprop";"size";"val");"yz";{x,"=",y}]
()

/ default dict joining pads values. this is regardless of v.
{+(!x;.x)}("axz"!("myprop";"size";"val")){x,"=", \y}'m
"all"
"   "
"   "
"cats"
"are"
(("a";"myprop=all")
 ("x";"size=   ")
 ("z";"val=   ")
 ("b";"      =cats")
 ("c";"      =are"))
----------

it's not a good idea to try to use string keys; use symbols instead. this is because strings are arrays. in other words, avoid using arrays as dict keys. even if it's possible to make it work, you'd be working with/against broadcasting:

[source,k]
----------
"ab"!2   / not a dict with one key; it's a dict with two atomic character keys, "a" & "b", both with the value 2, which was derived by broadcasting
"ab"!2 2

/ broadcasting allows us to create dicts by specifying only one atom instead of a list of them
(`t!4)~ \`t!,4
(,`t)!,4
1
----------

==== scoping

*scope like j. scope is not nested:*

[source,k]
----
{v:4;{x+v}@x} 6 / inner lambda does not inherit outer lambda's namespace!
'value
 {x+v}
    ^
 {v:4;{x+v}@x}
           ^
 {v:4;{x+v}@x} 6
               ^
{v::4;{x+v}@x} 6 / globally define v
10
v                / v retains its last binding, regardless of context!
4
----

so you have to pass all your data as arguments to inner lambdas: `{v:4;{[x;v] x+v}.(x;v)} 6`, or use projections; `{v:4;(v+)@x}6` works fine. fortunately this is not common in k, since k is mostly semi-concatenative. furthermore, scoping is a hairy mess, and ought to be avoided. furthermore, lexicalaly scoped lambdas are not purely functional simply because any lambda might be defined in terms of data outside its input arg vector! that's hardly different from using state! j's & k's design is sometimes less convenient, but more elegant.

array langs use arrays _instead_ of functions anyway; rather than composing functions, which bundle into a big, complex, hairball, we "compose" data by applying a sequence of operations on it, which adds information to it but retains its shape. TODO: find an example of this

all nested lambdas are re-expressible as one flat lambda with more args. rather than nesting lambdas, it's better, equivalent form to create a lambda with more arguments, thne partially apply it. for example, the haskell `(>=>) :: \x -> f x >>= g` can be re-expressed as `f >=> g x :: f x >>= g` in k as `(⇒):{[f;g;x]bind[f;g x]}`, then `f⇒g` is the same as `f >=> g`.

composition is like a complex set-union of namespaces and sequencing of nested programs. composition is a function automorphism. likewise, data operations are data automorphisms. however, data operations are commonly structure-invariant!

NOTE: a bit surprisingly, functional code like haskell or erlang is mostly ad-hoc polymorphism via type classes, and recursive functions that use pattern matching for control flow.

NOTE: it's hard to find complex code in factor, because factor has very fundamental looping primitives, namely b/c they're defined of the most fundamental looping primitive, `each-integer`. factor is not purely functional, but commonly emulates it by returning new, same-size seqs, then pushing computed values into them. this is how `map` works. also factor has not identifiers nor scopes; instead, it either uses the data right then, possibly in multiple computations such as `cleave` or `curry map`.

also, apparently we can't set a global variable to a local variable of the same identifier:

[source,k]
------------
{a:4;a::a}[]
a
'value
 a
 ^

/ yet...
{c:4;a::c}[]
a
4

/ setting to a global then overwriting that global is fine
{a::4;a::1+a}[]
a
5
------------

==== really cool k semantics to incorporate in other langs

* funcall/index duality. `@` is "index x at y" or "call x with argvec y"
* functions are implicitly quoted simply by parenthecizing them e.g. `(-),1` returns 2-element vector `(-;3)`; this is because k's grammar is contextual, and a verb by itself (without args) is considered as a noun; thus, because in the parenthecized `-` is a noun and thus `,` joins two nouns into a vector.
  ** to invoke the essentially-quoted verb, use `@`
* contextual grammar and thus contextual evaluation of deferred/quoted expressions
* a single variable can refer to a set e.g. in `{4+x}`, `x` can refer to a vector. ideally it would, like in prolog, refer to a (constrained) set. as an honorable mention, sql variables also refer to sets.

hopefully rank must be explicit in k. rank should always be explicit as a general coding convention. k's `each` probably does that.

.beautiful dictionary/vector symmetry

each'ing (a monadic verb) over a vector applies to a vector's elements, not its indices. likewise, eaching over a dict applies to its values, leaving its keys in tact e.g. `{5+x}'`a`b`c!1 2 3` returns ``a`b`c!6 7 8`.

[source,k]
&`rita`bob`sue`adam`frank!0 0 1 0 1      / keys which have a value of 1: `sue`frank
(`bob`adam`sue`rita!23 54 12 82)?12      / find key by value: `sue. if vals were ordered, then we'd be able to use X'
&5=`bob`adam`sue`rita!5 1 5 3            / all keys having a value 5: `bob`sue
|\`rita`bob`sue`adam`frank!12 7 87 32 11 / returns `rita`bob`sue`adam`frank!12 12 87 87 87

=== types

types are here listed with a common shorthand:

[options="header"]
|======================================================
| sym               | name                | empty value
| c                 | char                |
| i                 | int                 | 0
| n                 | float               | 0.0
| n                 | number (int\|float) | 0[.0]
| s                 | symbol              | `
| a                 | atom                |
| A                 | list                | () or !0
| d                 | dict                | (!0)!0
| u                 | monadic func        | ::
| F                 | dyadic func         | <n/a>, i think
| any of x, y, or z | any                 | <n/a>
|======================================================

TODO: wtf is "atom"?

excepting `F`, a lowercase letter means a scalar, and a capital one a vector; e.g. `C` means a string and X or means "a vector of anything."

these symbols are used by cast ($/2) and type (@/1).

=== syntax

* right-associative
* conditional branching: `:[p1;f1;p2;f2;...;else]`
  ** dollar sign may be used instead of colon
  ** the empty values are the only falsy values in k: number: `0`; array: `()`; character: `0x00` i.e. "\0"; symbol: ```````; function: `::`, dict: `()!()`. all others are truthy. *`0N` is truthy! use `^:` to convert it to a false*
  ** prefixing a clause with `:` will make it return immediately, ignoring the clause's remaining computation
* newlines behave identically to semicolons. this enables you to directly code pretty-print matrices: one row per line.
* literals:
  ** empty list: `!0`
  ** character: `0xHH` where HH is a number in hexadecimal
  ** null: `0N`. *null is truthy*.
  ** `[stmt1;...]` is progn [lisp] i.e. all statements except the last are evaluated only for side effects, and the last statement's value is returned from the whole bracked expression list. this is the same as the comma operator in c.
  ** symbol: ````sym```
  ** vector: `(a;b;...)`
  ** generally list literals are sequences of homogenous-type data literals.
    *** the following must be parenthesized and its elements must be delimited by semicolons:
      **** hetrogeneous lists' of literals
      **** lists of non-literal nouns
      **** lists of lambdas (this prevents applying the lambdas to each other)
    *** exception: logical vector literal: [0|1]*b e.g. `10010b`
  ** dicts, at least in ngn/k, must be constructed by `!/2`. i think that i've seen other k6 impls use `[k:v;...]` syntax where symbol keys are not prefixed by grave accent.
  ** function:
    *** *multi-line lambdas' last line must be prefixed with `:` in order for it to return that value; else it returns nothing*
    *** nullary lambdas must be invoked by using m-expr syntax with an empty arg list e.g. `myNullaryFn[]`
    *** `{[arg1;...] definition}`
    *** in ngn/k, to bind to a symbol (single non-ascii character, it seems) to a definition, parenthesize it e.g. `(⁂):(10+)` which can be invoked like `⁂!6`. afaik you cannot define ambivalent functions. however, there is special support for defining 2-character symbols where the 2nd symbol is `:` but this has nothing to do with arity. e.g. `(⁂):(10+);(⁂:):{%x%y}` to define an inline monad, `⁂`, and an inline dyad `⁂:` invokable as e.g. `20⁂:10` or `⁂4`. of course, conventionally you'd define verbs ending in `:` as monadic, and a corresponding non-`:` one as dyadic.
    *** `{...}`. unary fns arg (on the right side) is called `x`, but in binary functions, `y` is the right arg, and `x` is the left! if you use `z` then you must invoke by an argument vector anyway e.g. in `{z%y+x}[30;20;10]`, `x`=30, `y`=20, `z`=10.
    *** fns may use semicolons; then they're the progn but parameterized by xyz
  ** negative literals are as in most langs: hyphen immediately followed by a number literal
* slash begins line comment
* `o` is like apl ∇ e.g. `{$[x<2;x;+/o'x-1 2]}9` returns 34. technically `o` is a special noun, not a special syntax. thus it can be used infix-dyadically or with the usual function application/indexing operators/syntaxes. of course, then, `o` is used commonly for recursion. however, maybe it can be used to return the current fn to another fn, for e.g. fn callback sequences; i'm yet unsure. idk if `o` captures the current continuation (or if k even uses continuations as they're in scheme or factor) or what.
  ** TODO: can this be like j's `$:`? what exactly is the continuation captured? can we use tricks to modify which continuation is captured?
* binding identifiers to values:
  ** `a:v` binds identifier `a` to value `v`
  ** `(a b c):v` binds identifiers `a`, `b`, and `c` to 0th, 1st, & 2nd values of `v`
  ** `aV:v` binds identifier `a` to `aVv` where `V` is a dyad
  ** "unpack": `(v;...):y` pattern matches/binds e.g. `(b;(c;d)):(2 3;4 5)` binds `b` to `1 2`, `c` to 4, and `d` to 5.
* juxtaposed nouns (`y x`) or `y[x]` evaluate as `y@x`. multi-parameter function punning also works: `x[i;j;...]` is the same as `x.(i;j;...)`
  ** omitting an index on a side of a semicolon means "all" e.g. `("abc";"DEF")[;1]` returns `"bE"`
  ** selecting multiple indices at depth (a mix of amend & drill): `(4 5#!20)[(0 1;1 2)]`. the parenthesis make this one vector index rather than multiple nested indices.
    *** `m[;i]` is the same as `m.(::;i)`.
* setting a values at a given indices (an alternative syntax for the "drill" primitive): `m[i;j;...]: v`. the would-be equivalent form, `m[i][j]...:v,` is illegal, btw.
  ** `m[i]:v` returns `v` but amend returns `m`: `{:x[1]:40}1 0 2` returns `40`. `{@[x;1;:;40]}1 0 2` returns `1 40 2`.
* you can't use a dot without a space between two identifiers e.g. `a.b c` will give a `'value` error. you must do `a . b c` or `a. b c` or `a .b c`. i'm assuming the "apply" use of dot, here.

you can put into a dict `d` by the following syntax: `d[`k1`k2`...]:v1 v2...`.

you can assign at the head of a conditional clause:

[source,k]
---------------------
:[c:6;"TRUE";"FALSE"]
"TRUE"
:[c:0;"TRUE";"FALSE"]
"FALSE"
---------------------

*note that it's `c`, not `:c`; the latter will return before `c` is even tested.

TODO: understand indexing exactly. `(4 5#!20)[0 1][1 2]` differs from `(4 5#!20)[0 1;1 2]` and isn't indxing at depth (so says xpqz). he may certainly be correct, as idk what semicolon means.

=== verbs

NOTE: suffix `:` forces an ambivalent verb's monadic form.

* verbs may be left- or right-atomic, or apply to the whole argument (in j this is rank infinity or rank _1).
* in this table, i mean `x` as the left arg and `y` as the right.
* useful verbs—the ones that help you design dataflow programs—are in bold

to be explicit i'll use `R` & `L` instead of `x` & `y`, unless `x` & `y`'s (or other symbols') positions are explicitly given. `x` is always the 1st arg; in a monad, the 1st (and single) arg is on the right; in a dyad, it's on the left.

the following table's verbosity is between link:https://github.com/JohnEarnest/ok/blob/gh-pages/docs/Manual.md#verb-reference[oK's verb table] and the <<_ngn_quick_reference>>.

[options="header"]
|=============================================================================================================================================================================================================================
| symbol     | monad                                                                  | dyad
| `s:x`      | identity                                                               | almost always used as _bind local_ (`s` is an identifier.) also, if `s` is a datum literal, then `s:x` returns `x` i.e. it's the "right" function, which is useful in the verbs "amend" or "drill"; this use of right is necessarily useless inline, but the right-curried version is useful. rather, its utility is that when its right arg is curried, then it's the constant fn.
| `::`       | identity (literally, `::` is the monadic form of `:`)                  | bind global
| `,`        | make singleton of +1-dim                                               | *concat or dict union* (merges per key, discarding the left dict's value in lieu of the right's)
| `<f\|i>#x` | *count*                                                                | *1. shape: truncate or repeat to make given length & shape, starting from the end if `i<0`; or 2. if `x` is a dict: select entries by (symbol or char) keys `i`; or 3. filter `x` by `f` [applied to its values]* (generally `f` returns a natural which is the count; 0 & 1 are the most common). *see notes & examples below.*
| `+`        | transpose                                                              | add
| `-`        | neg                                                                    | sub
| `*`        | first val (atom)                                                       | mul
| `%`        | sqrt                                                                   | div
| `!`        | i. (0D) / permutations (1D); or dict's *keys*; print fn's internal rep | dict of `keys!vals`, or `div` if `num<0`, or `mod` if `num>0`; *div & mod are `denom!num`*
| `&`        | *each elt elt times* ("where")                                         | min
| `\|`       | reverse                                                                | max
| `<` & `>`  | *grade* [keys by their values] up or down; or <<_io>>                  | less or greater than
| `=`        | partition into nub & idxs; or identity matrix                          | atomic equality
| `~`        | `(0=)`                                                                 | "match" (total equality: same shape, values, *and types*)
| `^`        | `(1^)`                                                                 | set `y`'s empty values (see chart above) to `x`; or *`Y` without any of `X`'s elts*
| `_`        | floor or `>lower`                                                      | *`i_X`: drop [from end if `i<0`]; `Y_i`: `Y` without ith elt; `I_X`: split `X` at `I` (which must be monotonically increasing) into non-overlapping substrs* (see notes below); `f_X`: filter-out.
| `$`        | convert elts to strs                                                   | x:ℤ, y:str: pad on right (or left if x<0); cast `y` to type `x`
| `?`        | *nub* or _n_ floats on [0,1]                                           | *∍ i.e. idxs of R in L*, return idx; or n rand vals of set given by y. x<0=>pick w/o replacement, in which case `\|x\|>=#Y` => length error, where Y is the set described by y. or `0N?X` to shuffle `X`.
| `\` & `/`  | while (adverb)                                                         | C/C: *join*. C\C: *split*; as in j: I/I decode, I\I encode. behavior about shaping transcodes varies among k implemenations.
| `.`        | eval k source code string; dict's *vals*; reference variable by symbol | call `y` with argvec `x`
| `@`        | type                                                                   | *`y` at `x`*
| `'`        | each (adverb)                                                          | `L` must be ordered-asc list. returns greatest `i` s.t. `L[i]<=R` or -1 if `R<L[0]`.
|=============================================================================================================================================================================================================================

------------------------------------------------------------------
.S get       a:1;.`a -> 1   b.c:2;.`b`c -> 2 / like j's reflex, ~m
/ unary or binary (with right arg) amend
@[x;y;f]   amend  @["ABC";1;_:] -> "AbC"   @[2 3;1;{-x}] -> 2 -3
@[x;y;F;z] amend  @["abc";1;:;"x"] -> "axc"   @[2 3;0;+;4] -> 6 3
/ drill is the same but accepts deep indices. it obviates amend. i guess that amend exists because it's more efficient, or b/c it works for multiple args without each right (/:)
.[x;y;f]   drill  .[("AB";"CD");1 0;_:] -> ("AB";"cD")
.[x;y;F;z] drill  .[("ab";"cd");1 0;:;"x"] -> ("ab";"xd")
.[f;y;f]   try    .[+;1 2;"E:",] -> 3   .[+;1,`2;"E:",] -> "E:typ"
/ splice removes a substring and replaces it with a string. if the substring is empty, then you're only inserting. it's a simultaneous removal & insertion. very good design.
?[x;y;z]   splice ?["abcd";1 3;"xyz"] -> "axyzd"
------------------------------------------------------------------

.derived verbs
--------
@(/')
`r
(/')4
4/
@(/')4
`r
(/')4 6
(4/
 6/)
--------

it's a shame that `*` is head instead of sign like it is in j. it's the only monadic operator that decreases the rank of its argument. `{x@0}` suffices, but is ugly. i think of +++*+++ not like "head" but instead like "derank" which ends-up doing head in the case of non-singletons as a mostly arbitrary but commonly useful case.

mnemonics:

* `\` & `/` are just 'transcode"; the side that they're leading toward is the coding direction: `\` is like `<-`: `2\14` transcodes `14` (implicitly in base 10) into base `2`. `/` is of course the inverse.
* aain, `\` & `/`, in the case of join vs split, think of `/` as fold `x` into `y`; this is join. then `\` is its dual.

NOTE: the special object +++`argv[]+++ can be indexed like +++`argv[2]+++ to get the 3rd element. however, you cannot do +++`env[`SHELL]+++; it's a domain error. you must do +++`env[]@`SHELL+++.

==== colon madness

when you see a colon in code, it's one of 3 things:

. definition (identifier on the left)
. one of these adverbs: window (`':`) or each left/right (`\:` or `/:`).
. force a verb to be monadic (builtin verb on the left)

or just the identity function, `::`.

never would one intentionally write `x:y` to mean "return right argument", since one could always simply put `y` instead. `:` is useful in amend/drill to set values to constants e.g. `@[!10;!3;:;5 4 6]` to produce `5 4 6 3 4 5 6 7 8 9`.

==== grade

grade returns a permutation vector s.t. `{x@<x}` is ordered ascending:

------------------------------------
<9 4 3 5 2 / input to grade
 4 2 1 3 0 / the grade i.e. perm vec
------------------------------------

represents the map:

[options="header"]
|=================
| dom | cod | `x@<x`
| 0   | 4   | 2
| 1   | 2   | 3
| 2   | 1   | 4
| 3   | 3   | 5
| 4   | 0   | 9
|=================

being a permutation, the map's domain is always implicitly `!#x`. b/c the map's domain is implicit, it's often omitted; this is called "one-line notation." i prefer the two-line b/c i'm used to dealing with maps/relations generally, so using the more general form, i feel freer to think generally. perhaps as i become more familiar, i'll prefer the one-line notation.

* in a sorted array, the elements nearest a given element are its neighbors

grade is an inverse thing. see the bqn explanation.

[TODO]
* explore group theory, then permutation cycles. these should help me understand j's anagram and cycle primitives, too.
* create a table of relations. apls relate by indices (ℕ), which is the canonical representation. the relational algebra is equivalent (with sequences being indexed sets) but not as natural/efficient as ℤ or ℕ are for computers. furthermore, ℤ/n & ℕ have algebraic properties worth exploiting which sets generally lack.

==== amend

applies a fn to a subset.

* replace items of y satisfying x with z: `@[y;&x;:;g]`

==== boolean operations

both min & max or addition & multiplication can be boolean AND & OR respectively, but only multiplication supports reals, namely filters, e.g. +++x*p+++ is `(if p x 0)` but `x&p` cannot be so used.

TODO: compare the two bounded distributive lattices: min/max, and the 2-element boolean semiring.

==== group (`=:`)

* freq, which replaced group in later versions of k, is `(+/=)\:`.
* similar definition, which implements group: `{n!(n:?x)(&=)\:x}`

==== `#/2`

===== reshape

* can columnize e.g. `0N 10!21` which is like j's `_2]\` but instead of filling, it leaves the last row ragged
* if one of left's values is `0N`, then that axis length is computed by the length and other axes' lengths
* `i#x` shapes `x` to have `i` shape. it is not like j's `#`! e.g. `1 0 1 0 1#"hello"` returns `,0#,,0#,," "`! `{1 0 1 0 1}#"hello"` returns `"hlo"`! `i` is a shape vector as would be used in j's `$/2` e.g. `3 2 2#"cat"` produces:

-------------
(("ca";"tc")
 ("at";"ca")
 ("tc";"at"))
-------------

which has shape `3 2 2`, which is attained by shaping the 1D array, `(*/3 2 2)#"cat"`. thus we see that `#/2` is useful for systematically nesting.

to reshape without repeating, index:

[source,k]
-----------------
15#"cats"
"catscatscatscat"
"cats"[!15]
"cats           "
{x[!15&#x]}"cats" / take up to 15
"cats"
-----------------

====== in the case of dict

the description "take keys" should not be taken to mean "filter for keys". it _is_ shape, just in the case of dicts. it selects keys _in a particular order_, and may select non-present keys:

[source,k]
----------
`b`c`a`d#`a`b`c!1 2 3
`b`c`a`d!2 3 1 0N
----------

likewise, `X_d` removes entries from the dict while preserving its kv order.

shaping many dicts to a common shape can make array operations on them easy. for example, we may take the intersection of a list of dicts' keys, then shape all the dicts to be that shape, then return a dict from keys to some fold over the sequence of the dicts' values.

btw, that `X#d` can put extra keys (with nulls) into its result demonstrates how "filter" is only one natural case of using reshape. `_` can only ever lessen a dict's key set, and so it properly filters.

===== filter

* `f#x` is just a combination of `&` & `@`: `p#` is equivalent to `{x@&px}`. this is a reason why `&` is called "where". like how `<` is useful for sorting multiple vectors by a common order, so is `&` useful for filtering multiple vectors by a common filter.
* `f` is applied to `x`, not each of `x`'s elts! e.g. `(0=2!)#!10` computes the mask `(0=2!)@!10` then applies it pointwise to `!10`. this is significant in e.g. `{`M=x[;2]}#(("dave";10;`M);("john";12;`M);("stacy";13;`F);("holly";20;`F))`
  ** this k3 example that apparently works in k3 but not in ngn/k: ```{x~|x}#("racecar";"nope";"bob")``` gives `0#,"       ". see the next section about that. anyway, `({x~|x}')#("racecar";"nope";"bob")` is correct in k6. i suspect that i'll often use this pattern of filtering with a predicate that's been each'd.

sometimes it's more efficient or natural to compute multiple selection vectors then intersect them e.g. +++{(!x)@&((thres2<)'.x[;`b;50])&(thres1<avg@)'.x[;`a;!50]}+++

====== funny-looking filter results

[source,k]
-------------------
((0 1 2~)')#3 3#!10
,0 1 2
((0 1 4~)')#3 3#!10
0#,0N 0N 0N
-------------------

the funny result is length 0. it's the result of `0 3#n` where `n` is any integer. similarly, `0 3#0.0` is `0#,0n 0n 0n`, and `0 2#""` is `0#,"  "`, etc null values. another example is:

[source,k]
-------------
2 0 3#580
(0#,0N 0N 0N
 0#,0N 0N 0N)

2 0 1 3#580
(0#,,0N 0N 0N / commas denote singletons, as per usual
 0#,,0N 0N 0N)
-------------

the empty vector of numbers is denoted `!0`. recall that dicts are alists. therefore reshaping a dict behaves exactly as reshaping a list. the empty dict/list (two different objects b/c they're technically different types, despite being isomorphic) already have shape `0`.

recall that `#/2` is overloaded for dicts:

[source,k]
----------
d:`a`b`c!10 20 30
5#d / x is an atom integer. reshape d to it.
`a`b`c`a`b!10 20 30 10 20
`c`a#d / x is a list; select d at those indices.
`c`a!30 10
6 5#d / SAME. x is a list & y is a dict; thus x is assumed to be an index vector.
6 5!0N 0N
----------

all empty vectors are falsy. their elements might be true, though! `0N` is true, but `(::)` is false!

[source,k]
----------
$[ \0 3#(+:);1;0]
0#,(::;::;::)       / empty vector
0
$[ \*0 3#(+:);1;0]
(::                 / non-empty vector
 ::
 ::)
1
$[ \**0 3#(+:);1;0] / the primitive, (::)
0
----------

====== filtering tables, nested dicts, and tables

TODO: ensure that i'm saying that i've found dict of tables is best.

list of records:

[source,k]
----------
:tbl:((0;"TOM";29);(1;"LIN";15);(0;"LARS";6))
((0;"TOM";29)
 (1;"LIN";15)
 (0;"LARS";6))
(*:')#tbl   / method 1
,(1;"LIN";15)
{x[;0]}#tbl / method 2
----------

method 2 is probably more efficient b/c it uses vectors but not "each".

list of attribute vectors:

[source,k]
----------
tbl
(0 1 0                / gender
 ("TOM";"LIN";"LARS") / name
 29 15 6)             / age
(*:)#tbl / wrong
,("TOM";"LIN";"LARS")
tbl[;&(*:)tbl]  / solution 1. ugly code but clean computation.
(+tbl)@&(*:)tbl / solution 2. ugly code and slow computation (b/c of +:).
----------

*overall, storing as an attribute list then filtering by `{x[;0]}#tbl` is best.*

suppose that we use ``j?` to parse some stock market candle json data of the form `{"S":{"h":[...],"l":[...],"c":[...],"v":[...]},...}`. we'll call it `m`. `m` is a map from ``S1` &c to their respective maps ``h`l`c`v!(h1...;l1...);...`. then:

[source,k]
----------
:n:m[;`h`l;!5]
`T`A!((1467 1459 1457 1456 1426
       1444 1441 1426 1421 1403)
      (12751 12445 12358 12873 12736
      12316 12122 12046 12151 12497))
----------

one bother is that `m[k]` returns a vector whereas `k#m` returns `,k!m`. the latter is better b/c it preserves information, which is nice. it's stupider syntax, but this is better:

[source,k]
----------
:n:`T`A#(`h`l#)'cs[;;!5]
`T`A!+`h`l!((1467 1459 1457 1456 1426
             12751 12445 12358 12873 12736)
            (1444 1441 1426 1421 1403
            12316 12122 12046 12151 12497))
----------

it preserves `h & `l so that we can write our predicate in terms of that, instead of arbitrary numeric indices. however, it might be so ugly that i prefer indexing by symbol the first time then henceforth indexing by numeral index, such as would be done in a filter predicate.

[source,k]
----------
:mask:&'{~2!x[;`h]-x[;`l]}n
`T`A!(,1;2 3)
:s:n{x[;y]}'.mask / output is equivalent here regardless of whether we include the dot or not,
                  / b/c the mask retains n's key order.
                  / if we omit the dot, then each uses its "inner join" behavior for dict's;
                  / the dicts entries' orders are irrelevant in that case.
                  / using pointwise association is almost certainly more efficient, so let's
                  / include the dot!
`T`A!+`h`l!((,1459;12358 12873);(,1441;12046 12151))
s[`T]
`h`l!(,1459;,1441)
----------

you can write `p` and change the predicate to be one of both the <TODO: idk somehow this part's missing>. this is the best way to filter nested dicts. it's not quite as clean as filtering lists, but it keeps the keys, which are nice for indexing. i can't use `#` with `n` because that would filter dict entries, but that's not what i want; i want to filter parts of _those_ entries. the same thing makes the following incorrect:

[source,k]
----------
{{2!x[`h]-x[`l]} \x}'n
`h`l!(1467  1459  1457  1456  1426 ; 1444   1441  1426  1421  1403) / T's h's & l's
`h`l!(12751 12445 12358 12873 12736; 12316 12122 12046 12151 12497) / A's h's & l's
`T`A!(1 0 1 1 1;1 1 0 0 1) / right masks, but...
----------

the masks are computed of `x@`h` & `x@`l` together, but i want to use that mask to filter each of `x@`h` and `x@`l`. `#` can't work for that because it generates a mask only of the thing being filtered. in this case, the mask is computed of more than that. we must use `@` & `&`.

the best way to handle this is to use q-like tables. their slightly-better indexability is appreciable is this scenario.

.the ideal representation: dict of tables
[source,k]
----------
:n:+'m[;`h`l;!5] / this time there's '+
`T`A!(+`h`l!(1467 1459 1457 1456 1426
             1444 1441 1426 1421 1403)
      +`h`l!(12751 12445 12358 12873 12736
             12316 12122 12046 12151 12497))

{~2!-/x@/:`h`l}#'n ! there's no reason to preserve keys for filtering, so we can index into x instead of doing keys#x
`T`A!(+`h`l!(,1459;,1441);+`h`l!(12358 12873;12046 12151))
----------

by using `#'`, we preserve the outer dict's keys, and filtering a table returns a table, which means key retention.

much cleaner! the aforementioned filter constraint is no longer problematic, since `x@`h` & `x@`l` _are_ of the same structure which is being filtered.

of course, we could always do straight-up flat sql-like tables, but that means that we don't get sensible integer-based indexing; we want each numerical index to feature `s`h`l`c`v for all candles, but in tables, each (s,h,l,c,v) tuple entry is an element, and so each one has a unique index. the only way to encode multiple tuples per index, in a flat table, is to make it as we would in sql—by adding an index attribute, so that our table is a list of (s,h,l,c,v,i) tuples. the ugly thing about this is the extreme redundancy in storing `s` & `i`. truly the best encoding for this variety of structure is a dict of tables.

use whatever style you prefer per desired computation. heck, i mean there's nothing wrong with e.g. +++(!n)!&/'n[;`v]+++ to get a map to min volume, if you're filtering the outermost dict.

NOTE: remember that extracting keys by `#` requires `x` to be a list e.g. +++#[,`v;]'`T`A#n+++ if you want a single attribute but while preserving the map (for whatever reason; i mean in most cases this doesn't make sense since there's no need to index, since there's only one array. it could be useful if you're going to build-up a composite dict from it plus other singleton dicts, though. i'm not going to judge whether that's good style or not.

NOTE: it's common for json to be a map to a list of maps e.g. `"results":{{"a":1,"b":2,"c":3,...},...},"status":200`. `results` is isomorphic to a table. to get all b's:+++myJsonBlob[`results;;`b]+++. the blank part is the natural number index.

TODO: muse on how, given a seq of +++(ks1!`a`b;ks2!`a`b;...)+++, `(somekeys#)'x` returns a table from index/key to table +`a`b. very slick! ofc a seq of dicts all having the same keys is expressed as a table. also, note that it's much more efficient (much faster runtime) to instead have a map from somekeys to +`a`b than a table [read: _seq of dicts_] of somekeys to +`a`b. remember: to produce a (nested) seq instead of a table, use (d@keys) instead of (keys#d). {ks!+x[;ks]} converts a seq of dicts (of common keys) to a dict of seqs. dunno if a faster equivalent solution exists.

.each

each makes verbs pointwise associate, even if that requires broadcasting. in some sense, atomic verbs become non-atomic, and non-atomic verbs become atomic.

complete interval index example:

-----------------
0.5 1.5 3'0 1 2 3
-1 0 1 2
-----------------

.other verb notes

* grading a dict returns keys. thus if you have a dict of names to values, then sql `select k from d order by f(v) desc limit 50` is k `{50#>x}f'd`. to select `k,f(v)` is `{k:500#<x;+(k;x k)}...`.
* `&` can be used to define its inverse: `({(>':&-':x),1})`, or the much more practical way, `@[(-1#x)#0;x;:;1]`
* `!` giving a dict's keys is similar to `!#x` giving a vector's indices, which are its keys if it's interpreted as a map
* if you want to split at one index `i`, then you must split at `(0;i)`. also, due to the mono inc condition, split does not accomodate negative indices.
* `Y'X` is equivalent to `-1++/X>/:Y`
* eval (`./1`) is slow
* joins are implicit in k e.g. `(`a`b`d!3 2 5) ,' `a`b`c!1 2 3` produces ``a`b`d`c!(3 1;2 2;5 0N;0N 3)` and replacing `,/` by ```*``` or ```*/``` (they're equivalent given ```*```'s rank) gives ``a`b`d`c!3 4 5 3`; we can see that default values are used as they are in fold. this is called `assoc-merge` in factor.
* in factor, window is called "clumps". "groups" is to split at every n. in k: `{(&0=y!!#x)_x}`
* oK has a builtin, `x in y`, which is just `~^y?x`
* `&` gives n indices for each index whose value isn't 0. we can define it as `{,/x#'!#x}`, or for dicts: `{,/x#'!x}`
* to get a better understanding of the permutation ("odometer") `!`, look at its transpose
* `X'` isn't an adverb because it doesn't modify a verb. if it's technically implemented in the parser as an adverb, then that's a hack, not a reflection of actual logical truth.
* is there really no ≤/≥? to be fair, those aren't really helpful; for integers, just +1 or -1, and floats aren't precise anyway, so equality is an infinitesimal difference anyway! instead of `gte 0` you can do `>1e-9`. this also critically calls into question your precision threshold.
  ** or, rather, ≤ is "not greater than": `~>`
* there's a floor but no ceiling! this is ok: ceiling is so defined in factor: `: ceiling ( x -- y ) neg floor neg ;` indeed, even floor isn't a primitive in factor.
* reshape with `0N` means "unbounded" e.g. `0N 3#!10`
* example i/o: `myFD:<`"/path/to/file.txt"` then `>myFD` to close it.
* `=/1` isn't useful. link:https://gist.github.com/chrispsn/3450fe6172a7cc441d0819379ed3a32a[it was also replaced by a function called "frequency"]
  ** btw, i think that the article suggests special token `(&:)?`to mean run-length encoding, which is the inverse of unary `&`; in some versions/implementations of k, `?` following a gerund (verb-as-a-noun) means "inverse" like how `^:_1` is "inverse" in j.
  ** its keys aren't sorted in ngn/k. check your implementation's docs to see if they sort it, and consider whether you want to write implementation-specific code.

==== io

TODO: add "seek" verb to ngn/k. takes a lambda from current position.

* `0:` & `1:` are verbs to read (unary) or write (binary) lines or bytes respectively. unary: read from io descriptor `x`. binary: write `y` to io descriptor `x`.
* the empty symbol is an io descriptor meaning stdin (when reading) or stdout (when writing). of course, you can use standard POSIX file descriptors `1` and `0` for stdout and stdin respectively. otherwise file descriptors may be gotten from `<:`
* other io descriptors:
  ** file paths as symbols, which may be absolute, or relative to the directory in which the k interpreter is running
  ** `"[host]:port"` where `host` defaults to `127.0.0.1`. *this does not support http(s)! it's tcp only!* if you want the usual www funcs, then interface k with cURL or something, somehow, such as via ``x`.

example:

[source,k]
----
/ the most primitive method: handles
h:<`"/home/nic/myfile" / open handle
`1:1:h                 / 1:h reads from h into a string; `1: prints it to stdout
                       / b/c we read h entirely, further reading from it will return "" unless this or some other process appends to the file before we try reading from it again. reading a handle leaves its cursor position at the end of a file when that file was read; if the file is appended to, then that position is no longer eof.
h 0:("thing #1";"thing #2") / overwrite file's contents. you may've thought that reading had put the handle at eof and thus that writing would write at that position. not so! afaik one cannot append to a file in ngn/k.
>h                     / close handle

/ the easy, most common way to read or write to a file: implicit handles; just use symbols instead of explicitly opening/closing them
`myFile 0:"some text" / write to "./myFile"
contents:0:`myFile    / read from "./myFile"
----

remember that you cannot have a symbol of a number! ``56` is a domain error! ``0:` is the empty symbol as the right arg to select stdout as the output fd. of course, you can symbolize a string of digits e.g. ``"56"`; note that k prints this without quotes. this example prints as ``56`.

NOTE: if you compute a filepath to open, e.g. through filtering, and it's blank, then +++`s$""+++ will return the empty symbol, and trying to open that with `<` will cause `h` to be `1`; it'll read from stdin. this is good default behavior in some cases.

* trying to close a file descriptor that is not open does nothing
* ngn/k appears to always choose the least, available numerical fd
* trying to read a file that doesn't exist gives the ``io` error

[quote,ngn,'https://news.ycombinator.com/item?id=22009241#22021986[hn]' in 2020]
____
reading is done with `mmap`. it returns instantly and then loads memory pages from disk only when you use them. 0:x uses 1:x and then it splits the content into lines. unfortunately splitting requires copying, so you'd be limited by the amount of ram (let's ignore "swap").

i don't use mmap for writing/amendment yet. i'll be working on it.

the way modern hardware works is like this: every process run by the os has its own view of the (typically 48-bit) address space. a process can request from the os that a part of that address space be "backed" by a certain file. this means that every time the process touches (i.e. tries to read or write) a virgin memory page there (usually page=4k, always aligned), the os will be automatically notified and will make sure to fill it in with actual content from the file, before the process even knows. from that point on, the page will occupy physical ram. if the os is low on memory later, it may decide to free up the page and return it to its previous state.

in effect, data from disk (or any disk-like storage) can be "streamed" while your program uses ordinary array indexing. the word "streaming" though implies reading from start to end in order (which is additionally sped up by prefetch, but that's a different story..); memory mapping is more general - it allows random access.
____

===== subprocesses

subprocs are executed via +++`x+++. it's unary and takes a 2-list whose head is argv, and whose tail is a string to pass to the proc as its stdin. example: what in posix shell would be `curl localhost:4000` is expressed in k as: +++`x(("/usr/bin/curl";"localhost:4000");"")+++. for portability, you'll probably want to use "env trick" the that haskellers / nixos users employ in their stack shebangs: +++`x(("/usr/bin/env";"-S";"curl";"localhost:4000");"")+++.

NOTE: remember that single characters are atoms, and strings are required! e.g. +++`x(("/usr/bin/echo";"a");"")+++ will fail with a domain error because `"a"*` was used, but `,"a"` is needed; we need a string, not a character!

==== serialization

because ngn/k always prints k source code, serialization is implicit. to convert to a string properly, use ````k@```. to serialize as json, use ````j@```. to read json, use ````j?```.

NOTE: json values `true` & `false` are parsed into `+:` and `(::)` respectively. this distinguishes them from numbers (though arguably we could just use integers 0 & 1 instead of floats 0.0 & 1.0) while retaining their truthiness. to convert to logical values, use `~~` as usual: `~~(+:;::)` returns `1 0`.

.namespaces & modules

there are no proper "modules" in k. there are, however, proper namespaces:

. to load (run/eval) a k file, use `\l <PATH>`
. use `\d <NS>` to set the namespace until the next `\d`.
  .. `\d .` returns to the default namespace
. to refer to an identifier of a particular namespace, prefix the identifier by the namespace and a dot e.g. `myns.myvar`.

keeping a hacky, dynamic spirit, which k supports and is good for the soul, it's often nice to load modules in the default namespace in a way similar to shared objects rather than static compilation:

.onefile.k
[source,k]
----------
myfn:{myotherfn 3+x} / yep, k had no problem assigning this definition, despite myotherfn having not been defined!
----------

.anotherfile.k
[source,k]
----------
myotherfn:{6*-4#x}
----------

.repl
[source,k]
----------
\l onefile.k
myfn 6
'value
 {myotherfn 3+x}
  ^
 myfn 6
      ^
\l anotherfile.k
myfn 6
54 54 54 54
----------

this makes k as dynamic as picolisp, except with simpler namespacing: k namespaces (both proper and of lambdas) are flat!

=== adverbs

the following are verbs given in terms of adverbs and an argument of a given type. i use brackets to mean optional, angle brackets to mean required, and `\|` to mean "or".

there are 3 kinds of abverbs: unrelated-element loops; related-element loops; window loops.

[options="header"]
|============================================================================================================================
| symbol w/types        | functionality
| `[y]<F\|f>'x`         | pointwise relation, or apply `f` to each elt of `x`. broadcasts atoms `y` or `x` to shape of `x` or `y`.
| `y F<\\|/>:x`         | relate entire `y` with each `x`, or vice versa.
| `[x]F</\>`            | left fold or scan with init val `x` or default value (so `x` is the accumulator and `y` the current item). unlike in j, scans are as efficient as folds.
| `[i\|p] f</\|\>x`     | apply `f` to `x` `i` times, or until it fails `p`, or until the value converges or returns to the inital. the scanny version's output (nearly) always contains the initial value and the 1st value that failed the predicate e.g. `{(x!)(1+)\1}` returns the sequence `[1..x]` and `(<1)(1+)\1` returns `1 2`. the "nearly" part is that, stranegly, if you use the predicate `{0}` (or `{x:0}`) then you're guaranteed to get a singleton result. the foldy version is equivalent to taking the last of the scan. see below for the general case: n-ary `f`.
| `i [f]':x`, `[y]F':x` | [apply `f` to each] `i`-window of `x`, or apply `F` to each 2-window of `x` [with initial value `y` for the 1st window]. there cannot be a space between `':` and its left arg, or so i thought, but maybe not?
|============================================================================================================================

a use for "times" is if you want to perform a refining action up to some limit below convergence, e.g. link:https://en.wikipedia.org/wiki/Radiosity_(computer_graphics)#Overview_of_the_radiosity_algorithm[ray tracing until sufficient accuracy] rather than the much more costly complete accuracy; or the "stage" parameter of link:https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods#Explicit_Runge%E2%80%93Kutta_methods[the runge-kutta approximation] of a differential equation.

j's outfix (`u\.`) is not present in k. at least one use of it, which i've found in finance, would be to, after first calculating price pivot points by `{x=p,((1+2*y)z/':x),p:&y}` (`x` is the seq of highs or lows, `y` is the number of elements to both sides to compare a point against, and z is `|/` or `&/`), get the nearest one of each pivot's 2 neighbors: `&/\.` for minima, and `|/\.` for maxima.

NOTE: the order of `':` is reversed; `y` is the previous elt and `x` is the successor.

NOTE: you get either "repeat until convergence" or "while"; if you use while (form `f g/x`), idempotency is irrelevant.

each left vs right mnemonic: `\:` iterates over the LHS elts. if you picture the (back)slash as a person, then they'd fall toward the side that is iterated over.

be aware of using `\:` or `/:`, namely concerning what to put inside its lambda or outside of it:

[source,k]
----------
(&>':b,0 1){y@*&~y<x}\:&a / good. now i want to remove nulls
7 14 0N

(&>':b,0 1){(^:)_y@*&~y<x}\:&a / wtf? rank what?
(,7
 ,14
 !0)

(&>':b,0 1){ \y@*&~y<x}\:&a / inspection shows that each y is atomic
7
14
0N
7 14 0N

(^:)_(&>':b,0 1){y@*&~y<x}\:&a / correct: filter AFTER each-left
7 14
----------

*`'` (each) be used with n-ary verbs by using m-expr syntax* e.g:

[source,k]
---------------------------------------------------------
/ apply triad over 3 argvecs. each pointwise-associates.
{z*x,y}'[1 2 3; 4 6 3;10 20 30]
(10 40
 40 120
 90 90)

/ re-expression
{z*x,y}.'+(1 2 3; 4 6 3;10 20 30)
(10 40
 40 120
 90 90)
---------------------------------------------------------

`/:` & `\:` give rank errors if you try using them non-dyadically. probably the same for `':`.

btw, currying a verb derived from `'` is useful to maintain concatenative style: `f'[A] B` where `f` is a 2+-ary fn, `B` is a large concatenative program, and `A` is defined before `B` is fully evaluated. `A f' B` isn't valid if `f` is a lambda, and `f'[A;B]` is non-concatenative and likely to cause mis-refactoring when `B` is very long or complex.

==== n-ary while/fold/scan

description: `f\[i;y1;...;yn]`

preconditions:

* all `y` have equal length

behavior:

if `i` is an integer and `f` is `n`-adic, then apply _f^∘i^_ (iterated fn), collecting results. if `i<n` then the ``i``'th argument is returned alone. the following code demonstrates the usual case, `n>i`:

[source,k]
----------------------------------------------------------------------------------
{y," ",x," ","f"}\[5;"x";"y"] / prints successive applications in postfix notation
("x"
 "y"                 / i=0. f\[0;"x";"y"] returns "x". ACC is "x".
 "y x f"             / i=1. f\[1;"x";"y"] returns "y". ACC is "xy".
 "y x f y f"         / i=2. f\[2;"x";"y"] returns `f.ACC`.
 "y x f y f y x f f" / i=3. `ACC:f.-n#ACC`. this is the general case
 "y x f y f y x f f y x f y f f")
----------------------------------------------------------------------------------

the final case is re-written in its applicative form as `f(f(y,f(x,y)),f(f(x,y),f(y,f(x,y))))`, which is represented by this tree:

--------------------------
     (    f    )
    /           \
   |           ( f )
   |          /     \
   f         f   |   f
  / \       / \  |  / \
 y   f     x   y | y   f
    / \          |    / \
   x   y         |   x   y
--------------------------

this is a binary tree becasue `f` is binary. at each level, the left branch is a sub-branch of the right.

NOTE: it may seem backwards that the first iteration is `y x f` instead of `x y f`. it is correct, though, in that `x` is the argument nearest to `f`, and if we were to omit `y`, then we'd have `x f` i.e. `f(x)`, the unary case. if we use this convention, then the rest of the iterations naturally agree.

as stated, the general case comes when `i=3`. `-n#` (here `n=2`) is the negative of ``f``'s arity; we apply `f` to the last _n_ of ``ACC``'s elts on each iteration for which `~n<i`.

consistent with the binary case of "while", you can use a predicate instead of a number of times to perform the loop e.g. `+/[20>;0;1]` to get the 1st fibonacci number greater than 20.

if `f` is `n+1`-adic, then we're doing a scan and `i` is an initial value. returned is `f.(,x),Y[;n]` where `Y` is `(y0;...;yn)`:

---------------------------
{x,y,z}\["ABC";"123";"abc"]
("ABC1a"
 "ABC1a2b"
 "ABC1a2b3c")
---------------------------

of course we can exchange `\` for `/` to return only the final result.

.implicit disambiguation/parsing of `[x]F</\>` vs `[i\|p]f</\>`

the ambiguity is whether ```*``` is monadic or dyadic; this determines whether to apply the lambda/predicate afterward, or whether to use it as a "while" clause. as far as i've noticed, this is the only ambiguous grammar.

theoretically, token sequence `A B /` (or `\`) must be parsed thusly if `B` is an ambivalent verb (`B` being a noun would imply the verb form of `/` or `\` (split/join or encode/decode):

. if `A` is a verb then (probably) the "while" form is assumed. idk if it's theoretically possible to have a lambda be a fold's initial value.
  .. in ngn/k, ```{0=2!x}*/1 2 3``` gives a type error whereas ```{0=2!x}(*/1 2 3)``` returns `1` because 6 is even.
. else if `A` is a non-integral noun then it must be a fold's initial value
. else if `A` is an integer then it could be a fold's initial value or a number of times to apply a unary fn
  .. apparently ngn/k assumes the fold case: ```4+/,1 2``` returns `5 6`. `4+:/,1 2` returns `,1 2`—the input transposed 4 times.

.each right/left examples
-------------------------
10 20 30,\:1 2 3 / map (,1 2 3) over 10 20 30
(10 1 2 3
 20 1 2 3
 30 1 2 3)

10 20 30,/:1 2 3 / map (10 20 30,) over 1 2 3
(10 20 30 1
 10 20 30 2
 10 20 30 3)

/ composed each's:

10 20 30,\:/:1 2 3
((10 1;20 1;30 1)
 (10 2;20 2;30 2)
 (10 3;20 3;30 3))

10 20 30,/:\:1 2 3
((10 1;10 2;10 3)
 (20 1;20 2;20 3)
 (30 1;30 2;30 3))
-------------------------

NOTE: you cannot have a space between argument and `/`, since in that case `/...` will be treated as a comment

TODO: how does the parser distinguish between `if/` and `xF/` where `x`=`i`? maybe it tries the dyadic version first, else tries monadic?

=== ngn quick-reference

backslash commands, when evaluated in the repl, are supposed to print their corresponding reference docs e.g. `\+` prints verbs. for me, however, they all print `'nyi`, so i can't get the reference in the repl, so i've put part the reference here that i haven't already covered in the above notes. the followig is copied from `repl.k` from the ngn/k repo:

---------------------------------------------------------------------------------------
\   help               \\         exit
\a  license(AGPLv3)    \l file.k  load
\0  types              \d foo.bar set namespace; restore with  \d .
\+  verbs              \t:n expr  time(elapsed milliseconds after n runs)
\:  I/O verbs          \v         variables
\'  adverbs            \f         functions
\`  symbols            \cd path   change directory
\h  summary            \other     command(through /bin/sh)
--------------------------------------------------------------------------------
\0
Types: / as returned by monadic @
list atom
 `A        generic list   ()   ,"ab"   (0;`1;"2";{3};%)
 `I   `i   int            0N -9223372036854775807 01b
 `F   `f   float          -0w -0.0 0.0 0w 1.2e308 0n
 `C   `c   char           "a"   0x6263   "d\0\"\n\r\t"
 `S   `s   symbol         `   `a   `"file.txt"   `b`cd`"ef"
 `M   `m   table&dict     +`a`b!(0 1;"23")   (0#`)!()
      `o   lambda         {1+x*y#z}  {[a;b]+/*/2#,a,b}
      `p   projection     1+   {z}[0;1]   @[;i;;]
      `q   composition    *|:   {1+x*y}@
      `r   derived verb   +/   2\   {y,x}':
      `u   monadic verb   +:   0::
      `v   dyadic  verb   +   0:
      `w   adverb         '   /:
      `x   external func
--------------------------------------------------------------------------------
\+
Verbs:    : + - * % ! & | < > = ~ , ^ # _ $ ? @ . 0: 1:
notation: [c]har [i]nt [n]umber(int|float|char) [s]ymbol [a]tom [d]ict
          [f]unc(monad) [F]unc(dyad) [xyz]any / this notation is distinct from the types given above
special:  var:y     set    a:1;a -> 1
          var::y    global a:1;{a::2}[];a -> 2
          (v;..):y  unpack (b;(c;d)):(2 3;4 5);c -> 4 / it seems that there's no "rest" matching like in scheme (`. xs`) so if you want to parse (1;2 3 4) into (a;(b.rst)), you'd do (a;b):(1;2 3 4);rst:1_b;b:*b; you'd probably just inline *b and 1_b anyway, though.
          :x        return {:x+1;2}[3] -> 4
          :[x;y;..] cond   :[0;`a;"\0";`b;`;`c;();`d;`e] -> `e
          o[..]     recur  {:[x<2;x;+/o'x-1 2]}9 -> 34
          [..]      progn  [0;1;2;3] -> 3

 !S ns keys   a.b.c:1;a.b.d:2;!`a`b -> `c`d
 &I where     &3 -> 0 0 0   &1 0 1 4 2 -> 0 2 3 3 3 3 4 4
 &x deepwhere &(0 1 0;1 0 0;1 1 1) -> (0 1 2 2 2;1 0 0 1 2)
 ~x not       ~(0 2;``a;"a \0";::;{}) -> (1 0;1 0;0 0 1;1;0)
 ,x enlist    ,`a!1 -> +(,`a)!,,1 / enlisting a singleton dict becomes a singleton table
i?x deal      -3?1000 -> 11 398 293 /guaranteed distinct
 @x type      @1 -> `i   @"ab" -> `C   @() -> `A   @(@) -> `v
 .S get       a:1;.`a -> 1   b.c:2;.`b`c -> 2
x.y apply(n)  {x*y+1}. 2 3 -> 8   (`a`b`c;`d`e`f). 1 0 -> `d
--------------------------------------------------------------------------------
\`
Special symbols:
   `k@x pretty-print `k("ab";2 3) -> "(\"ab\";2 3)"
   `p@C parse k
 `hex@C hexadecimal  `hex"ab" -> "6162"
 `pri@i primes       `pri 20  ->  2 3 5 7 11 13 17 19
   `t[] current time (microseconds)
`argv[] list of cmd line args (also in global variable x)
 `env[] dict of env variables
`prng[] `prng@I get/set pseudo-random number generator internal state
                     s:`prng[];r:9?0;`prng s;r~9?0 -> 1
        `prng@0 use current time to set state
 `err@C throw error
 `sin@N trigonometry `sin 12.34 -> -0.22444212919135995
 `exp@N exponential  `exp 1 -> 2.7182818284590455
  `ln@N logarithm    `ln 2 -> 0.6931471805599453
`exit@i exit
--------------------------------------------------------------------------------
?[a;i;b]     splice
@[x;i;[f;]y] amend
.[x;i;[f;]y] drill
grammar:  E:E;e|e e:nve|te| t:n|v v:tA|V n:t[E]|(E)|{E}|N
limits: 8 args, 16 locals, 256 bytecode, 2048 stack
---------------------------------------------------------------------------------------

looks like there's no way to just pass to a command line without parsing its output.

* "trace" means to print a value without affecting the computation. it's denoted by a backslash preceeded by whitespace. it's useful for debugging.

* note the similarity of `.` & `@` in drill/amend and application: `@` accepts one arg or one level of nesting, whereas `.` accepts multiple. indeed: `"cats"@0 1` returns "ca" while `("cats";"mice").1 0` returns "m", and (10*)@1 2 3 returns `10 20 30`
* multiline comments start with a slash alone on a line and end with a backslash alone on a line, *and must have blank lines before & after the starting & ending slashes; else you'll get odd behaviors.*

NOTE: you cannot put comments in multiline forms such as lists

[source,k]
----------------
STUFF::("things"
/ comment
"more")

'parse
 / comment
          ^
----------------

you can do it for multiline progn blocks, though, including `$[...]`.

== reflection

* to test whether a variable has been defined, use the "get" & "try" forms of `.`: `defined:{~.[.:;x;()]~()}`. pass it a symbol to see if the corresponding identifier is defined.
* `$:` applied to a function (type +++`o+++) gives its internal definition as a string. see the following section for discussion.

."the `$` problem"

tl;dr: to force a verb which leads a train to be unary, make `@` the leading verb.

consider the following code:

[source,k]
----------
"-"/${x+4}15 6 54 2
"19-10-58-6" / what we want. let's factor-out the verb
("-"/${x+4})15 6 54 2 / parenthecize the verbs into a train
" 4 x" / or not??!
("-"/${x+4}) / debugging strat: remove args
"{-x-+-4-}"  / ok, `$` is applying to the lambda. bad.
("-"/${x+4}@) / solution: apply lambda first 
"-"/$:{x+4}@  / confirmed by k's representation of the train
----------

NOTE: if you define a long lambda L and try to evaluate `(...$L@)` it may seem that L's definition is printed. look for a trailing `@`, though! checki its type, too. see this real-world example:

[source,k]
----------
jdnymd:{ / use with ' when applying to many jdns
  a:32044+x
  b:_(3+4*a)%146097
  c:a-_(146097*b)%4
  d:_(3+4*c)%1461
  e:c-_(1461*d)%4
  m:_(2+5*e)%153
  :((_m%10)+(d+100*b)-4800; 3+m-12*_m%10; 1+e-_(2+153*m)%5)}
millisjdn:{2440588+_x%86400000}

(jdnymd millisjdn)
'type
   a:32044+x
          ^
 (jdnymd millisjdn)

/ pay attention to the output. it's jdnymd's definition followed by millisjdn's,
/ followed by `@`
(jdnymd millisjdn@)
{
  a:32044+x
  b:_(3+4*a)%146097
  c:a-_(146097*b)%4
  d:_(3+4*c)%1461
  e:c-_(1461*d)%4
  m:_(2+5*e)%153
  :((_m%10)+(d+100*b)-4800; 3+m-12*_m%10; 1+e-_(2+153*m)%5)}{2440588+_x%86400000}@

/ its type is composition
@(jdnymd millisjdn@)
`q
----------

== control flow

particularly sequencing io ops is sometimes necessary. sometimes you want explicit control flow.

.when "each" matters
[source,k]
------------------------------
/ sleep 2 seconds then print value, for each value, in order
{`x(("/usr/bin/sleep";,"2");"");`0:$x}'10 2 6;

/ if i omit each (') then sleep once and print $x.
{`x(("/usr/bin/sleep";,"2");"");`0:$x}'10 2 6;
------------------------------

polygon.io provides data as paginated json; only at most 1k results are returned per query; if there are more to get, then the json response has a `next_url` key telling the next page's url. the last page has no `next_url` json key. recursive solution:

[source,k]
----------
tickers:{{j:`j?`x(("/usr/bin/env";"-S";"curl";x);"");:$[|/`"next_url"=!j;o[j`"next_url"];()],j[;`ticker]}INITIALURL}
----------

recursion is elegant here compared to "while" because "while" operates on one object for all the loops, similarly to fold. this recursion has two changing data: the input and the output. on each iteration the input url changes, and the output is accumulated. expressing such a pattern via "while" requires (un)packing the changing input and accumulating output:

[source,k]
----------
tickers:{*{x 1}{{j:`j?`x(("/usr/bin/env";"-S";"curl";x 1);"");(j[;`ticker],*x;$[|/`"next_url"=!j;j`"next_url";0])}/(();INITIALURL)}}
----------

i had to encode effectively as a `maybe url` type so that i can both preserve its value for the next iteration, and enable testing it for loop continuation. just plain less elegant than recursion.

=== tools

==== repl

* `\+` is supposed (by xpqz) to list verbs, but does not; it prints `'nyi`.

=== examples

[source,k]
----------------------------------------
quicksort:{$[2>#?x;x;,/o'x@&'~:\x<*1?x]}
----------------------------------------

. `x<*1?x` picks a random element from sequence `x` then compares it to each of ``x``'s elements e.g. `*1?"hello"` may pick `"l"` in which case `x<*1?x` evaluates to `1 1 0 0 0`. if `"e"` is picked then we get `0 0 0 0 0`.
. in `~:\`, `~:` is a unary operator; the colon suffix syntax specifies the unary version. you can verify this by substituting `~:` by `{~x}` and see that it gives the same result. `~:\` applies negation until convergence, which here is just a logical vector's inverse coupled with its identity. 
. `&'` converts each logical vector to integers where `1` is set ("where")
. `x@` indexes into the input sequence

e.g. if we pick `"l"` then `~:\1 1 0 0 0` evaluates to `(1 1 0 0 0 ; 0 0 1 1 1)`, then applying `&'` to that gives `(0 1; 2 3 4)`, then applying `"hello"@` to that gives `("he";"llo")`.

=== technique of coding in k

TODO: consider:

* link:https://github.com/JohnEarnest/ok/blob/gh-pages/docs/Programming.md[common dataflow patterns effectively expressed in k]
* link:https://github.com/kevinlawler/kona/wiki/Idioms[*k3* idioms]

only the following verbs actually concern relation; the rest are arithmetic, type stuff, or special like binding to an identifier:

[horizontal]
.relational quickref
`#`:: count, shape, filter/replicate
`_`:: drop [from end], remove, split at idxs
`?`:: nub, find, splice (ins/del/ovr substr)
`/\`:: join, split
`@`/`.`:: val@idx, or variant of struct with modified val@idx
`/`:: fold, while, converge
`^`:: without
`<>`:: sort
`|`:: reverse
`'`:: interval index / bin search
`&`:: non-0's
`':`:: window

they're approximately listed in the order that i expect, from most common to least common.

==== style

you can nest lambdas, or you can use inline bindings:

[source,k]
----------
/ alternative codes
{(&~=':10>x)_x}1 2 10 12 14 16 3 3 4 9 2 20 11 15
(&~=':10>a)_a:1 2 10 12 14 16 3 3 4 9 2 20 11 15
----------

==== thinking "array"

the common test for good array code is that you use few adverbs (higher-order fns), and their argument verbs (functions) are small. in many langs, control flow devices are part of the language. in freer langs such as factor, they're simply higher-order functions. in k also, they are higher-order functions. this is good, because now we need only this one rule to avoid both adverbs generally and control flow particularly. avoid nesting. verbs are flat; adverbs are not. one may freely use verbs, but adverbs must be used wisely. as much as possible, *put verbs on the right of adverbs, not on the left.*

much of control flow can be re-expressed as programs e.g. `std::vector v(N);for(i=0;i<N;i++)if(i%2==0)continue;else v.push(i);` is the same as `{~2!}#!N` i.e. `continue` here is effectively `filter`.

TODO: put this fact in a good section: "encode" with "where": "encode" maps permutations to indices. each permutation is 0...n, i.e. a base n-number. encode is a polynomial/linear equation, too, then, b/c it's `+/d^n`. odometer (`!`) represents cycles and modular arithmetic. modular arithmetic approximates a sawtooth wave. it can (though i'm not sure that it ever should) represent nested loop iterations, too: e.g. `!2 4` represents an outer loop running for two iterations and its inner one for 4 iterations. this generalizes the nested-`for` control flow pattern from a builtin language feature to a 1st-class map from "iteration index" to iteration value. operations on the result of odometer is equivalent to a `for` loop none of whose "header" subexpressions are mutated by/in its body. odometer is also multidimensional indices. all these are the same thing as regrouping [counting]. get to the (r-1)th digit, then incrementing regroups i.e. increments the next most significant digit. this generalizes modualar arithmetic by endowing a regrouping context. odometer does not handle mixed radix. compare ```+!14 3``` to ```(3\)'!14```. the former is [0,14) zipped with [0,3). the latter is the first 14 naturals expressed in base 3. ```+!4 3``` equals ```(4 3\)'!12``` i.e. iota with encode generalizes odometer to mixed radix. *more generally is the group theory thing that the natural numbers can code anything.* array langs are particularly apt with this! (TODO: i mention this same thing right after the folling example; clean that up)

===== `switch` statements

there are no switch statements in k. lookup in a dict or array instead:

[source,c]
--------------
switch thing {
  case A:a;
  case B:b;
  case C:c;
}
--------------

[source,k]
--------------
(`A`B`C!`(a;b;c))@thing
--------------

your dict/list's values can be lambdas, or, if you need arbitrary branching code, you must use `$[...]`.

===== loop-array equivalence

this loop prints the map from input index `i` to each iteration's output value:

.test.c
[source,c]
----
#include <stdio.h>
#include <math.h>
int main(int argc, char** args){
  int i;float j,v;
  for(i=0,j=i;i<12;i++,v=(float)i*1.7,j+=v)
    if((int)truncf(j)%2==0) printf("%i\t%f\t%f\n",i,j,v);
    else                    printf("%i\t-\t\t-\n",i);
  return 0;
}
----

.`cc -lm test.c && ./a.out`
-------------------------
0   0.000000    0.000000
1   -           -
2   -           -
3   10.200001   5.100000
4   -           -
5   -           -
6   -           -
7   -           -
8   -           -
9   76.500000   15.300000
10  -           -
11  112.199997  18.700001
-------------------------

the lines with hyphens are those where those indices map to nothing. alternatively they could be said to not be in the map. in c, the map is produced by iteration, and (i,j,v) is computed for each iteration. we could say that `i` is the index and the map maps from `i` to `print(j,v)`. `print` can be replaced by any action/function. we could instead say that it's a map from `(i,j)` to `v`, or to `(j,v)` or whatever. this is the case because `(i,j,v)` is a relation [sql or prolog] i.e. that it can be indexed by any subset of its values to return the whole set of values.

i express it in k:

[source,k]
------------------------------
j:+\v:1.7*i:!12
m:i!+(j;v)
`0:("\t"/)'$i,'({~2!_x[;0]}#m)@i
------------------------------

prints

-----------------------------
0   0.0    0.0
1   0n     0n
2   0n     0n
3   10.2   5.1
4   0n     0n
5   0n     0n
6   0n     0n
7   0n     0n
8   0n     0n
9   76.5   15.299999999999999
10  0n     0n
11  112.2  18.7
-----------------------------

notice that in k there are many easy ways to build-up the map, since i'm dealing exclusively with data and not at all with control flow. i express the loop as a dictionary from `i` to `(j,v)`, filter by the values, associate the indices with the values all as a table, then format and print. the point is not in the elegance nor how exactly i express the map; the point is that any loop can be expressed as a map from iteration number to iteration value, and that maps are data and so can be composed, edited, etc as freely as data can be, whereas loops are not 1st-class objects and are not nearly as mutable nor composable.

this also demonstrates the scan/while equivalence discussed later in these notes. notice how `j` was computed as a scan; emergent loop values (here, `j` being mutated—incremented by `v`—on each iteration) are computed & stored as scans, then used in a later array operation.

*generally we translate control structures to maps from iteration number to that iteration's output. loops are maps from iteration number to output, and conditional branches are maps from branch number to body.*

scans should be a concept & notation that represents the actual execution of a loop. suppose that i'm scanning into a set. of course i want to not store multiple copies of a set, and the only way to efficiently get around that would be particular to sets (which is a fair primitive, so ok). in an array lang, the only reason that i'd use a scan is to preserve loop state for doing array operations since they're alternative to looping. the most natural way to do this would just be to loop! this is another example of how we should have *loop combinators*, like factor's `map-permutations`, which never holds more than one permutation at a time in memory, because it's defined in terms of `permutations-quot`, and ultimately just loops over an iota vector. it's best to combine functions then put them into one loop, but have them appear as though they each represent a loop (or not, w/e); it should be understood that they're the same, like how in an array lang atoms are not treated differently from arrays.

''''

start with the minimum needed to code anything: 0 & 1. this generalizes in two equivalent directions: becoming a sequence of 0's & 1's, or staying one number and increasing in maximum value i.e. 0, 1, 2, 3, ...to infinity. of course any programmer knows that they're the same: 1110 bin is the same as 14 dec. they should be seen as the same: it's just value itself, expressed by a sequence of digits; the digits' meaning is exclusively determined by the radix.

we borrow the group/galois theory brilliance that anything can be represented by natural numbers, then combine it with the fact that all natural numbers are equivalent to sequences of arbitrary-radix numbers which is equivalent to modular arithmetic, combined with that all programs are maps, then suddenly everything is a map from naturals to outputs, and apls/k excel(s) at working with that structure!

TODO: in the name of arithmetic, push for powerful arithmetic being used in programming e.g. clifford algebras, convolution matrices, polynomials, en/decode. these conspicuous primitives obviously, greatly-should be discussed thoroughly so that people can actually USE THEM!

===== avoiding windows

windows are computationally expensive because they compute over many elements and can't generally cache intermediate values. a size-k window over a length-n vector produces an annay of shape `(1+n-k) k`. not only is that more elements, but it's especially inefficient because most elements appear k times in the output (or in the window upon which a window fn acts). window fns should be used only when they operate on lists, not elements. for example, `k&/':x` cannot be re-expressed because min requires exactly a window's information to compute; however, `k{(+/x)%#x}':x` can be re-expressed not as a window fn because average can be computed one element at a time i.e. by a scan: `{(((y-1)_a)-0,(-y)_a:+\x)%y}`. note that scan is just a window of size 2 that's capable of retaining all information yet encountered, and is thus the smallest window capable of relating all elements to each other, and cannot consider elements redundantly.

===== using arrays instead of lambdas, and avoiding each (`'`) or transpose

lambdas (not in k, but in most langs which are lexically scoped) introduce new scope; thus indiscriminate use of lambdas sees unmaintainable scope nestings. non-nested lambdas are fine to use with abandon; this use is effectively inline combinators.

`{100*(y-x)%x}/'A` can be expressed as `100*(A[1]-*A)%*A` or `(a;b):A;100*(b-a)%a`. arrays don't lose you anything, but are guaranteed to be flat, not introduce scope concerns, and can be accessed across their many axes. in the actual full line of code (which i used in _real life coding_) i'd used `t[y]` inside that lambda only to realize that it was actually part of an outer lambda. doing away with the inner lambda implicitly avoided this unnecessary problem.

.antipatterns

assuming that `a` is a 2-list of equal-length lists, and `F` is `+`, then `F/'+a` is poor. `a[0]F/'a[1]` is better b/c it avoids the transpose, but reduces to `a[0]F'a[1]` then to `a[0]F a[1]`, finally to `F/a`, which sees `F` acting on two vectors in their entirety. generally, when applying a function to data, ask:

. does `F` entail io? if so, then you likely want to use "each". such an example is, if `a` is a dict from names to ordered strings, then `(!a){`0:$x;`0:y}'.a` prints each name and its data.
. what's `F`'s arg count? must i use `.`?
. what's `F`'s rank?
  .. if it's non-atomic, then you must use "each".
  .. can i apply it to vectors just as well as to each set of elements?
  .. do i need `'` or is the same mapping already implied?
    ... if not, do i need `/:` or `\:`?
    ... one example of needing each is if the vectors together create a deep index e.g. `{A[x;y]}'`

once i had this problem, and i came-up with these solutions:

[source,k]
-------------------------------------------------
/ for each of b's runs of 1's, mark the 1st a
/ a:              0 1 0 1 0 0 0 1 1 0 1 1 1 0 1
/ b:              0 0 0 0 1 1 1 1 1 1 1 1 0 0 1
/ desired output: 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1

>':{:[(2<y)&~x;1;x&2>y;0;x]}\2/(b;a) / solution 1
>':{(1;x;0)y}\1+sgn 2-2/(b;a)        / solution 2
>':{(1;x;0)y}\1+(~b)-a&b             / solution 3
>':{y&x|z}\[0;b;a]                   / solution 4
(^:)_(&>':b){y@*&~y<x}\:&a           / solution 5
-------------------------------------------------

(2) is better than (1): it doesn't use a cond block, uses more vector ops than iterative ones, avoids needless encode. (1) came from me playing with data. i used encode to enable me to scan over `a` & `b` simultaneously. (2) reflects my understanding that comparison with `2` is really just using `b` & `~b`. the trick to making (2) work is that it uses not only boolean operations: it uses the real-valued `-` to output a 3-valued image, which i need to encode the 3 ideas during the scan: mark, continue, and reset. once a position is marked (as `1`), it continues to be `1` until it resets to `0`. a 2nd pass (`>':`) is needed b/c, on the 1st pass (the scan) we don't know, at the current position, whether the run of 1's ends here or later.

i just now refactored into solution (4), having only just now remembered about the n-ary scan form: the very thing that i'd desired initially. (4) is best b/c it has no operations at all before the scan and `>':`. to derive it, i began with `y&z` to mark, then `x|` to make the run of 1's continue, then `y&` to force `x` to be 0 if `y` is i.e. the run can continue only while `y`; my original expression was `y&x|y&z` but then i removed the redundant `y&` before `x|`. (4) seemingly cannot be written more tersely in terms of vector ops because the relations of `x`, `y`, & `z` are too complex; i cannot prove it yet, though.

solution (5) is interesting because one may think that using integers and such a common-sense solution would be best. yet look how inelegant it is compared to (4)! quite something.

.deep indexing as an alternative to transpose

[source,k]
--------------------------------------------
,/'+((2 1 4;2 4 6);(4 5;-1 3))
(2 1 4 4 5
 2 4 6 -1 3)

0 1{,/y[;x]}\:((2 1 4;2 4 6);(4 5;-1 3))
(2 1 4 4 5
 2 4 6 -1 3)
--------------------------------------------

the latter version is more general than transpose but is more verbose. it allows one to apply different operations to the axes.

===== mapping/association

* we don't use the `map` fn; it's implicit. for 1:n, it's implicit via broadcasting else explicit via `/:` or `\:`. for 1:1, it's implicit else explicit via `'`
* rather than writing loops, we use scan or fold. see the following section for discussion & examples
* symmetric relation is broadcasting. asymmetric relation is pointwise association. asymmetric relation generalizes pointwise. k makes it easy to merge relations e.g. numbers divisible by 3 or 2: `~~+/((3!);(2!))@\:!10`.

example #567 from _k3 idioms_ is worth study. it's like link:https://code.jsoftware.com/wiki/Vocabulary/curlyrt[j's `}`] or link:https://code.kx.com/q/ref/maps/#case[q's `case`]: it uses selection vector `g` to determine which row to extract from:

[source,k]
----------
x:`hot`white`short`old
y:`cold`black`tall`young
g:1 0 0 1
(x,'y)./:(!#g),'g
`cold`white`short`young
----------

===== exploit common arithmetic relations

numbers have many symmetries & asymmetries. we can exploit these greatly. not only do they generalize well, but they're terse and fast because arithmetic is fast, and on digital processors, integer arithmetic is especially fast.

alternation:: pow(-1,n). don't use it, though, since it isn't directly accessible in k6, and it's floating point. use `(~~n!)` instead, which generalizes and uses integer arithmetic.
replace `x` by `y` where `p(x)`:: `x+y*px`
choice:: `choices@f[x]` e.g. `("sell";"buy";stay)@sgn` where `sgn:((x>0)-x<0}`
boolean choice:: `:[0=y;x;y]` is better expressed as `y+x*0=y`. read `*` as "coproduct" (AND/intersection) and `+` as coproduct (OR/union)

using (multi)linear algebra to express computations is very good when applicable.

one of apls' greatest properties is that they rely greatly on arithmetic to determine selection vectors, rather than relying on higher-order functions & predicates, which are inefficient, inflexible, and must be defined. no one will ever design any system as perfect as arithmetic. when programs/logic are encoded as matrices, then _programs_ are enabled all their power: empty elements, broadcasting, boolean algebra / set union, negation, intersection.

TODO: neural nets vs bit arrays vs float arrays vs integer arrays vs any general boolean algebraic number seq, all considered wrt correlation & set intersection. intersection generalizes crrelation. it looks at where A & B occur together i.e. A intersect B. btw, neural nets' training is finished at fixpoint i.e. at an objective function's global extremum.

===== indices

don't be too hasty to use `&:`:

* sets of indices, when stored as boolean vectors, are easily unioned or intersected by using `&` or `|`. if stored as integer vectors, then union is `{?x,y}` and intersection is `{x^x^y}`. the latter two are the most general definitions for union & intersection since they demand only equality to be defined of their elements; they're less both efficient and elegant.
* suppose that you apply some predicates to a sequence. one predicate might designate the start of an event, and the other predicate designates the end of an event. to sequence the events, just put them together in a list. maybe transpose it or encode it.

[source,k]
----------
:(A;B):4 6{0=x!y}\:1+!24
( 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1
  0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1)

/ sequence A & B, preferring B when both occur
A|2*B
0 0 0 1 0 2 0 1 0 0 0 2 0 0 0 1 0 2 0 1 0 0 0 2

/ sequence A & B with full information retention,
/ in a way that generally works for any number of
/ sequences. good for serializing.
A(2/,)'B
0 0 0 2 0 1 0 2 0 0 0 3 0 0 0 2 0 1 0 2 0 0 0 3

/ decode back to input seqs
2\0 0 0 2 0 1 0 2 0 0 0 3 0 0 0 2 0 1 0 2 0 0 0 3
(0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1
 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1)
----------

of course this is obviously much easier than trying to sequence (3 7 11 15 19 23) & (5 11 17 23), especially while retaining which of the indices are of A vs B.

===== shapes & encodings

TODO: have fun coming-up with example problems & solutions where shape is exploited for elegant in/dependence and nesting.

store a list of records. this way you can use fold, stencil, etc to properly relate sequenced elements. consider the following stock candle operations:

[source,k]
----------
/    H  L  C  V  / pretend that these are valid hlcv values
dat:(28 9  16 12
     10 12 14 18
     9  10 18 16)
>':dat / compare each candle's hlcv to its prior
(0 0 0 0
 0 1 0 1
 0 0 1 0)
(|/>)':dat / candles any of whose hlcv was higher than its predecessor. returns same-length vector; 1st elt is 1 as a default value b/c the 1st elt has no prior.
1 1 1
(|/>)':dat[;0 2] / same, but consider only high & close
1 0 1
----------

to stitch tables (to add attributes to a list of records): `X,'Y` or `+(X;Y)`, which are equivalent up to distinction:

[source,k]
-----------------------
X:3 4#!10
Y:3 4#24+!12
X,'Y
(0 1 2 3 24 25 26 27
 4 5 6 7 28 29 30 31
 8 9 0 1 32 33 34 35)
+(X;Y)
((0 1 2 3;24 25 26 27)
 (4 5 6 7;28 29 30 31)
 (8 9 0 1;32 33 34 35))
-----------------------

let only your program's specifications' relations determine how you relate data. in k et al apls, relating data effectively means: 1. whether data are put into a common array; and 2. the composite array's shape; and as in all computational models, 3. coupling data as args of a (2+)-ary relation/fn. for example, if you relate two vectors, then don't put them in a list, since that's redundant; verbs already relate two vectors. so e.g. do `x+y` instead of `+/(x;y)`. don't group `x` & `y` together just because they _can_ be related. a good test of whether to de/couple data is syntax. in the above hlcv example, `>':` is very *terse and implicitly entails all of hlcv.* if i wanted to identify only particular columns, then i must add more syntax, namely in the above example, `[;0 2]`. if instead i wanted to commonly apply verbs to attributes without regard to each other, then it'd be nicer for me to not put them into a common table; i'd rather do `h-l` than `-/hlcv[;0 1]`, and indeed, beautifully, the syntax's verbosity reflects data storage & flow flow elegance. don't strive to de/couple your data; let the coupling naturally reflect the operations that you'll apply to the data.

===== know how morphisms can be rearranged/delayed

* we can factor actions (side effects) out of array ops (see the while example below)
* make stencil operations small & simple. it avoids redundant computation; you don't want to compute a hefty stencil `H` over `4 H':!10`, because that'll compute `H` 4 times for 5 and 6. `4':!10` has 28 items. also it enables you to run any number of variably-sized stencils on one array, and decouples computations from any one stencil. try to avoid stencil; there are usually more elegant, more efficient solutions. for example, moving average can be done as a fold/scan: `{(((y-1)_a)-0,(-y)_a:+\x)%y}`.
  ** a common pattern that's better than stencil is to operate on trimmed, shifted/rotated vectors e.g. rather than `3 {(x@2)>(x@0)*x@1}':`, do `{(2_x)>'-1_1_*':x}`
* if there's a (3+)-ary fn to apply, then use `.'` but otherwise it should be more efficient to express the computation as a succession of binary array operations. for example, `{(x*y)-z}.'+(10 20 30;1 0 1;2 3 4)` can be better expressed as `(10 20 30*1 0 1)-2 3 4` which saves us enlisting, transposition, and argvec application. the reason that things like `3map` exist in other langs is that there it's preferred to compose functions are reduce the number of loops, whereas in array langs it's preferable to have no functions are rely on the implicit looping of primitive binary array operations. this tip is more useful when translating functional code from a non-array lang, than in creating array code yourself.

==== shape, maps, and conditionality

TODO: merge §conditionality

shape is useful for mapping. shape replaces higher-order functions (and probably `cond`). consider:

[source,factor]
---------------
{ "racecar" "nope" "bob" } dup [ >upper ] map 2array
---------------

and

[source,k]
---------------
0 32 {`c$y-x}'2 3#("racecar";"nope";"bob")
---------------

both return

------------------------------
{ { "racecar" "nope" "bob" }
  { "RACECAR" "NOPE" "BOB" } }
------------------------------

this equivalence relies on identities; in the factor code, there's an implicit `[ ] map` that's missing because it does nothing. however, in the k code, that is seen as adding 0. the factor code is nicer in this case, but this situation generalizes to `nmap` in factor, and a matrix with _n_ rows in k.

given that we have the empty program—called `::` in k—which is an identity under application,...idk, some theorem about numbers and programs being some algebraic structure so we have a sort of equivalence and this makes programs expressible as multidimensional arrays of numbers and we can manipulate the programs just as elegantly/powerfully as "../../coding.adoc" tells, such as representing each k operator by a length 5 bit sequenece, and the rest of the machine word's bits can be used as a bit set where each position being on or off corresponds to some algebraic property being satisfied or not.

then again, a less algebraic perspective is to just say that ```{(4,#x)#x}``` is akin to `ndup`, and `map` is implicit in k unlike in factor. we could easily just do `(::;{`c$x-32})@'2 3#("racecar";"nope";"bob")`.

you can do some interesting things with shape, that basically has to do with modualar arithmetic where the modulus is the input sequence's length. modular arithmetic relates to waves being in/out of phase, or rotation e.g:

--------------
2 6#1 6 5 2 4
(1 6 5 2 4 1
 6 5 2 4 1 6)
--------------

for `y>0`, `rot:{y_(y+#x)#x}`.

===== looping

if you want to iterate through an array with persistent state, producing an array, then use a scan adverb. consider the following factor code:

[source,factor]
------------------------------------------------------------------
! 1 if cross above, -1 if cross below.
: cross ( s1 s2 -- {above/below/f} )
  [ - sgn ] 2map                                             ! (1)
  [ first ] [ rest-slice ] bi                                ! (2)
  [ [ f ] [ 2dup = [ drop f ] [ nip dup ] if ] if-zero ] map ! (3)
  nip f prefix ;                                             ! (4)
------------------------------------------------------------------

`(2)` breaks the seq into a state and a seq. `(3)` is the heart of the computation. it replaces runs of the state by `f` but if the iter elt is not the state, then the state is set to it. the state is thus not updated on each iteration. i can't use `accumulate*` (scan) because it necessarily uses the accumulated/returned value as the "prior" value in successive iterations, which is not the case here. if we express the state changes as a scan then there will commonly be runs of one value e.g. if the state is updated on the 4th iteration, then the first four elements of the scan will be `s s s s'`. so, naturally in the k version, i'll express the computation as a scan to accumulate the state, then a map which corresponds to the map over the sgn seq:

i translate the stateful scan: ```{:[y=0;x;x=y;x;y]}```. ```:[x=y;x;y]``` is the identity function! so the actual translation is ```{:[y=0;x;y]}```, which is arithmetically expressed as ```{y+x*y=0}```. you can reason about that methodically as ```*``` being and/intersection/product/implication, and `+` as being coproduct/or/else. the rest is easy. the whole repl session follows:

[source,k]
---------------
sgn:{(x>0)-x<0}
a:10 11 12 16 18 14 12
b:2  3  7  19 18 14 11
sgn a-b
1 1 1 -1 0 0 1
{y+x*y=0}\a-b
1 1 1 -1 -1 -1 1
/ next, i clearly want to identify the places where the value changes; that's =':
=':{y+x*y=0}\sgn a-b
0 1 1 0 1 1 0
/ whoops. that's not right; i want the inverse:
~=':{y+x*y=0}\sgn a-b
1 0 0 1 0 0 1
/ ok, but now i want to retain the original values; this is my mask. time to apply it to the original.
{x*~=':{y+x*y=0}\x}sgn a-b
/ set the first to 0, because it's always 0. pretty much the same as the factor version's line (4)
@[{x*~=':{y+x*y=0}\x}sgn a-b;0;:;0]
---------------

and done! the actual definiton:

[source,k]
----------
:cross:{@[x*~=':{y+x*y=0}\x;0;:;0]}sgn@-
{@[x*~=':{y+x*y=0}\x;0;:;0]}{(x>0)-x<0}@- / notice the sgn fn's lambda literal definition inlined!
----------

without the `@` between `sgn` & `-`, trying to evaluate `cross[a;b]` gives ````nyi```, which i don't understand. i'd expect that, worst case, `-` would try to use the lambda as its left arg and throw a type error. anyway, whatever. simply restricting my implementation to k primitives & arrays revealed a better algorithm!

.methods of accomplishing short-circuiting

* return the same value twice when using fixpoint
* modify the output (or another variable) s.t. it fails the "while" condition
* trim then iterate e.g. to effectively accumulate, stopping when sum>30, and printing the accumulator on each iteration: ````0:${#[1+*&30<x;x]}@+\6 11 16 21 50```. compute all the accumulator values and the earliest index whose element fails "while"'s predicate, add 1 to it, and take that many elements, convert them to strings, and print them. this example importantly demonstrates two things: 1. terminating a fold early is equivalent to completely looping through its trimmed scan; and 2. performing an action for each iteration is equivalent to performing it for each element of the scan. these are the case only when (what would be) while's predicate does not entail io. in this example, the loop body entailed io, but the predicate depended only on the accumulator, which is of a referentially transparent dataflow.
  ** unless there's operator fusion, this means more looping, which is less than ideal, but because array lang primitives so strongly suggest this pattern, the interpreters should fuse into one loop.
* using "while" to emulate a short-circuiting fold, e.g. accumulate until sum≥30: ```{30>*x}{(x[0]+x[1;0];1_x[1])}/(0;6 11 16 21 50)``` returns `(33;21 50)`. the fact of storing multiple data is kind of ugly compared to a fold that supports short-circuiting. btw, for more complex loop states, you may want to use amend/drill or the "unpack" syntax.
  ** "while" is necessary only if your loop predicate relies on or incurs side effects, including any that may be executed in "while"'s body e.g. ``(40>){`1:"> ";`I$-1_1:`}\0`` to read-in numbers until you enter one that's greater than 40; here the predicate acts on an object gotten from io.
  ** "while" is, though technically unnecessary, practically desirable if you want to avoid excessive computation e.g. given a very large vector of arbitrary numbers, find the first 10 of them which are prime. this obviously benefits from non-strict evaluation, but sadly k does not support that.

==== (avoiding) cond/jumps

first, if you're unfamiliar with the term "hot code", see the following:

. <https://www.youtube.com/watch?v=bVJ-mWWL7cE>
. <https://www.youtube.com/watch?v=r-TLSBdHe1A>

for speed and more natural program expression.

`cond`/`if` itself is not bad; rather, jumps bad because they retard execution perhaps in their own right, but namely because they're typically conditional, so the program loader must predict which branch will be taken, to load that block of code well in advance of its execution, so that we aren't waiting to load code upon each conditional jump.

i'm unsure whether `if` is slow for stack machines. if `call` [eval] is slow, then `if` is also slow simply because it entials `call`. `if` for a stack machine is linear; it's conditional `nip` or `drop` followed by `call`, and `nip` & `drop` are fast.

generally branching may be expressed as a map from natural numbers to programs (TODO: OR PREDICATES/LOGICAL VALUES?). this model describes `cond`, which generalizes `case`, which generalizes `if-then-else`, which generalizes `if then`. the "case" form can be seen in haskell: `case True -> branch1; False -> branch2;`. `if` without `else` is the same as using the empty program for `branch2`. when predicates are expensive to compute or entail side effects, then nest the maps e.g. instead of `p1->prg1;expensivep2->prg2;else->prg3`, do `p1->prg1;else:(expensivep2->prg2;p3->prg3)`. `else` does not need to be a semantic device; it can be a particular value such as a representation of infinity, or the maximum integer size, or `-1`, which is not a natural number, but is easily expressed by 2's complement. btw, such isomorphisms as this should be studied algebraically. anyway, we evaluate value(s) against predicate(s) to ultimately derive the branch number to take. there are many fine ways to do this: pass a datum to many preds in parallel, unioning their numbers into a set, then choosing the set's minimum branch number. there are solutions specific to parallelization, such as by vector ops or multiple agents running independently; and there are solutions for single-thread/agent or multi-thread all of which must sync on a mutex. design for your purpose: speed or ergonomics. remember that conditional branching is, like all programming, just mapping—just `filter` i.e. predicate intersection. `f(x)` ("f:fn of x") is `f[x]` ("f:map at x") which is a specific case of `xs [ f ] map` since atom `x` is equivalent to singleton `{x}` which generalizes to any set. if we enable `f` to map to an empty value, and assume that empty values are omitted from output, then it's `map-filter`, such as is done in prolog since predicates return values and pattern-match on their inputs, and pattern matching is filtering.

array langs are very apt for associating arguments with predicates: pairing an atom (arg) with a vector (of predicates) broadcasts, and a vector of args with a vector of predicates associates pointwise. if you use `cond` to select values rather than computations, then just run all the computations and use masks to filter aka select values.

===== algebraic consideration from 1st principles

predicates, types, logical values, maps, and the fact that all computation is relations i.e. grouping data into sets, where any datum may belong to multiple seqs/sets.

we consider coproduct & product. these are seen equivalently across types, predicates, sets, and the boolean ring, ℤ/2. consider `(∩ (HashTable k t) t)` which states that variable `t` "satisfies a property" i.e. "matches/satisfies a predicate" aka has a non-null set intersection. adopt the habit of knowing types, (1st-order) predicates, set theory. abstain from higher-order logics; they're prettier at the cost of being more constrained, complex. work with data, not programs. metaprogramming is a mistake; it suggests that code should be considered as data. what ought to be done is avoiding code entirely, using only data. this is what prolog does. true, prolog supports macros (static metaprogramming), but that merely enables custom notations (dsls), which is entirely divorced from program logic.

fixpoint is convergence to idempotency, a property common to boolean rings.

booleans concern satisfaction/sufficiency, difference. these generalize to sets, wherein they're expressed as membership and set difference. 0 & 1 generalize to naturals, which may represent set cardinalities. viewing conditionality in terms of predicates, integers, sets, is refreshing and empowering, because it means that we may use nothing more than sets to define conditionality. given that all other coding is exclusively sequences/sets, this makes conditionality just another aspect of common data ops.

==== awkward scan patterns

so there's that thing that j's `F:.` can do that would be nice in k: storing a state used for the scan yet returning functions of said state as elements of the scan. in factor we'd just store the state on the stack.

the problem that we're considering is a simpler version of the prior renko example (§<<__multiple_simple_array_operations>>). however, there i was comparing a complex loop vs multiple simple array operations; here i'm demonstrating a deficiency of k's scan operator.

.the problem
given a sorted vector of numbers, discard any that are near enough the prior e.g. `1 1.1 1.11 1.15 1.2 2 4 4.6 4.61 5` with a threshold of 0.5 becomes `1 2 4 4.6`.

this is a loop that uses a state, consumes a list, and outputs another list of a different length. this pattern generalizes a scan.

[source,k]
---------------------------------------
(0<)#{x*~=':x}{$[0.5<y-x;y;x]}\[*a;1_a]
1.0 2.0 4.0 4.6
---------------------------------------

ok, so actually i can use scan b/c i can retain the accumulator redundantly, then remove redundancies. were the accumulator a large state, then removing redundancies might be computationally expensive. this is unlikely to occur in practice, though.

of course we can directly translate into factor:

[source,factor]
--------------------------------------------------------------
unclip-slice [ 2dup - -0.5 < [ nip ] [ drop ] if ] accumulate*
0 prefix [ [ = not ] keep and ] 2 clump-map sift
--------------------------------------------------------------

NOTE: `0` & `*` in k are `f` & `and` in factor.

but the direct, obvious solution is directly encodable rather than having to formulate it in terms of scan, since we're afforded more general primitives:

[source,factor]
------------------------------------------------------
[let [ rest-slice ] keep first 1vector :> v
[ dup v last - 0.5 > [ v push ] [ drop ] if ] each v ]
------------------------------------------------------

ah, the joys of mutating basic data structures (here a queue which factor calls a "vector") and using only the most basic combinators (`each`)! this solution is straightforward, definitely efficient for this simple case, and efficient for when the accumulator is large. furthermore, it works for generalizations of this problem that can't well be expressed by a scan (TODO: identify such an example).

in case it's desired, the non-locals version:

[source,factor]
------------------------------------------
[ first 1vector ] [ rest-slice ] bi
over [ push ] curry [ drop ] [ if ] 2curry
[ dup pick last - 0.5 > ] prepose each
------------------------------------------

so the question is how to do this in k. well, we can do it any of multiple ways, and they're all a bit awkward:

.solution 1: state


.solution 2: un/packing

i hope that `a:a,x` is efficient, ideally internally pushing into a queue.

==== debugging & observation

* use trace ` \` to print arbitrary intermediate values easily
* use scan `\` to print intermediate values of a loop
* use `,` as your verb that you pass to adverbs. because it has rank infinity, it makes behavior clear compared to atomic verbs.
* if a verb train isn't working like you'd expect, then evaluate the train (in whole or parts) without args e.g. `("-"/${x+4})6 3 5` gives `4--`—clearly wrong. removing the args gives `"{-x-+-4-}"`, so our verb is obviously incorrect. btw, see "§reflection" about solving this particular problem.

''''

there is a disconnect between theoretical & actual efficiency: where `cond` can save computation, the computation is still slower than doing more-but-faster computation. habitualize looking for fast computation, not fewer computations or fewer data! *code per your specific hardware*, or if you know that you're bound to a vm, then code for that virtual hw. know your hw's primitives, and which are fastest: e.g. on x86, `xor` is faster than `mov`, and avx kicks ass; for ngn/k, `=:` is slow compared to use-case-specific alternatives; in c, malloc is slow. obviously there's some overlap among these, but you get the idea: don't just consider number of ops, or whether you're using primitives; use _fast_ primitives, and use _fast_ ops.

jumping is needed sometimes. in these cases we simply accept its requirement. in most cases, though, conditionality can be expressed without jumps, namely through the single other system afforded to programmers: bit sequence arithmetic. inherently, to operate on a vector is to effectively iterate over its elements, applying an operation on each iteration. this is the same as "do `action` _n_ times", since the sequence length is `n` and constant throughout the iteration. anything done a static number of times can be expressed as a sequence of inline statements, which avoids jumping:

`for(i=I;i<N;i++)action(i);` re-expresses as any of:

* `N I - [ i set action ] times` e.g:
  ** `7 3 dup i set - [ i get . i inc ] times` (concatenative version of stateful increment)
  ** `3 7 over - [ dup . 1 + ] times drop` (stack machine version; `i` tops the stack instead of being in a register.)
* `action(I); action(I+1); ... action(N-1);`

ultimately when this compiles to opcodes, the cpu should easily load the next chunk of instructions without prediction, so long as it has support for repeating a block of instructions a static number of times.

natural numbers generalize booleans. ℤ is effectively equivalent to ℕ.

`0` & `1` work in the linear algebra sense: `{x+y*px}` effectively conditionally adds `y` to `x` where `x` satisfies predicate `p`. `+` generalizes to any function that maps 0 to itself.

cpu opcodes e.g. simd/avx, or just gpu primitives, are our best friend. they natively support very many operations on large logical vectors, such as counting the number of ``1``'s or ``0``'s, or the number of ``0``'s before the first `1`.

when we use bitmasks instead of naturals, then we can leverage native logical vector operations. even better, lvecs, like all seqs, are implicitly sets; thus we can e.g. compute multiple predicates simultaneously (via simd) then union them and effectively do ```*&:``` on it i.e. get the earliest satisfied predicate. the kicker here is that cpus have opcodes that do ```*&:```.

some operations can avoid loops by using other primitives e.g. ```*``` is iterated `+`, and `pow` iterated ```*```. usually they're not direct substitutes, since seq vals are practically never all the same, but certain patterns may be found. the multiple methods of calculating the fibonaccis is a good example: it has closed-form expressions like binet's formula, or the even-simpler `GOLDEN_RATIO swap ^ 5 sqrt / round`. another example is `+/1+!100` vs `%[100*100+1;2]`.

.particular examples for my study

how to write oisín kidney's trie impl that fits in a tweet in k?

[source,haskell]
--------------------------------------------------------------
type Trie a b = Cofree (Map a) (Maybe b)
string :: Ord a => [a] -> Lens' (Trie a b) (Maybe b)
string = foldr (\x r -> _unwrap . at x .
                        anon
                          (Nothing :< mempty)
                          (\(v :< m) -> null v && null m) . r)
               _extract
--------------------------------------------------------------

what lesson can i learn from my following tweet?:

once i wanted to connect to named kak session if one exists. i intially wrote

[source,sh]
--------------------------------------------------
p=(ps -e | sed -n 's/^kak -s ([^[:space:]]+)\1/p')
if -z "$p"; then kak -c "$p"; else kak -s 1; fi
--------------------------------------------------

but then realized i could just do `kak -c 1 || kak -s 1`.

some cool k examples:

[source,k]
-------------------------------
{x?&/x} / argmin. ? is should short-circuit and thus be faster than *&. then again, & gives all argmins if there are multiple.

{x@&~=':x}1 2 2 2 3 2 2 1 1 1 5 / remove repeats
1 2 3 2 1 5

allEq:{x~(1_x),*x} / is a list just one element
allEq:{(1#x)~?x}   / alternate definition

{*&~allEq'+(&/#'x)#'x} / 1st idx at which seqs differ

/ indices where a run has been going on for 5+ elements
-1{y*x+y}\0 1 1 1 1 1 1 1 0 0 0 1 1 1 / interestingly, {y+x*y} is equal to {y*x+y}}
0 1 2 3 4 5 6 7 0 0 0 1 2 3

(-1{y+x*y}\)4>a / running 
0 1 2 3 4 5 0 1 2 0 1 2 3 4 5 6 7 0 0 1

/ for each run of length 3+, give the index where the run first becomes length 3
&3={y*x+y}\0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1
8 15

/ for each run of length 4+, the index of that run's last 1
-1+&<':3<{y*x+y}\0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1
,11

{`c$(x-32*-1_0,"_"=x)^"_"}"a_legal_k_identifier"
"aLegalKIdentifier"

(</(*:;*|:)@\:<) / max follows min?
"cat",/:\:"BAT" / apply function to cartesian product (here i use ,). ,\:/: is its transpose.
(("cB";"aB";"tB")
 ("cA";"aA";"tA")
 ("cT";"aT";"tT"))

?,/(0::)@/:fs / bourne shell: cat fs|uniq. gotta parenthecize 0 to disambiguate from `:` left-curried with 0; but (0:) is a train, whose leading verb is assumed dyadic unless suffixed by `:`. hence (0::).
x0:{@[{x*~x=y}':{y+x*~y}\sgn x;0;:;0]} / ±1 where a seq crosses 0. sensitive to bounces: 0=#&x0 1 0 0 1 because it never crosses 0.

(+/*)\: / multiply matrices
{x[;!|/x]} / rectangularize a ragged matrix

{@[x;m;:;z@m:&y]}["mices";0 0 1 0 1;"ABCDE"] / amend/composite [j], like mesh [apl]
"miCeE"

{1+\>':x@<x}50 49 38 27 28 25 10 38 12 49 / rank list of scores
1 2 3 4 5 6 6 7 7 8

3(2*)/1 / exponentiation
8

/ partition substrings (factor's `group-by` in the `grouping.extras` vocab)
{(&~=':10>x)_x}1 2 10 12 14 16 3 3 4 9 2 20 11 15
(1 2
 10 12 14 16
 3 3 4 9 2
 20 11 15)

/ same, but apply average to each substring, then match the averages to the original sequence
{x,',/(-':(1_i),#x)#'{(+/x)%#x}'(i:&~=':10>x)_x}1 2 10 12 14 16 3 3 4 9 2 20 11 15
((1;1.5)
 (2;1.5)
 (10;13.0)
 (12;13.0)
 (14;13.0)
 (16;13.0)
 (3;4.2)
 (3;4.2)
 (4;4.2)
 (9;4.2)
 (2;4.2)
 (20;15.333333333333334)
 (11;15.333333333333334)
 (15;15.333333333333334))

/ same thing, simpler data; except that i put 0N for starting values
{a:,/(-':(1_i),#x)#'>':x@i:&0<x;x,'@[a;!*1_i;:;0N]}0 0 0 6 0 11 7 0 0 0 0 15 0 0 0 0 14
(0 0N
 0 0N
 0 0N
 6 0N
 0 0N
 11 1
 7 0
 0 0
 0 0
 0 0
 0 0
 15 1
 0 1
 0 1
 0 1
 0 1
 14 0)

/ latest value of x that satisfies a condition
{{y+x*~y}\x*6<x}1 6 8 9 5 2 4 7 6 1 12
0 0 8 9 9 9 9 7 7 7 12

/ running count of elements that have satisfied a predicate
{{x+~~y}\x*6<x}1 6 8 9 5 2 4 7 6 1 12
0 0 1 2 2 2 2 3 3 3 4

/ 0 for =, 1 for >, or 2 for <
{(~x=y)*(1+x<y)}':6 6 11 7 7 7 7 7 15 15 15 15 15 14
1 0 1 2 0 0 0 0 1 0 0 0 0 2

/ TODO: identify what these do exactly. yeah i wrote them but w/e.
substrs:{({(y-x)#x_z}[;;x]/)@/:y} / with y, a list of intervals as an n×2 array, get substrs of a vector x
/ substr:{{(z-y)#y_x}[x]/y} / above but used as 2substr[myArr]':idxs
-------------------------------

.functional `cond` demonstration

factor-style "cond":

TODO: this is hacky; it works only if `x` is atomic, since in this case `.` is forced to not see `x` as a deep index, but instead use it just the same as `@`

[source,k]
-----------------------------------------------------------
cond:{({~x.0 0,y}[;x](1_)/y).0 1,x}
cond[5;(((7=);{"seven"});((5<);(10*));((~2!);{"even"}))]
5
-----------------------------------------------------------

* "while" short-circuits. it's "while not head pair's predicate, behead". then apply head's body to args.
* i use a projection to get around the "nested lambda namescope" problem.
* notice `.0 1,x`; use one indexing vector to select the head's second element then apply argvec `x` to it—a beautiful benefit to k's indexing/function equivalence.
  ** we do the same with `0 0,args`
* instead of handling an "else", it returns the input as-is if no case matches.

i wrote this only to show that k is as capable as lisp/factor; there's no reason to not use k's built-in conditional construct (for those few times when you actually need it.)

== ngn/k bugs & todo's

* flip (+:) applied to a list of only iota (!:) arrays gives 'OOM e.g. +,!1
  ** didn't happen on my arm arch linux when compiled with clang-18
* `{x=5:'&/x}1 2 4 3 5 0 4` causes k to print an error then silently exit
* if not already done, use floyd-rivest algorithm to select kth order statistic instead of literally using quicksort then selecting the kth element.
* implement semantic highlighting in repl/text editor

something here crashed k (SIGSEGV (core dumped)):
-----------------------------------------------------------
@('/4)
@('/)4
/4
'4
@'4
@('4)
-----------------------------------------------------------

running `{((#x)&4+*&"."=x)#x}"4"` causes k to hang!

== ngn/k c ffi

there are two distinct ways to interface k & c, and idk if they can both be done vs whether only one may be done at a time: the "embed" method (call k from c) or the "extend" method (call c from k). the trouble with choosing these is that each has its own makefile; we must build a modified version of the k interpreter to make it support dynamic loading of shared objects.

=== call k from c (the "embed" style)

run k from within c e.g:

[source,c]
-----------------------------------------------------------------------
#include"myfile.c"
int main(){
 kinit();            // always call before invoking any k-related forms
 KR("add",Fadd,2);   // register a c fn with k
 setbuf(stdout,0);   // disable buffering on stdout
 Kx("`0:$add[2;3]"); // run k from within c
 return 0;}
-----------------------------------------------------------------------

to enable this:

NEXT

=== call c from k (the "extend" style)

run fns defined in c from within the k interpreter/repl/source e.g:

[source,k]
----------------------------
add:`"./libadd.so"2:(`add;2)
add[3;5]
----------------------------

to enable this:

as `k/extend/makefile` says, in the k repo root, run `make c` then, in `makefile`, in the `k` build rule (the line starting with `k:`), add `-Wl,-E` to the end of `L`'s options (you'll see a comment about this on that line); then `make k libk.so`.

=== defining functionality in c

now that you've enabled ffi functionality, it's time to write some k-compatible fns in c.

in c, k data are represented as data of the `K` type, a `long long`, which is enough to encode the K vm object type on a 64-bit arch (64-bit architectures are the only ones supported by ngn/k). fns to convert data representation from c to k are named like `K□` where □ is any of the following:

[options="header"]
|==================
| type     | letter
| `int`    | i
| `double` | f
| `char`   | c
| k symbol | s^*^
| k list   | L^†^
|==================

^*^you cannot directly represent a k symbol in c; you must represent it as a string.
^†^the list, of course, has no atomic form, and so is always capitalized

and the letter is capitalized if converting an array thereof. to convert from k to c, use a fn named `□K`. for lists of c objects, you must provide the c array and its length; this is why e.g. `KI` takes two arguments. the `void` fns such as `void IK(int*,K)` store the equivalent `K` object in the address given by the given int pointer, rather than allocating new memory and returning that pointer. thus you can think of `void IK(int*,K)` as `int*IK(K)`.

.myfile.c
[source,c]
-----------------------------------------------------
// idk when stddef is needed
#include<stddef.h>
#include<stdio.h>
#include"k.h"

// define a fn which can be called from k as an mexpr
K add(K x,K y){return Ki(iK(x)+iK(y));}
-----------------------------------------------------

=== details about the k ffi

the ffi types are defined in `k.h`. the descriptions of k->c & c->k conversion fns is given in `k.c`.

ignore `WV`; it's a technical detail.

.understood callable forms (fns & the `Kx` macro)
* `KR(name,c_fn,nargs)`: "k register" (i guess). make a fn `c_fn` defined in c callable as `name` in k as an mexpr
* `K0(K* o,const char* s,K* args,int nargs)` runs k source code string `s` with list of k args `args` & `nargs`, then stores the result in `o`.
* `Kx` runs some k code (s,a...) ({static K f
                                   K0(&f,s,
                                      (K[]){a}, // idek what this c syntax means
                                      sizeof((K[]){a})/sizeof(K))
                                  })

.not yet understood fns
* `TK(K)` returns a `char`
* `unref(K)` mark passed obj for garbage collection (TODO: i guess)
* `void*dK(K)`. totally no clue what this might do.
* some `void` fns clearly associated with c objects and k objects (of probably equivalent types). being that they don't return anything,...what would they do, i wonder? i notice that all the ones that take pointers also take `size_t`'s, so those're almost certainly lists & their lengths.
  ** `CK(char*,K)`
  ** `LK(K*,K)` KL(K*,N) for k array
  ** `KA(K,K)` for lists of k objects?
* K KC(C*,N),ref(K),Kp(V*),KE(S),

