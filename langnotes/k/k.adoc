= k
nic chandoke's notes
:toc:

k3 & k6 much differ. this document details k6 & ngn/k yet. a section comparing k3 & k6 will be added. it's been implied that k3 & k4 are practically interchangeable, as are k5 & k6.

== metanotes

this doc discusses k as a proglang, an apl, k itself, and specific implementations of k, in that order.

=== apls

* applicative, not concatenative :( expect to use parens. at least it's semi-concatenative; parens aren't needed for _all_ subexpressions—only some, like haskell's `f . g $ x` notation. in fact, k's type-based multi-dispatch and syntax make it quite like a lean, interpreted haskell that disallows adding new types and whose builtin types are simple.
  ** fortunately, afforded by limited arity, arguments are not named.
  ** effectively, pointfree/tacit notation is used when argument are passed to a (composed) function.
  ** no support for multiple outputs, except as effectively done by returning them as (boxed) array elements, but this requires unpacking. this would be fine if we could pattern-match them out like in ml, haskell, erlang, prolog.
* i'm unaware of any debugging tools! 81
* overloaded 1/2-adic operators
* no (good) support for 1st-class functions, let alone programs. like factor, such things are done by quoting programs (as strings or boxed nouns) then effectively calling `eval` on them; however, unlike factor, apls are not homoiconic, and one must manipulate syntax, not program objects (e.g. factor word sequences or lisp sexps).
* non-concatenative. simple, terse, but hard-to-read syntax
* operations are symmetric over sequences of char or num. the sequences are: for apl, n-dim flat; for j, that or boxed; for k, linked lists, so effectively everything is boxed, except there's no unboxing; all arrays are ragged, so there are no fill rules. idk if k has rank like j does.
  ** note that flat or homogenous arrays are quite constrained; generally data is non-uniform in its dimensionality and type. a language should never have a ceiling on generalization! not only does it limit power, but expressivity, too. for example, if we take integration and differentiation to be dualistic, separate operations, and force them as primitives, then we cannot afford unifying them as fractional derivatives/integrals. i'd much rather have D(1) & D(-1) than ∂(1) & ∫(1) (and D(-2) instead of ∬), and i want to be able to implement that myself if the language hasn't already done it for me.
* usually interpreted

=== k

* canonically, tiny language implementation, built for speed & brevity, and rebuilt from scratch often
* especially overloaded; even an operator with a given arity may have many entirely different definitions depending on its arguments' types.
* nomenclature is same as j

==== k vs j

k is categorically better than j:

* vectors instead of arrays
  ** no boxing
  ** no rank system; simply use adverbs to iterate
  ** 1st-class functions can be in vectors plainly. no particular system like gerunds. you can stright-up do `(*{4+x},3 4)@64`
* dicts (i'm unsure if these are inferior to vectors of arbitrary-type/shape elements. at least dict-fn-vec equivalence is good.)
* fewer, overloaded verbs is better than more verbs many of which have a colon, which is harder to read
* verbs can actually be defined with more than 2 args
* more-sensible verbs both by notation and functionality e.g:
  ** `f\` instead of `f^:a:`, which is a more consistent mnemonic and syntactically plainer
  ** `#` instead of `{` & `}`
* there's no function composition in k...not sure if that's better or worse. j's fncomp was good but flawed; i'm unsure whether such things should be boldy discarded, or retained despite that they only offer convenience rather than a robust programming code.
* k is easily learned in a weekend
* because j verbs aren't 1st-class, j has a special tacit dsl. b/c k verbs are 1st-class, there's no need for a dsl; we can just define combinators such as `fork2:{[f;g;h;x;y] g[f[x;y];h[x;y]]}`. that being said, (ngn/)k _does_ have a dsl, described below.

.differences from j

* user-defined k verbs can have only one valence. this asymmetry against builtin k verbs is odd but not necessarily bad. then again, user-defined k verbs can have up to 8 args.
* in k's grammar, all the following are nouns: parenthesized exprs, lambdas, identifiers.

k's trains differ from j's:

.k trains
[options="header"]
|===========================================================
| name                      | juxtaposition seq | definition
| "projection" (left-curry) | N V               | `(xf)y` <=> `xfy`
| composition               | N/V ... V         | `(fg...h)[x;y]` <=> `fg...(xhy)`. `(fg)xy` cannot be applied in-place e.g. +++(5+)(*)[6;7]+++ is valid (47) but +++7(5+)(*)6+++ is a type error. example from link:https://ngn.codeberg.page/txt/tacitjk.pdf[ngn's pdf]: +++(1-_%*)[x;y] <=> 1-_%*[x;y] <=> 1-_%x*y+++
|===========================================================

these terms are used in ngn/k's quickref.

k' trains' utility is mainly refactorability, but also brevity.

* hook as a k train: `f/1 g\`. `1 g\` produces a 2-vector `(x;g x)`; then fold `f` over (insert between) those 2 args.
* fork as a k train: `g/(f;h)@\:`. it applies each of `f` & `h` to the argvec, returning a 2-vector, then folds `g` over (inserts between) those results.
* `({10+x};(20+))@\:15` returns `25 35`

verbs in j but not k; i wonder how to implement these in k:

* key (group by)
* rotate & shift (in k3 but not k6). these are just index transforms with mod, max, or min.
* is `=` equivalent for j & k. j uses logical vectors whereas k uses indexes.
* k has no support for complex numbers? kinda whack. `%-2` gives `-0n`.
* no `E.` in k? `E:{((#y)':x)?y}`. (ratpack) parsers are better, though, since they generalize from mere equality to powerful patterns.

=== implementations

i'm going to consider this only after i use ngn/k. i'll use it as my _de facto_ k before i choose another, just because it's said to be good, and it's accessible, easy, small. it's perfectly sufficient for using and learning k. i can choose practical versions later, after becoming familiar enough with k to immediately appreciate nuances among implementations.

[options="header"]
|=======================================================================================================
| name                                                 | impl lang | k ver | notes
| link:https://github.com/ktye/i[i]                    | go        | ?     | -
| link:https://anaseto.codeberg.page/goal-docs/[goal]  | go        | -     |
| link:https://codeberg.org/ngn/k[ngn/k]               | c         | 6     | unmaintained since jan 2024
| link:https://github.com/kevinlawler/kona/wiki[kona]  | c         | 3     | 1st open k, so good wiki
| link:https://t3x.org/klong/klong-ref.txt.html[klong] | c         | -     |
| link:https://github.com/zholos/kuc/[kuc]             | c         | 5     |
| link:https://github.com/JohnEarnest/ok/[oK]          | js        | 5,6   |
|=======================================================================================================

=== why/when to use k

measured by criteria in `~/codenotes/langs.adoc`, k scores high. it isn't ideal, but it's close. about the only real issue with it is that it's semi-concatenative; fortunately in practice this is probably tolerable if you style your code well, especially with k being so terse. to be determined.

* scripting: terse, no imports needed, interpreted.
* dataflow notation, or if you've been using character-stream based interfaces enough to be tired of typing loads of shit, without typos, often redundantly many times
  ** it's really cool to be able to memorize programs or use low interfaces such as a smart phone, small keyboard, or just pen & paper to develop code. pen & paper isn't too much worse than the interactive repl, since the repl doesn't have a debugger anyway.

the whitney design argument about seeing all code in one place is good. however, to accomplish this by making code syntax terse assumes that we're displaying text in the common manner in a text editor. because text is a much poorer code than graphical ones, and should generally be so deprecated anyway, the terse syntax argument is moot.

*an important reason to use k* is to become familiar with its primitives: sets, seqs, maps. k is all the good primitives and structures. regardless of whether you use k, everyone should master designing k programs so that they can use those designs in _all_ programming, hopefully in a tacit, readable, metaprogrammable, virtual-operation language. it's also small enough (20 prims, and short code) that you can reason about it in your mind. you can even memorize codes by using person-object-action mnemonics.

=== my opinion of k, now using it after i've become most used to factor

* k's ridiculous overloading is awesome. it's not an issue as long as the operator's context is clear, which is true when using literals or conventions that preface variables with a single character denoting their types.
* parsing is easy (but takes some practice) as long as i can read rtl, notice verb-adverb pairs, and know that left args are delimited; i don't want to ever deal with operator associativity levels. those suck. reading from the right is odd, too, since it makes newlines special syntax.
  ** consider this arbitrary k code: +++:m:(("forward";"down";"up")~/:\:d[;0])*\:d[;1]+++ i tried copying then evaluating +++d[;0])*\:d[;1]+++ to see what its value was, to try to visualize what's happening, only to find that it's malformed: there's a mismatched right parenthesis! fair enough, but not nearly as readable as factor. it's the same parsing as we see in factor: parse from one side, then parse a delimited subprogram, then consider them together. the same code, in concatenative style: `d [;1] d [;0] ( "forward" "down" "up" ) ~/:\: *\: m: :`. the whitespace makes confident parsing by eye much faster & easier! the dis/association is immediately obvious. refactoring is a load easier, too; if seeing the parens is already error prone, imagine what hell refactoring is; if you mismatch a parenthesis, then you're screwed! and because of k's extreme overloading, your mistake program may give a _totally_ different result from what you'd expected, so identifying what the refactoring mistake was would be very difficult & painful. the concatenative syntax shows that the code can be factored in the beginning, too: `d [;1] d [;0]` becomes `d [;1] [;0] bi`. we can then remove the input, `d`, and have a subprogram disassociated from any arguments. it also shows that parts of the program are related by `d` commonly and are computed next-together; the delimiting/separating parens of the original k expression suggest separation of `d[;0]` & `d[;1]`, and it's not obvious to think that they're computed next-together.

TODO: why doesn't this happen in good factor code? when i was new to factor, my code was horrible because i was doing manual loops, but also that i would build-up the stack in complicated ways, leaving a complex stack to be consumed by various subprocesses such that my code didn't permit easy refactoring, which is analagous to this unreadable k. i think it's because i used stack words instead of combinators and quotations. *one thing's certain: programs are easier to consider as incremental state changes than as gargantuan monoliths of nested subexpressions.* compared to factor, maybe the k code is weird b/c the parenthesized part is an expression rather than a program, and that the parenthesized expression is an argument to a verb rather than an adverb?

anyway, other booboo about the k code:

* perhaps, tracking order in which ast is evaluated is difficult, which would be an issue for non-pure code.
* though we usually read from right to left, this code is more easily read from left to right, since the left arg to `*\:` is more complex.
* parsing-out `~`, `/:`, and `\:`, among an arbitrary line of such code, is ugly. i don't care if the computer can do it; i'm a human, and such coding is unnatural and thus error-prone, stressful, and inefficient for me.

==== k vs factor

if k were purely tacit / concatenative, and readable, then it'd be perfect. k is tolerable, especially with syntax highlighting and judicious spacing. k is semi-concatinative: it supports trains and mostly reads in one direction. it accepts parameters inline, but rarely more than two, and when it uses two, it often does not require parentheses, which makes refactoring easier. if k were purely tacit, then statements would be able to span multiple lines, and the dyadic syntax wouldn't exist anymore. it has nested expressions, but nesting does not commonly go very deep. when it does, it's good style to refactor it into a subexpression or helper function. the nesting/monolith problem can be, as it can be in factor, solved by instead defining many small words. in both these langs defining words is low-overhead: in factor it's `: name effect def ;` and in k it's `name:{def}` (if 3 or fewer parameters) or `name:{}`. in both cases, definition is just a literal program but wrapped in delimiters then associated with a name. even in scheme, where this _can_ be done, it rarely is: usually we say `(define (name . params) def)` instead of `(define name (λ (params) def))`. scheme sucks because: 1. these are two significantly different syntaxes; 2. even the shorter syntax is non-ergonomically verbose.

''''

.aside: function arity

how _exactly_ to decide which parameters fns take? the following are considerations & observations that seek to answer.

. is it better for fn to take params, or have them one param but pattern match it into subsets?
. are variadic fns worth anything? even factor can use macros to inline fns and assert their stack effect statically. it'd be nice to not have to specify a number to e.g. `nmap`, but w/e.
  .. are variadic fns useful only for coding ergonomics i.e. are they always fns known at runtime?
. sql's model of queries essentially being pattern-matching fns of relations is good. a sql table can be made by reading json, so tables can be added dynamically, which is good.
. higher-order fns are bad: the ability to define them encourages one to parameterize _arbitrary_ parts of the computation; though these parameters are common, eventually, inevitably, a user will want to parameterize a different part of the computation, or for the parameter to be of a slightly different nature. because data can be modified (easily) and functions cannot (easily be modified), it's better to have functions be so small that they're sensibly defined only of a small variety of inputs. this avoids the arbitrary-degree-of-parameterization problem.
  .. b/c fns should take a small variety of input information, the number of inputs should naturally be few.
. fns should return many outputs, to preserve its computation. the user may decide to discard those outputs, rather than the function deciding to discard them by simply not returning them. returning multiple outputs is much easier if we pattern match elegantly. for stacks, it'd be inelegant to use `ndrop`, `nip`,  &c frequently. in applicative langs, it'd be ugly for many multi-parameter positional bindings to feature many holes. eliding outputs is best done in sql: rather than using binding clauses, the outputs are named by the function. one may rename them (and indeed must occasionally do that to disambiguate). anyway, the lack of binding clause and ability to tacitly refer to variables is excellent.

''''

* k has subexpressions. factor has only subprograms, b/c it's purely tacit.
* needing to "lookahead" to the left of a verb to determine whether it's unary or binary is horrible. look at this definition: `quicksort:{$[2>#?x;x;,/o'x@&'~:\x<*1?x]}`. how long does it take you to tell me what the hell is going on here? does this code feel natural? you should start parsing from the left because that's how `$[...]` evaluates; but then each of its argument programs you should read from the right, since that's whence they evaluate. the first predicate and corresponding return value are short enough that parsing happens instantaneously; you read it like a simple mathematical expression. of course it's in the "else" clause that things actually start getting k-ish. remember that to read source code, we must tokenize. starting from the right, i see `x`, then `?`, so i would like to think `?x` but i must lookahead to the next token to see that it's a noun, `1`, so now i've parsed code into an actual semantic value, `1?x`; then +++*+++'s meaning is unknown until i read the following token, which is `<`, so now i know that `*` is monadic, meaning "first"; then i still don't know what `<` is until i read the next token, which is `x`, so `<` is dyadic "less than", then `\` is a unary or binary adverb partically depending on whether any verb to the left of its 1st argument is a verb or not. in this case, it is given as the verb `~`, so i know that the "while" form of `/` is used. don't mistake it for the adverb `\:`, btw. anyway, next is `x@&'`? `&'` is "each &" which is monadic b/c the next token to the left is `@` which is not a noun. contextual grammars make _tokenization_ so difficult, before i even get to imagining the actual logic that the tokens denote! (btw, if you're curious about how quicksort works, see the explanation in <<_examples>> below.) though this is true generally, i think that k has a good chance of being readable simply because it's so small, so one can become familiar with the few verbs, idioms, and potential ambiguities, despite them being _generally_ of confusing design.
* where k beats factor (in practice; factor has strictly greater capability):
  ** terse: avoids shit that isn't strictly encoding the program logic itself. needing to type multiple characters is a needless pain just like needing to compile, or scaffold a project, or any other assumed, imposed constraint that could theoretically be removed or modified without affecting the program itself. we are humans coding; our needs are important, and our coding methods must reflect that! the code itself is generated by our methods, and is so related to them; it's appropriate for us, as one aspect of our method, to choose codes that suit our ability to code them and reason about them!
  ** overloaded: each verb is a concept with multiple varieties as it's applied to specific contexts (nouns). this is a natural separation and combination of verbs and nouns, which makes reasoning about program design easy. it also avoids trying to name conceputally similar or homomorphic operations e.g. in factor the separate words `remove` for sequences and `delete` for sets, despite them being the same damn thing! but nope, due to types, they aren't interchangeable!
  ** powerful mechanisms for relating structures' elements
  ** lookup is assumed when a noun is used as where a verb is expected
  ** dictionary/vector symmetry
* where factor beats k:
  ** walker (debugger)
  ** concatenative. in a nutshell: incremental data pipeline construction, spilicable & (re)factorable programs
* both have excellent documentation. factor's is interactive at the cost of being specialized, whereas link:https://codeberg.org/ngn/k/src/branch/master/repl.k[k's] is accessible since it's just text. it's small & succinct.
* to be able to collect intermediate values from any loop is cool. the backslash verbs do this.
* very optimized, small implementations are very cool: they afford codes that would otherwise be too inefficient. still, though, mostly virtual operations afford that.
* the stack's excellence is questionable because function parameterization is questionable. having separate inputs instead of one which is pattern-matched against is questionable.

===== common factor patterns done in k

k is semantically scheme [lisp] but with apl-ish syntax. scheme, prolog, factor, and probably all other homoiconic languages are prefectly general and equivalent in their capability; no hacks are required, and all paradigms can be defined by these languages. thus k is as capable as factor. here are some common "powerful" factor idioms translated to k.

[options="header"]
|============================================================
| factor                       | k                  | comment
| `7 [ 10 * ] [ 5 swap - ] bi` | `((10*);(5-))@\:7` | k uses only seqs, whereas factor has a false dichotomy of seqs vs the stack. k's better b/c no swap and only one structure. also if i use `7 8 9` instead of just `7` then i'd have to change the factor code to include `map`, but no such need in k.
|============================================================

== k notes

=== semantics

* apparently evaluates from the left, as `(b;(c;d)):(2 3;4 5);c` suggests; `c` is to the right of `;` yet at that time `c` has the value 4.
* vector—not array—language.
  ** dicts are just pairs of vectors. they are ordered.
* an n-dim vector maps n coordinates to its unique elt
* scalars are exactly 0-dim vectors. an empty vector can be used to index into a scalar.
* like j, verbs may be _atomic_: they apply to all atoms of a vector (TODO: what about dicts?)
* scalars are broadcast
* functions and indexing are one operation. this is appropriate when we consider functions as maps from dom to cod i.e. (10+)@12 can be equivalently interpreted as "the map that adds 10, indexed at 12" (an interpretation which i strongly encourage) or "pass 12 to the function that returns 10 plus its input." this enables `{10+x} 5` to work; `{10+x}` is not a verb; it's a noun! thus `{10+x} 5` satisfies the subgrammar, "noun noun". juxtaposed nouns are evaluated as "index left noun by using right noun as index". because of function-dict equivalence, to access a function as a map is to invoke it on its argument.

TODO:
* what are "tables" and "prototypes?" the link:https://wiki.cor.fyi/wiki/Ngn/k[k wiki] says that ngn/k supports tables w/o prettyprint, and partial support for prototypes. kona hasn't tables but has prototypes.
* why does `(-)@4` return `-[4;]` i.e. "apply `-` to whatever the quoted series of programs `[4;]` returns"? note that `[4;]` is the program `4` followed by the empty program, which returns nothing.

==== really cool k semantics to incorporate in other langs

* funcall/index duality. `@` is "index x at y" or "call x with argvec y"
* functions are implicitly quoted simply by parenthecizing them e.g. `(-),1` returns 2-element vector `(-;3)`; this is because k's grammar is contextual, and a verb by itself (without args) is considered as a noun; thus, because in the parenthecized `-` is a noun and thus `,` joins two nouns into a vector.
  ** to invoke the essentially-quoted verb, use `@`
* homoiconic syntax & output i.e. if you copy any displayed output then it's a valid data literal in that syntax
* contextual grammar and thus contextual evaluation of deferred/quoted expressions
* a single variable can refer to a set e.g. in `{4+x}`, `x` can refer to a vector. ideally it would, like in prolog, refer to a (constrained) set. as an honorable mention, sql variables also refer to sets.

hopefully rank must be explicit in k. rank should always be explicit as a general coding convention. k's `each` probably does that.

.beautiful dictionary/vector symmetry

each'ing (a monadic verb) over a vector applies to a vector's elements, not its indices. likewise, eaching over a dict applies to its values, leaving its keys in tact e.g. `{5+x}'`a`b`c!1 2 3` returns ``a`b`c!6 7 8`.

[source,k]
&`rita`bob`sue`adam`frank!0 0 1 0 1      / keys which have a value of 1: `sue`frank
(`bob`adam`sue`rita!23 54 12 82)?12      / find key by value: `sue. if vals were ordered, then we'd be able to use X'
&5=`bob`adam`sue`rita!5 1 5 3            / all keys having a value 5: `bob`sue
|\`rita`bob`sue`adam`frank!12 7 87 32 11 / returns `rita`bob`sue`adam`frank!12 12 87 87 87

=== types

types are here listed with a common shorthand:

[options="header"]
|======================================================
| sym               | name                | empty value
| c                 | char                |
| i                 | int                 | 0
| n                 | number (int\|float) | 0[.0]
| s                 | symbol              |
| a                 | atom                |
| d                 | dict                |
| f                 | monadic func        |
| F                 | dyadic func         |
| any of x, y, or z | any                 | <n/a>
|======================================================

excepting `F`, a lowercase letter means a scalar, and a capital one a vector; e.g. `C` means a string and X or means "a vector of anything."

these symbols are used by cast ($/2) and type (@/1).

=== syntax

* right-associative
* conditional branching: `:[p1;f1;p2;f2;...;else]`
  ** dollar sign may be used instead of colon
  ** `0` & `()` are falsy; all others are truthy
* newlines behave identically to semicolons. this enables you to directly code pretty-print matrices: one row per line.
* literals:
  ** `[stmt1;...]` is progn [lisp] i.e. all statements except the last are evaluated only for side effects, and the last statement's value is returned from the whole bracked expression list. this is the same as the comma operator in c.
  ** symbol: +++`sym+++
  ** vector: `(a;b;...)`
  ** generally list literals are sequences of homogenous-type data literals.
    *** the following must be parenthesized and its elements must be delimited by semicolons:
      **** hetrogeneous lists' of literals
      **** lists of non-literal nouns
      **** lists of lambdas (this prevents applying the lambdas to each other)
    *** exception: logical vector literal: [0|1]*b e.g. `10010b`
  ** dict: `[k:v;...]` but therein, symbol keys are not prefixed by grave accent
  ** function:
    *** `{[arg1;...] definition}`
    *** `{...}`. unary fns arg is called `x`. then add `y` and `z` to namespace as arity increases to 2 or 3. example: `{z%y+x}[30;20;10]` returns 0.2.
    *** fns may use semicolons; then they're the progn but parameterized by xyz
  ** null: `0N`
  ** negative literals are as in most langs: hyphen immediately followed by a number literal
* slash begins line comment
* `o` is like apl ∇ e.g. `{$[x<2;x;+/o'x-1 2]}9` returns 34. technically `o` is a special noun, not a special syntax. thus it can be used infix-dyadically or with the usual function application/indexing operators/syntaxes. of course, then, `o` is used commonly for recursion. however, maybe it can be used to return the current fn to another fn, for e.g. fn callback sequences; i'm yet unsure. idk if `o` captures the current continuation (or if k even uses continuations as they're in scheme or factor) or what.
* `(v;...):y` pattern matches/binds e.g. `(b;(c;d)):(2 3;4 5)` binds `b` to `1 2`, `c` to 4, and `d` to 5.
* juxtaposed nouns (`y x`) or `y[x]` evaluate as `y@x`. multi-parameter function punning also works: `x[i;j;...]` is the same as `x.(i;j;...)`
  ** omitting an index on a side of a semicolon means "all" e.g. `(4 5#!20)[;1]` returns the 2nd column, `1 6 11 16`
  ** selecting multiple indices at depth (a mix of amend & drill): `(4 5#!20)[(0 1;1 2)]`. the parenthesis make this one vector index rather than multiple nested indices.
  ** indexing into a dict is the same as indexing into a vector, but with the dict's keys instead of an integer index
* setting a value at a given index: `m[i;j;...]: v`. `m[i][j]...:v` is illegal. drill is better.

you can put into a dict `d` by the following syntax: `d[`k1`k2`...]:v1 v2...`.

TODO: understand indexing exactly. `(4 5#!20)[0 1][1 2]` differs from `(4 5#!20)[0 1;1 2]` and isn't indxing at depth (so says xpqz). he may certainly be correct, as idk what semicolon means.

=== verbs

NOTE: suffix `:` forces an ambivalent verb's monadic form.

* verbs may be left- or right-atomic, or apply to the whole argument (in j this is rank infinity or rank _1).
* in this table, i mean `x` as the left arg and `y` as the right.
* useful verbs—the ones that help you design dataflow programs—are in bold

the following table's verbosity is between link:https://github.com/JohnEarnest/ok/blob/gh-pages/docs/Manual.md#verb-reference[oK's verb table] and the <<_ngn_quick_reference>>.

[options="header"]
|=============================================================================================================================================================================================================================
| symbol     | monad                                                   | dyad
| `s:x`      | identity                                                | almost always used as _bind local_ (`s` is an identifier.) also, if `s` is a datum literal, then `s:x` returns `x` i.e. it's the "right" function, which is useful in the verbs "amend" or "drill"; this use of right is necessarily useless inline, but the right-curried version is useful.
| `::`       | identity                                                | bind global
| `,`        | make singleton of +1-dim                                | *concat*
| `<f\|i>#x` | *count*                                                 | *1. shape: `\|i\|<#x` means _take_ [from end if `i<0`]; `i>#x` means _repeat_. or 2. if `x` is a dict: select entries by (symbol or char) keys `i`; or filter `x` by `f`* (generally f returns a natural which is the count; 0 & 1 are the most common)
| `+`        | transpose                                               | add
| `-`        | neg                                                     | sub
| `*`        | first [val, if dict]                                    | mul
| `%`        | sqrt                                                    | div
| `!`        | i. (0D) / permutations (1D); or dict's *keys*           | dict of `keys!vals`, or `div` if `num<0`, or `mod` if `num>0`; *div & mod are `denom!num`*
| `&`        | *idxs of non-0's*                                       | min (implicitly boolean product)
| `\|`       | reverse                                                 | max (implicitly boolean coproduct)
| `<` & `>`  | *grade* [keys] up or down; or open/close file/socket/fd | less or greater than
| `=`        | partition into nub & idxs; or identity matrix           | atomic equality
| `~`        | not                                                     | match (same shape, values, *and types*)
| `^`        | `null?`                                                 | set `x`'s nulls to `y`, or *`Y` without any of `X`'s elts*
| `_`        | floor or `>lower`                                       | *`i_X`: drop [from end if `i<0`]; `Y_i`: `Y` without ith elt; `I_X`: split `X` at `I` (which must be monotonically increasing) into non-overlapping substrs*; `f_X`: filter-out
| `$`        | convert elts to strs                                    | x:ℤ, y:str: pad on right (or left if x<0); type cast (see below)
| `?`        | *nub*                                                   | *find*, return idx; or n rand vals of set given by y. x<0=>pick w/o replacement, in which case `\|x\|>=#Y` => length error, where Y is the set described by y.
| `\` & `/`  | while (adverb)                                          | C/C: *join*. C\C: *split*; as in j: I/I decode, I\I encode. behavior about shaping transcodes varies among k implemenations.
| `.`        | eval k syntax string, or get a dict's *vals*            | call `y` with argvec `x`
| `@`        | type                                                    | *`y` at `x`*
| `'`        | each (adverb)                                           | *interval index* (j's `I./2`). generalizes binary search.
|=============================================================================================================================================================================================================================

.colon madness
--------------
when you see a colon in code, it's one of 3 things:
. definition (identifier on the left)
. one of these adverbs: window (`':`) or each left/right (`\:` or `/:`).
. force a verb to be monadic (builtin verb on the left)

never will it be a literal, but if it _were_, then it'd mean "ignore this literal."
--------------

* +++*/1+++ returns an atom whereas `(1#)` would return a singleton.
* `X'` isn't an adverb because it doesn't modify a verb. if it's technically implemented in the parser as an adverb, then that's a hack, not a reflection of actual logical truth.
* is there really no ≤/≥? to be fair, those aren't really helpful; for integers, just +1 or -1, and floats aren't precise anyway, so equality is an infinitesimal difference anyway! instead of `gte 0` you can do `>1e-9`.
  ** or, rather, ≤ is not greater than: `~>`
* there's a floor but no ceiling! this is ok: ceiling is so defined in factor: `: ceiling ( x -- y ) neg floor neg ;` indeed, even floor isn't a primitive in factor.
* reshape with `0N` means "unbounded" e.g. `0N 3#!10`
* example i/o: `myFD:<`"/path/to/file.txt"` then `>myFD` to close it.
* `=/1` isn't useful. link:https://gist.github.com/chrispsn/3450fe6172a7cc441d0819379ed3a32a[it was also replaced by a function called "frequency"]
  ** btw, i have no idea how `(&:)?` is supposed to be run-length encoding. i get an error in ngn/k, which i'd expect. `&` is already monadic, so `:` suffix is redundant, and `?/1` doesn't return logical vectors, so `&/1` won't work on its output....
  ** its keys aren't sorted in ngn/k. check your implementation's docs to see if they sort it, and consider whether you want to write implementation-specific code.

others:

------------------------------------------------------------------
.S get       a:1;.`a -> 1   b.c:2;.`b`c -> 2 / like j's reflex, ~m
/ unary or binary (with right arg) amend
@[x;y;f]   amend  @["ABC";1;_:] -> "AbC"   @[2 3;1;{-x}] -> 2 -3
@[x;y;F;z] amend  @["abc";1;:;"x"] -> "axc"   @[2 3;0;+;4] -> 6 3
/ drill is the same but accepts deep indices. it obviates amend. i guess that amend exists because it's more efficient
.[x;y;f]   drill  .[("AB";"CD");1 0;_:] -> ("AB";"cD")
.[x;y;F;z] drill  .[("ab";"cd");1 0;:;"x"] -> ("ab";"xd")
.[f;y;f]   try    .[+;1 2;"E:",] -> 3   .[+;1,`2;"E:",] -> "E:typ"
/ splice removes a substring and replaces it with a string. if the substring is empty, then you're only inserting. it's a simultaneous removal & insertion. very good design.
?[x;y;z]   splice ?["abcd";1 3;"xyz"] -> "axyzd"
------------------------------------------------------------------

=== adverbs

the following are verbs given in terms of adverbs and an argument of a given type. i use brackets to mean optional, angle brackets to mean required, and `\|` to mean "or".

there are 3 kinds of abverbs: unrelated-element loops; related-element loops; window loops.

[options="header"]
|============================================================================================================================
| symbol w/types        | functionality
| `[y]<F\|f>'x`         | pointwise relation, or apply `f` to each elt of `x`. broadcasts atoms `y` or `x` to shape of `x` or `y`.
| `y F<\\|/>:x`         | relate entire `y` with each `x`, or vice versa.
| `[x]F</\>`            | (left) fold or scan with init val `x` or default value. unlike in j, scans are as efficient as folds.
| `[i\|p] f</\|\>x`     | apply `f` to `x` `i` times, or until it fails `p`, or until the value converges or returns to the inital. the scanny version's output (nearly) always contains the initial value and the 1st value that failed the predicate e.g. `{(x!)(1+)\1}` returns the sequence `[1..x]` and `(<1)(1+)\1` returns `1 2`. the "nearly" part is that, stranegly, if you use the predicate `{0}` (or `{x:0}`) then you're guaranteed to get a singleton result. the foldy version is equivalent to taking the last of the scan.
| `i [f]':x`, `[y]F':x` | [apply `f` to each] `i`-window of `x`, or apply `F` to each 2-window of `x` [with initial value `y` for the 1st window]. there cannot be a space between `':` and its left arg.
|============================================================================================================================

each left vs right mnemonic: `\:` iterates over the LHS elts. if you picture the (back)slash as a person, then they'd fall toward the side that is iterated over.

.implicit disambiguation/parsing of `[x]F</\>` vs `[i\|p]f</\>`

the ambiguity is whether +++*+++ is monadic or dyadic; this determines whether to apply the lambda/predicate afterward, or whether to use it as a "while" clause. as far as i've noticed, this is the only ambiguous grammar.

theoretically, token sequence `A B /` (or `\`) must be parsed thusly if `B` is an ambivalent verb (`B` being a noun would imply the verb form of `/` or `\` (split/join or encode/decode):

. if `A` is a verb then (probably) the "while" form is assumed. idk if it's theoretically possible to have a lambda be a fold's initial value.
  .. in ngn/k, +++{0=2!x}*/1 2 3+++ gives a type error whereas +++{0=2!x}(*/1 2 3)+++ returns `1` because 6 is even.
. else if `A` is a non-integral noun then it must be a fold's initial value
. else if `A` is an integer then it could be a fold's initial value or a number of times to apply a unary fn
  .. apparently ngn/k assumes the fold case: +++4+/,1 2+++ returns `5 6`. `4+:/,1 2` returns `,1 2`—the input transposed 4 times.

.each right/left examples
-------------------------
10 20 30,\:1 2 3 / map (,1 2 3) over 10 20 30
(10 1 2 3
 20 1 2 3
 30 1 2 3)

10 20 30,/:1 2 3 / map (10 20 30,) over 1 2 3
(10 20 30 1
 10 20 30 2
 10 20 30 3)

/ composed each's:

10 20 30,\:/:1 2 3
((10 1;20 1;30 1)
 (10 2;20 2;30 2)
 (10 3;20 3;30 3))

10 20 30,/:\:1 2 3
((10 1;10 2;10 3)
 (20 1;20 2;20 3)
 (30 1;30 2;30 3))
-------------------------

NOTE: you cannot have a space between argument and `/`, since in that case `/...` will be treated as a comment

TODO: how does the parser distinguish between `if/` and `xF/` where `x`=`i`? maybe it tries the dyadic version first, else tries monadic?

=== ngn quick-reference

backslash commands, when evaluated in the repl, are supposed to print their corresponding reference docs e.g. `\+` prints verbs. for me, however, they all print `'nyi`, so i can't get the reference in the repl, so i've put part the reference here that i haven't already covered in the above notes. the followig is copied from `repl.k` from the ngn/k repo:

---------------------------------------------------------------------------------------
\   help               \\         exit
\a  license(AGPLv3)    \l file.k  load
\0  types              \d foo.bar set namespace; restore with  \d .
\+  verbs              \t:n expr  time(elapsed milliseconds after n runs)
\:  I/O verbs          \v         variables
\'  adverbs            \f         functions
\`  symbols            \cd path   change directory
\h  summary            \other     command(through /bin/sh)
--------------------------------------------------------------------------------
\0
Types:
list atom
 `A        generic list   ()   ,"ab"   (0;`1;"2";{3};%)
 `I   `i   int            0N -9223372036854775807 01b
 `F   `f   float          -0w -0.0 0.0 0w 1.2e308 0n
 `C   `c   char           "a"   0x6263   "d\0\"\n\r\t"
 `S   `s   symbol         `   `a   `"file.txt"   `b`cd`"ef"
 `M   `m   table&dict     +`a`b!(0 1;"23")   (0#`)!()
      `o   lambda         {1+x*y#z}  {[a;b]+/*/2#,a,b}
      `p   projection     1+   {z}[0;1]   @[;i;;]
      `q   composition    *|:   {1+x*y}@
      `r   derived verb   +/   2\   {y,x}':
      `u   monadic verb   +:   0::
      `v   dyadic  verb   +   0:
      `w   adverb         '   /:
      `x   external func
--------------------------------------------------------------------------------
\:
I/O verbs
  0:x read  lines
x 0:y write lines
  1:x read  bytes
x 1:y write bytes
   <s open          fd:<`"file.txt"
   >i close         >fd

x can be a file descriptor (int) or symbol or string such as
 "file.txt"
 "/path/to/file"
 "host:port"
 ":port"         /host defaults to 127.0.0.1
--------------------------------------------------------------------------------
\+
Verbs:    : + - * % ! & | < > = ~ , ^ # _ $ ? @ . 0: 1:
notation: [c]har [i]nt [n]umber(int|float|char) [s]ymbol [a]tom [d]ict
          [f]unc(monad) [F]unc(dyad) [xyz]any
special:  var:y     set    a:1;a -> 1
          var::y    global a:1;{a::2}[];a -> 2
          (v;..):y  unpack (b;(c;d)):(2 3;4 5);c -> 4
          :x        return {:x+1;2}[3] -> 4
          :[x;y;..] cond   :[0;`a;"\0";`b;`;`c;();`d;`e] -> `e
          o[..]     recur  {:[x<2;x;+/o'x-1 2]}9 -> 34
          [..]      progn  [0;1;2;3] -> 3

 !I odometer  !2 3 -> (0 0 0 1 1 1;0 1 2 0 1 2)
 !S ns keys   a.b.c:1;a.b.d:2;!`a`b -> `c`d
 &I where     &3 -> 0 0 0   &1 0 1 4 2 -> 0 2 3 3 3 3 4 4
 &x deepwhere &(0 1 0;1 0 0;1 1 1) -> (0 1 2 2 2;1 0 0 1 2)
 <s open      fd:<`"/path/to/file.txt"
 >i close     >fd
 ~x not       ~(0 2;``a;"a \0";::;{}) -> (1 0;1 0;0 0 1;1;0) / TODO: what does :: in a vector mean?
 ,x enlist    ,`a!1 -> +(,`a)!,,1 / TODO: wtf is this literal? a projection?
d,d merge     (`a`b!0 1),`b`c!2 3 -> `a`b`c!0 2 3
X_d drop keys `a`c_`a`b`c!0 1 2 -> (,`b)!,1
 $x string    $(12;"ab";`cd;+) -> ("12";(,"a";,"b");"cd";,"+")
s$y cast      `c$97 -> "a"   `i$-1.2 -> -1   `$"a" -> `a
s$y int       `I$"-12" -> -12
i?x deal      -3?1000 -> 11 398 293 /guaranteed distinct
 @x type      @1 -> `i   @"ab" -> `C   @() -> `A   @(@) -> `v
 .S get       a:1;.`a -> 1   b.c:2;.`b`c -> 2
x.y apply(n)  {x*y+1}. 2 3 -> 8   (`a`b`c;`d`e`f). 1 0 -> `d
--------------------------------------------------------------------------------
\`
Special symbols:
   `j?C parse json   `j?"{\"a\":1,\"b\":[true,\"c\"]}" -> `a`b!(1.0;(1;,"c"))
   `k@x pretty-print `k("ab";2 3) -> "(\"ab\";2 3)"
   `p@C parse k
 `hex@C hexadecimal  `hex"ab" -> "6162"
 `pri@i primes       `pri 20  ->  2 3 5 7 11 13 17 19
   `x@x fork-exec    `x(("/bin/wc";"-l");"a\nbc\nd\n") -> "3\n"
   `t[] current time (microseconds)
`argv[] list of cmd line args (also in global variable x)
 `env[] dict of env variables
`prng[] `prng@I get/set pseudo-random number generator internal state
                     s:`prng[];r:9?0;`prng s;r~9?0 -> 1
        `prng@0 use current time to set state
 `err@C throw error
 `sin@N trigonometry `sin 12.34 -> -0.22444212919135995
 `exp@N exponential  `exp 1 -> 2.7182818284590455
  `ln@N logarithm    `ln 2 -> 0.6931471805599453
`exit@i exit
--------------------------------------------------------------------------------
I/ decode    24 60 60/1 2 3 -> 3723   2/1 1 0 1 -> 13
I\ encode    24 60 60\3723 -> 1 2 3   2\13 -> 1 1 0 1
F': eachprior -':12 13 11 17 14 -> 12 1 -2 6 -3 / swaps then applies
--------------------------------------------------------------------------------
0: lines i/o
1: bytes i/o
?[a;i;b]     splice
@[x;i;[f;]y] amend
.[x;i;[f;]y] drill
grammar:  E:E;e|e e:nve|te| t:n|v v:tA|V n:t[E]|(E)|{E}|N
limits: 8 args, 16 locals, 256 bytecode, 2048 stack
---------------------------------------------------------------------------------------

TODO:
* what's using `\` for "trace" like?
* is k homoiconic? it seems that it is!

* note the similarity of `.` & `@` in drill/amend and application: `@` accepts one arg or one level of nesting, whereas `.` accepts multiple. indeed: `"cats"@0 1` returns "ca" while `("cats";"mice").1 0` returns "m", and (10*)@1 2 3 returns `10 20 30`
* multiline comments start with a slash alone on a line and end with a backslash alone on a line

=== logic & dataflow patterns in k

some example code is copied from <https://xpqz.github.io/kbook/index.html>.

after learning k, see the following links about designing common programs in k:

* link:https://github.com/JohnEarnest/ok/blob/gh-pages/docs/Programming.md[common dataflow patterns effectively expressed in k]
* link:https://github.com/kevinlawler/kona/wiki/Idioms[*k3* idioms]

only the following verbs actually concern relation; the rest are arithmetic, type stuff, or special like binding to an identifier:

[horizontal]
.relational quickref
`#`:: count, repeat/take [from end], filter
`_`:: drop [from end], remove, split at idxs
`?`:: nub, find, splice (ins/del/ovr substr)
`/\`:: join, split
`@`:: set/get/upd at idx
`/`:: fold while converge
`^`:: without
`<>`:: sort
`|`:: reverse
`'`:: interval index / bin search
`&`:: non-0's
`':`:: window

they're approximately listed in the order that i expect, from most common to least common.

looping:

* short-circuiting:
  ** return the same value twice when using fixpoint
  ** modify the output (or another variable) s.t. it fails the "while" condition

=== tools

==== repl

* `\+` is supposed (by xpqz) to list verbs, but does not; it prints `'nyi`.

=== examples

+++quicksort:{$[2>#?x;x;,/o'x@&'~:\x<*1?x]}+++

. `x<*1?x` picks a random element from sequence `x` then compares it to each of ``x``'s elements e.g. `*1?"hello"` may pick `"l"` in which case `x<*1?x` evaluates to `1 1 0 0 0`. if `"e"` is picked then we get `0 0 0 0 0`.
. `~:\` couples each logical element with its inverse e.g. `~:\0` becomes `0 1`, `~:\1` becomes `1 0`, and `~:\0 1 0` becomes `(0 1 0; 1 0 1)`. how this works: 1. the initial value is always included in the output list; 2. the 1st value that fails the test is also always included as the last element of the output list. thus the output of `~:\0` starts with `0` then `~0` is 1 so the loop continues and flips again, thus producing the starting value `0`, so the loop terminates, having accumulated `0 1`. `~:\1` starts with `1`, then `~1` is 0, so the loop stops, having accumulated the starting value and the 1st failed value.
. `&'` converts logical vectors to integers where `1` is set ("where")
. `x@` indexes into the input sequence

e.g. if we pick `"l"` then `~:\1 1 0 0 0` evaluates to `(1 1 0 0 0 ; 0 0 1 1 1)`, then applying `&'` to that gives `(0 1; 2 3 4)`, then applying `"hello"@` to that gives `("he";"llo")`.

i only wish that i knew what/how `~:\` does. i have no method of stepping through to actually see which values are passed to which verbssssssssss! what horrid debauchery has befallen us! X(
