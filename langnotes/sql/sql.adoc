== sql

"a wrt b" is sql `select a from x join y on x.a like y.b`. cartesian product is like join w/ union; left join is like join w/intersection. "a wrt b" means "the subset of a that's related to b, and return a & b."

[TODO]
* what're windows? cf local binds?
* how to organize/encode data: relations are basically their headers. thus make a table for each shape. whatever data have a common shape belong in the same table.
* cf j/k db
* partition this module into relalg, working with data, common exprs (e.g. exists, case), useful compound patterns, and techniques for deriving solutions to given problems

sql is an array-based proglang whose sole data structure—the table—generalizes maps and arrays to matrices any subset of whose columns can be indexed. like APL, a table's cell's value can itself be a table. 1D arrays in sql are represented by single columns. objects [structs] are represented by single rows, and arrays of objects are represented by tables. features:

* slicing
* concatenation
* sorting
* partitioning
* folds
  ** map
  ** filter
* generators
* set-theoretic operations—a very unique feature for arrays!
* extremely efficient; much easier to reason about performance than using linked lists, hash maps, arrays, etc
* link:https://www.sqlite.org/json1.html[native JSON support] (introduced in the SQL 2016 standard)
* null propogation
* declarative
  ** query-based
  ** reactive programming via triggers
* clear separation of ad-hoc and symmetric relations: symmetric across rows (with implicit map over rows, and explicit map over tables by `group by` and aggregates) and ad-hoc relation of attributes of each given row.

but appears to lack:

* pointfree funcomp

NOTE: sql is case-insensitive!

=== (no) lambdas

TODO: revise this section remembering that views are effectively functions, except on a fixed rather than variable table. also discuss fns as parameterized data.

firstly let's identify what a _lambda_ is. a λ is a relation of inputs and outputs. picolisp's λ syntax makes this obvious: `((arg ...) (body ...))`. it's not even special syntax, really; the pil interpreter knows to process an sexpr as a λ if its first element is a list. the best λ syntax is clojurescript's shorthand: e.g. `(%1 + %2)/%3`, which generalizes apl's dfns syntax; these achieve brevity by identifying arguments by ordinals instead of names. a _function_ is exactly a λ, though commonly in programming (namely in languages not supporting λ's), it refers to a special linguistic construct that is _effectively_ just a λ bound to an identifier. as such, in such languages, _functions_ [programming] are just poor implementations of functions [math] i.e. λ's, where the poorness is by senseless asymmetry of how data are treated viz treating functions differently from other data.

fns' advantage is their variability: the locations of both their args and output vary with each invocation, and may even be unnamed (in the cases of an input being a literal or the output of another fn.) thus fns achieve composability. purely tacit langs like joy are purely function based, and thus every arbitrary substring of these programs is a valid function (cf concatenative langs, generally for which any substring of a program is a valid program, but not necessarily a function.) fns can be also seen as a scoping mechanism: `f(a,b)` is seen as variables `a` & `b`, whose meaning is relative to each invocation of `f`. this can be encoded in sql as a table `f(a,b,e)` where each invocation of `f` is a row, and `e` is the location where the output should go. `a`, `b`, and `e` may each be literal values or addresses. this has the side effect of making computation lazy by implicit memoization (namely when `e` is not an address, and it's just stored right there in the table.)

usually λ is an asymmetric linguistic primitive; once a λ is created, it cannot be modified, and no operations exist on it aside from β-reduction by application of provided inputs (which is always at invocation time in strict-eval langs.) this is needless restriction. we _just_ said that λ's are merely relations of inputs & outputs. so why not express them as such?

* picolisp does this; once a λ is defined, it does not become a black box; it remains exactly the list of 2 lists that it ever was. see _fexprs_ in pil docs.
* some functional langs support this via currying: a binary function is converted into a unary function of a pair of data

we've now restructured λ's as some `eval`-type fn on a relation [of data]. so let's talk about `eval`.

`eval` takes syntax as an argument, whether that syntax be encoded as an sexpr (viz lisp) or a string (e.g. bash). instead, let's generalize `eval` from a single function that evaluates syntax to a set of functions that each evaluates some specific form of data. oh, wait, look at that: those are just ordinary functions! so `eval` should really not be considered unique at all. yet `eval` isn't user-definable! why?

`eval` being not user-definable expresses a serious flaw in the design of languages: asymmetry in the form of functions being treated differently from data! yes, even functional languages, in which λ's are "first-class", are really no better than a non-functional language like C! they're only more _convenient_. if λ's were really data, then we'd be able to modify them—ya know, like _any other data_. instead, functions are *not* first-class; instead the language merely supports a _still-special syntax_ for _inline functions_. to summarize, _first-class_ is used to mean:

. declared/declarable inline by some special syntax
. can be bound to multiple identifiers
  .. passable to other functions (thus binding the λ to one of that function's parameters)

thus enabling one to express the full λ-calculus, which basically means function _composition_. it does not entail function _modification_!

now try to imagine _first-class_ data: you can declare the data, and you can pass them to functions; no mutation. that's  purely-functional programming. so how is it that even non-pure functional programming retains the same non-mutation limitation, but only for functions instead of other data?

this restriction is not necessary. we can have functions and mutation. again, functions are only relations; let's express them as such, and not in some special linguistic, asymmetric way. the only way to do that is for literally _everything_ to be mere relations. in the usual dictonomy of "data and code", this means all data and no code.

i know: "no code?! that implies no evaluation, and thus no program!" so there must be _some_ code. the question is: what? anything will do, so let's choose the least-constrained solution. thus the solution is β-reduction/evaluation of a relation—basically, effectively a lambda, only now we aren't thinking of _lambdas_ as their own concept, really; now we see just the evaluation of particularly-structured relations. now the necessary linguistic construct is not the `lambda` builtin, but instead `eval`, which now means "evaluate this relation" instead of "evaluate this syntax."

we have now achieved a language model where all data except `eval`, which is the only code, and is _not_ a datum, since that'd be redundant.

so how does this relate to sql? sql is made for relations. a fold can be expressed by a fn called `fold` that parses a [probably single-element] table of header `(init,s,op)` where `init` is the initial value, `s` is a relation (probably `select * from t` for some `t`) and `op` is a relation of inputs and outputs, expressed by `select body(arg,...) from t` where `t` contains all the args, where each column name practically is a locally-bound identifier of a function parameter. the only problem is that sql does not support variable `t`! `t` must be an absolute identifier! this is sad. however, at least it identifies the exact fault that makes sql non-composable—the single lack of variability that it'd need to be as capable as any language could be. such functionality can be easily implemented in a small language that merely converts a simple syntax into sql statements. i suggest making a dsl in factor [lang]. the lang would generate nonce identifiers to satisfy sql's requirement that every of its lingustic elements must be named.

.sql metaprogramming example

TODO: given that we can define fns as views, if we permit paramerizing the query, then metaprogramming = non-meta-programming?

pseudocode `def f(a,b,c) := (a+b)/c; f(1,2,3)` is sql `create view f as select (a+b)/c from params; insert into params values(1,2,3); select f`.

there are an infinite number of alternative expressions for defining & invoking functions, but ultimately we must group (fn id, param vec, output expr), and be able to invoke the function. to make regular programming into metaprogramming, simply make the function identifier an ordinary datum, e.g. a string; that way function names can be computed from any data. in lisp this is decently easy via `eval` or macros, and in scheme it's more difficult because of they hygeine constraint. hygeine is a concern only because of scope. because all scopes in sql are tables, which all must be named, accidental shadowing is impossible, so hygeine isn't a concern. furthermore, functions may be identifiable by more than a mere string; they may be stored in a table with arbitrary attributes, and we may filter as per usual (e.g. `select * from fns where name = ? and other_attr = ?`) to disambiguate.

as an ending aside, note that a side-effect of data-only programming is that all computation is delayed, since all computations are only data until explicitly passed to `eval`.

.λ's aren't needed for aggregates in sql

haskell `map (\x -> x+4) xs` is `select x+4 from xs`, which returns a fresh, unnamed table; `select` is basically lambda. haskell `foldl + 0 xs` is sql `select sum(x) from xs`. indeed, lambdas would benefit folds in sql, though their benefit would be only be a bit of efficiency or syntactic elegance; general folds can be expressed in sql by using `with recursive ... select`, using the tables locally bound by `with` to store fold state. at the end of the fold, all that remains is the output of the fold; the temporary tables are garbage-collected.

.where λ's would be nice in sql

update clauses: _update_ (cf _put_ or _set_) connotes modifying a value already present, which is a fn of the value to be updated. λ's would be especially useful in triggers that update per row! altirnatively it'd be very nice to be able to automatically select a table of rows that caused the trigger!

furthermore, though tangential, association or lack thereof is encoded in such phrases as `x,y` where, if `x` is a single value, then it's associated with all in `y`, akin to `let x = 4 in map (\y -> f x y) y`. the (lack of) association between memebers of different sets (viz {x} and y) implicitly tells how they must be scoped & sequenced. in this case, `x` must be in `y`'s scope when we compute `f` over all in `y`, but `x` is only associated with `y`, not there being a unique association between some `x` with every element of `y`.

.when `join` cannot alternatively express `where` (maybe. this is a tough-to-identify thought that needs investigation)

commonly `select a from t where a=(select b from u)` can be re-expressed as `select a,b from t join u on a=b where p`. but if there's nothing to join on, because one of the queries returns empty,...well then we can still use coalesce or exists maybe?

=== what is sql

sql is a bit mysterious:

* there's an open standard, but you must pay to access it
* despite the standard existing, no sql database totally conforms to the standand—both lacking standard features and including extra non-standard features
* sql began as merely a relational database system in 1974, but updates to the standard from SQL-99 onward have introduced much more functionality

=== sql basics

a table A may have a primary key (uniquely identifying set of attributes), and may have a set of attributes that, in another table B, is a primary key; then: this attribute set is called a _foreign key_, B is called the _child_ table, and A is called the _referenced_ or _parent_ table. foreign key is its own concept (as opposed to a column that we can `join` on) because it can be used as a constraint in a table's schema, which is basically a type check that we won't modify columns improperly.

the beauty of sql is that you don't need to care how you store data; all relations are equally flexible and easy to use. your queries are easy and practically the same regardless of whether you store `x` as an attribute in table `y`, or `y` as an attribute in table `x`.

foreign keys' sole use is in rejecting inserts that would violate the pk/fk relationship [constraint], called maintaining _referential integrity_. they add neither functionality nor efficiency, though, at least in sqlite, they conveniently make some dependent operations automatic; see `foreign-key-clause` in `CREATE TABLE`'s spec. aside from that convenience, though, it's a verify-only constraint.

a _virtual table_ acts like a table but is not actually _stored_ as a sql table, e.g. json virtual tables.

.foreign key example

[source,sql]
----
pragma foreign_keys = on; -- needed in sqlite; else foreign key clauses are not syntax errors, but foreign key constraints are ignored
create table t(id integer primary key autoincrement,
               x,
               dep integer,
               foreign key (dep) references t(id));
create index tdep on t(dep); -- make the upcoming join efficient
insert into t values(null,20,null); -- null is given to autoincrement columns, to use the autoincrement feature
insert into t values(null,40,3); -- fails b/c there's no record in x whose id is 3
insert into t values(null,40,1); -- succeeds b/c we've successfully inserted one row already
select x.x,y.id from x join x as y on x.dep = y.id; -- returns one row: {x=40,x=20}
----

this example creates a table with a foreign key constraint on itself. `dep`, which may be null, since the `not null` constraint was not given, is an optional value to consider after we've considered `x`.

TODO: how to efficiently & elegantly select rows that are or are not referenced by a foreign key, e.g. here, selecting only rows that are not dependencies i.e. rows whse ``id``s are not in any other rows' `deps`? decent solutions: 1. have a boolean attribute flag this; 2. store un/flagged ones in their own table, this making the "foreign" in _foreign key_ appropriate; however, this would be horrible attribute duplication! the 2nd table would have all the same columns as the original! so really only (1) is a decent solution so far.

.foreign keys as lattice of relations on subset of attributes

x := (a b c)
y := (x z)

thus:

* a, b, c ∈ x (i.e. {a, b, c} ⊂ x)
* x, z ∈ y

[source,sql]
----
pragma foreign_keys = on;
create table x(id integer primary key autoincrement, -- always good to have an auto inc integral pk column in
                                                     -- every table in case of need to join or use as foreign key.
               a, b, c);
create table y(id integer primary key autoincrement, x, z, foreign key (x) references x(id));
insert into x values(null, 1, 2, 3);
insert into y values(null, 1, 20);
select a,b,c,z from y join x on y.x = x.id; -- (1,2,3,20)
----

rather than explicitly join `x` with `y` on each `select`, it's more sensible to create a view that represents the relation x ⊂ y:

[source,sql]
----
create view y_full(a,b,c,z) as select a,b,c,z from y join x on y.x = x.id
select * from y_full; -- (1,2,3,20)
----

you may name the view 'y' & the underlying table _y, or you may name the view e.g. y_full & the underlying one 'y'. consider that you cannot delete, insert, nor update a view; those must be done to the actual table.

=== language design problems (inelegance & inability)

consider `select aapl.c,goog.c from aapl join goog on aapl.d=goog.d`. note how verbose this would become if i were to consider an arbitrary number of tables, despite that being a simple idea. the problem is that columns are not row types; they're less flexible. furthermore, that sql cannot transpose is a serious limitation! indeed, this lang-specific asymmetry limits the metaprogrammability of sql. this certainly is what makes sql bound to being poor, while the relational db model is good.

there are multiple scoping mechanisms: tables and `as`, at least.

columns in a select statement must be hardcoded. i cannot, for example, say `select (cond col1="x" => col2,col3; col1="y" => col3; ...; else *) from t`.

there's neither support for naked variables (e.g. `x := 3` not explicitly of a table) nor eponymous tables (or views) e.g. `create table x(x)` (to my knowledge yet.)

=== relational algebra

.terminology

[options="header"]
|===================================================
| relational algebra | common name or implementation
| tuple              | row
| attribute          | column (w/type if applicable)
| relation/selection | table
|===================================================

* _constraints_ on a table or column [attribute], e.g. `UNIQUE`, `NOT NULL`, `FOREIGN KEY`, `PRIMARY KEY`. they're verify-only constraints, not adding functionality, and so should be avoided (except indexes, should those be considered constraints)
* tuples are unordered, instead being expressed as attribute-tagged unions
* a tuple's set of attributes is called its _heading_, _domain identifying list_, or when as an argument to projection (see below,) a _projection list_. the heading is a list of indexes, whether ordinal or nominal.
* a set of tuples sharing a common heading is called a _body_
* a relation can thus be partitioned into a heading and body

degree:: number of attributes
schema:: heading with constraints (all needed to produce a selection)

.primitive operations

TODO: continue from ~/Downloads/pacific75-eval.pdf

union-compatible:: having the same attribute (column) sets

* link:https://en.wikipedia.org/wiki/Selection_(relational_algebra)[selection (aka _restriction_)] (σ_pred(R)): filter by predicate
* link:https://en.wikipedia.org/wiki/Projection_(relational_algebra)[projection] (π) of a heading onto a table, π_L(R) := {r[L]: r ∈ R} is just a subset of R found by restricting to attributes L, which must be a subset of R's original attributes; ior a projection may be a map over R's values, e.g. `select a+2 from R` maps `(+2)` over a ∈ R. only the column space is concerned; the number of rows is unaffected.
* link:https://en.wikipedia.org/wiki/Rename_(relational_algebra)[rename ρ]: rename an attribute
* [flattened cartesian] product (×). TODO: test: in sql lhs & rhs tables must have mutually exclusive attribute sets.
* set difference (aka _relative complement_) (\). requires union-compatiblity and may be defined in terms of union: given relations R & S of equal degree _n_, R \ S = (σ_(r[1] ≠ s[1] ∨ ... ∨ r[n] ≠ s[n])(S)).
* union (∪). union-compatible.
* join
  * natural (⋈): defined when lhs & rhs share exactly one attribute. attribute set is the union of lhs' & rhs' attribute sets. (e.g. join a,b,c and b,c,d = a,b,b,c,c,d)
  * inner (intersection in relation algebra): natural but without repeated columns [WRONG] (e.g. join a,b,c and b,c,d = a,b,c,d). union-compatible? not in sql! or perhaps this could be said to be a succession of projection then union.
  * outer: flattened cartesian product
  * left or right
* division: for relations R & S of headings A & B (without repitition) of degrees m & n respectively, the division R[A÷B]S is a subset of π_A'(R), viz {r[A']: r ∈ R ∧ ∀s ∈ S ∃r' ∈ R : r[A'] = r'[A'] ∧ r'[A] = s[B]}. definitions vary when S is null.

the _theta join_ is a non-primitive operation: x θ y = σ_pred(x ⋈ y), expressed in sql as `select _ from _ join _ on <cond>;`

the relational algebra is closed under all these operations.

NOTE: *for the love of god, use `BEGIN TRANSACTION` &al*

=== the language

==== semantics

* both `0` is falsy in sqlite. anything other than null is truthy. null is neither truthy nor falsy; `select x from t where x` will select truthy `x`; `... not x` will select where `x=0`. in neither case will null x's be returned.
* when a sqlite db can be opened read-only, we can still create and modify temporary tables
* everything is a table (multiset of tuples whose positions may be bound to, in a given conext, a name) viz the results of statements, which can be enclosed in parens, e.g. `select * from (select * from mytbl) t`
  * such statements are called _derived tables_
  * thus tables can be locally bound. this allows passing multiple data, e.g. `select * from (values(1),(2),(3)) t` to mean scheme `(values 1 2 3)`
    * this is apparently equivalent to `select * from (select 1 as a from dual union all; select 2 as a from dual union all; select 3 as a from dual) t`
  * _rows_ have no special meaning; they're just singleton tables. all operations are over tables.
    * generally all operations are on the entire table
* if both args to `/` are integers, then `/` is integer division. `cast(expr to real)/cast(expr to real)` to ensure floating point division.

[options="header"]
|==============================================================================
| sql                 | java 8, math, or scheme
| `table`             | list of vectors
| `where` & `having`  | filter
| `group by`          | concatMap (useful for aggregates only)
| `except`            | \
| `order by`          | sort
| `union all`         | concat
| `union`             | distinct concat
| `with`              | `letrec`
| `check`             | guards
| `join`              | flatmap [TODO: how?]
| `collate`           | TODO
| `escape`            | TODO
| `exists`            | whether argument select query returns non-empty
| `frame-spec` grammar  | TODO
|==============================================================================

TODO: consider (in `expr` grammar): 

===== joins

all joins are refinements of cartesian product. `join` (or comma) is cartesian product. `join on <pred>` filters cartesian product to those matching `pred`. `join using attrs ...` is shorthand for `join on t1.attr=t2.attr ...`. `natural join` is shorthand for `join using X` where `X` is the intersection of tables' attributes.

* `inner` & `cross` are redundant; just say `join`. however, as a non-standard sqlite feature, `cross` prevents query optimizer from reordering input tables.
* `outer` applies only to `left`, `full`, and `right` joins. `outer` is redundant.
  ** `inner` is inapplicable to `left`, `full`, and `right` joins. 
* `left` join is just `join` unless an `on` or `using` clause is provided.
* `full` & `right` are currently unsupported in sqlite; at least `right` is redundant: `x right join y <join-clause>` = `y left join x <join-clause>`

.examples
[source,sql]
----
-- kinda odd that we can't just do create tablet(a1,...) as (values...)
create table x as with x(a,b) as (values(1,2),("x","y")) select * from x;
create table y as with x(o,b) as (values(6,"y"),(100,2),(101,"B")) select * from x;
select * from x left join y using (b);
┌───┬───┬─────┐
│ a │ b │  o  │
├───┼───┼─────┤
│ 1 │ 2 │ 100 │
│ x │ y │ 6   │
└───┴───┴─────┘
select * from y left join x using (b);
┌─────┬───┬───┐
│  o  │ b │ a │
├─────┼───┼───┤
│ 6   │ y │ x │
│ 100 │ 2 │ 1 │
│ 101 │ B │   │ -- (101,B,NIL)
└─────┴───┴───┘
----

==== syntax

`table.attr` disambiguates when `attr` is shared by multiple tables; otherwise attr is resolved against the table of the `from` clause.

.basic operators
|======================================================================
| &          | bitwise and
| \|         | bitwise or
| ^          | bitwise xor
| += &al, %= | assignment can be used for variables bound in a funcbody
| &=         | bitwise and assignment
| ^-=        | bitwise or assignment
| \|*=       | bitwise xor assignment
|======================================================================

===== `create table`

* `create table as` still inserts a table into a database. it's used to init a table at declaration time, for convenience.
* `temp` tables are accessible in the remaining sql script, but is not persistent; it isn't inserted into the database, and so doesn't exist after the sql script that created it finishes execution.

===== functions defined in sql (not in sqlite)

[source,sql]
----
-- define
create procedure foo @param1 nvarchar(30), @param2 nvarchar(10) as
select * from customers where p2 = @param1 and p2 = @param2
go;

-- invoke
exec foo @param1 = 42, @param2 = "stuff";
----

===== columns

====== `case`

determines a column's value. syntax: `case [when <cond> then <value>]+ [else <value>] end`.

.examples

[source,sql]
----
select customername, city, country from customers
order by case when city is null then country else city end

-- or
select case when city is null then country else city end from customers
----

====== `exists`

should be called `any`, but oh, well. `exists <select-stmt>` checks whether the selection is (not) empty. when used in `case`, one can effectively do `<|>`/`asum`.

====== null

* ifnull(<col>,<val>)
* isnull(<col>) -- returns bool. called nvl on oracle.
* coalesce(<col>) -- 1st non-null value in a list. generalizes `ifnull` to accept multiple values each of which may be null (though it'd be expected that at least one isn't)

====== constraints

all constraints can be added or dropped via `alter table` or can be added in `create table`

* primary and foreign keys
* `check`, which guards inserts
* default
* indexes
* auto increment

===== filters

* `having` is simply `where` that is a boolean of aggregates instead of per row, e.g. `having count(x) > 5`. using count
* `where` clause accepts things that eval to bools
  ** <, = &al common equivalence relations and boolean conjunctions
  ** between <lb> and <ub>
  ** in <set>
  ** like <pat> (useful only for strings)
    *** `%` is regex `/.*/`
    *** `_` is regex `/./` 
    *** regex-style character classes
  ** exists
  ** <attr> <bin_comp_op> <`any` | `all`> <single_col_tbl> -- `any` is called `some` in some sql implementations

===== result set modifiers

* order by
* limit (or `select top <number> [percent]` in MSSQL; or `fetch first <number> rows only` in oracle 12+) 
* group by

==== table set operations

===== union

union tables' rows. valid only for tables of equal column sets. `union` returns sets; `union all` returns multisets.

==== views (named, non-parameterized select functions)

[source,sql]
----
create view [<name>] as select ... ; -- the view name is whatever, including spaces, delimited by brackets
----

NOTE: `as` is optional for aliasing table names: `tbl as x` is equivalent to `tbl x`.

==== `with` & recursion (common table expression (CTE) subquery refactoring)

this is how we do local binds.

TODO: cf normal aliases

* supports recursion
* exists temporarily: discarded after the statement that uses its binds
* considered a cleaner alternative to temp tables
* alternative to views (prob like `let*` in alt to `define` in funcbods)
* repeated aggregations, e.g. avg of maxes
* "overcome constraints such as what `select` has, e.g. non-deterministic `group by`"

[source,sql]
----
with
  t1(v1, v2) as (select 1, 2),
  t2(w1, w2) as (select v1 * 2, v2 * 2 from t1)
select *
from t1, t2
----

produces

[options="header"]
|==================
| v1 | v2 | w1 | w2
| 1  | 2  | 2  | 4
|==================

could use `values` instead of `select`; `values` is just `select` but more efficient and without a limit on number of supported rows.

.generator example

[source,sql]
----
with recursive t(v) as (
  values(1) union all select v + 1 from t
) select v from t limit 5
----

produces a column `v` with five rows of values 1 through 5, effectively equal to haskell `take 5 (Data.List.NonEmpty.unfoldr (\n -> (n, pure $ n + 1)) 1)`. the definition of `t` is unbounded; the bound is in `limit 5`; therefore locally bound tables (at least when bound with `recursive`) are not stricted evaluated before the body of the `select` statement.

.example: trace paths in a graph

[source,sql]
----
create table x(id integer, prev integer, val integer);
insert into x values(1,null,20),(2,1,40),(3,2,50),(4,2,100),(5,4,200),(6,3,400),(6,4,300),(7,6,1000);
select * from x;
┌────┬──────┬──────┐
│ id │ prev │ val  │
├────┼──────┼──────┤
│ 1  │      │ 20   │
│ 2  │ 1    │ 40   │
│ 3  │ 2    │ 50   │
│ 4  │ 2    │ 100  │
│ 5  │ 4    │ 200  │
│ 6  │ 3    │ 400  │
│ 6  │ 4    │ 300  │
│ 7  │ 6    │ 1000 │
└────┴──────┴──────┘
with recursive y(id,prev,val) as (select * from x where id=7
                                  union -- union all produces some redundancies, since the graph is a dag
                                  select x.id,x.prev,x.val from y join x on y.prev=x.id)
select * from y; -- edge set for nodes reachable from node 7
┌────┬──────┬──────┐
│ id │ prev │ val  │
├────┼──────┼──────┤
│ 7  │ 6    │ 1000 │
│ 6  │ 3    │ 400  │
│ 6  │ 4    │ 300  │
│ 3  │ 2    │ 50   │
│ 4  │ 2    │ 100  │
│ 2  │ 1    │ 40   │
│ 1  │      │ 20   │
└────┴──────┴──────┘
----

maybe unexpectedly, we select from `x`, not `y`! `[...] select y.id,y.prev,y.val from [..]` is unbounded recursion.

===== insert

* `select <cols> into <new_tbl_name> [in <external_db>] from ...` is equivalent to a sequence of `create table` and `insert` statements (not available in sqlite)
  ** remember that you can use `as` to rename the columns. they'll retain their column attributes.
  ** `select * into <newtable> from <oldtable> where 1 = 0;` creates a new empty table with the same schema
* `insert into <dest> select <cols> from <src> ...;` is the same but for a table that already exists. both tables must be of the same schema.

===== table ops

* `alter table` changes schema
* <create | drop> db
* <create | drop> table

==== compound examples

.get successive integer 

we get the greatest integer in the table, or if the table is empty, then start with 10.

[source,sql]
----
create table x(id integer);
select case when count(id) > 0 then max(id)+1 else 10 end from x; -- 10
insert into x values(100);
select case when count(id) > 0 then max(id)+1 else 10 end from x; -- 101
----

.tic tac toe

this example demonstrates many things about how to reason about relations. to start, the 3×3 grid will not be a table with 3 rows and 3 columns. think about how you'll check for a winner: you'll want to check each of the rows, and each of the columns (and each of the diagonals, too.) to check all of the columns, you'll want to use the same logic for each column, just a different column number. ah, there's one hint: we want column _numbers_; sql does not number columns. columns are fixed and must be addressed by name. rows, on the other hand, are arbitrary in number and are all treated the same. furthermore, we want code that generalizes non-verbosely to higher dimensions, say for _connect four_. x & y should be treated the same; thus we'll use `(x,y)` indices. x's & o's will be stored as -1 and 1 respectively; an empty cell is 0. this makes checking for winners easy: if the absolute value of the sum _s_ of a row, col, or diag is 3, then the winner is `sign(s)`.

[source,sql]
----
-- make the grid
create table grid(x integer, y integer, v integer default 0, primary key (x,y));
insert into grid(x,y) select * from generate_series(1,3) as x join generate_series(1,3) as y;
-- assume that player just moved, which updates grid. now check for winner:
select sum(v) from grid where x=y;   -- one diagonal
select sum(v) from grid where x=4-y; -- the other diagonal
select sum(v) from grid where x=1;
select sum(v) from grid where x=2;
select sum(v) from grid where x=3;
select sum(v) from grid where y=1;
select sum(v) from grid where y=2;
select sum(v) from grid where y=3;
----

ugly as sin, eh? clearly we're considering the cartesian product {x,y}×[1,3], so our code should reflect that. `where x=n` is here actually a poor way of referring to the set {(x,y)|x=n}! that set is described properly as a cartesian product in sql:

[source,sql]
----
with t(x,y) as (select * from (values(1)) join (select * from generate_series(1,3))) select * from t;
┌───┬───┐
│ x │ y │
├───┼───┤
│ 1 │ 1 │
│ 1 │ 2 │
│ 1 │ 3 │
└───┴───┘
----

we could `natural join` that table with grid on `(x,y)`. (btw, expressions like `where (x,y)=(1,2` are valid!) however, this is a perfect use case for `group by` & the `sum` aggregate. the finished code is:

[source,sql]
----
create table grid(x integer, y integer, v integer default 0, primary key (x,y));
insert into grid(x,y) select * from generate_series(1,3) as x join generate_series(1,3) as y;
-- check diagonals
select sum(v) from grid where x=y;
select sum(v) from grid where x=4-y;
-- check rows & columns
select * from grid group by x having abs(sum(v))=3; -- rows for which sum({(x,y)|x=n})=3
select * from grid group by y having abs(sum(v))=3; -- rows for which sum({(x,y)|y=n})=3
----

so there you go: checking for winners in tic tac toe simply by 4 queries. maybe it can be syntactically shorter, but this is a good encoding of the game's rules: you win if you cross any row, column, or diagonal.

we see that `group by` partitions by equality, which is analagous to the set of (sets each one of whose axes' value is fixed.)

.select by day

[source,sql]
----
select * from tbl where strftime("%Y-%m-%d",date) = "2022-07-01";
----

`date` may be a datetime or date string.

.resample 1m candles into day candles (single day)

[source,sql]
----
with x(start,end,high,low,open,vol)
  as (select strftime("%Y-%m-%d",min(datetime)), max(datetime), max(high), min(low), open, sum(vol)
  from AAPL where datetime between datetime("2010-01-04 09:30") and datetime("2010-01-04 16:00"))
select start,high,low,open,vol,close from x join (select close from AAPL where datetime = (select end from x));
----

in a common proglang this would be like:

----
let t = {AAPL | datetime ∈ ("2010-01-04 09:30", "2010-01-04 16:00")}
    end = max(t.datetime)
    close = t[end].datetime
 in (start,high,low,open,vol,close)
----

the `join` is not done as a cartesian product, but instead should be interpreted as putting the `close` at `end` into the `select` clause's scope. `x` is a local binding. if i'm using sql from another proglang, then alternatively i could have stored `x` as its own table (a non-local binding) then done `select start,...vol from x` in one query and `select close from AAPL where datetime = (select end from x)` in another.

`open` needs neither aggregate nor other special calculation because for any data selected among aggregates, the first encountered value is used in practice, though according to sqlite's documentation (§2.4 of the `SELECT` docs), "each non-aggregate expression in the result-set is evaluated once for an arbitrarily selected row." if this turned-out to be a problem in practice, then we'd need to endow it with similar logic as we used for `close`.

NOTE: the datetime format requires leading zeroes for all values, e.g. day, hour, &al.

.resample 1m candles into day candles (multiple days)

[source,sql]
----
with x(start,end,high,low,vol) as (
  select min(datetime), max(datetime), max(high), min(low), sum(vol)
  from x_AAPL
  where datetime between datetime("2010-01-01") and datetime("2010-02-01")
    and time(datetime) between time("09:30") and time("15:59")
  group by strftime("%d",datetime)
)
select strftime("%Y-%m-%d",start),high,low,open,close,vol
from x join (select datetime as cdt, close from x_AAPL) on end = cdt
       join (select datetime as odt, open from x_AAPL) on start = odt;
----

returns

----
2010-01-04|30.6429|30.34|30.4871|30.5971|116694802
2010-01-05|30.7986|30.4643|30.64|30.6257|136014592
2010-01-06|30.7471|30.1071|30.6257|30.1343|133300727
2010-01-07|30.2857|29.8643|30.25|30.0829|113809059
2010-01-08|30.2857|29.8657|30.0429|30.27|104221936
2010-01-11|30.4286|29.7786|30.4143|30.01|111353487
2010-01-12|29.9671|29.4886|29.8843|29.6757|129700571
2010-01-13|30.1329|29.1571|29.6957|30.0571|145122992
2010-01-14|30.0657|29.86|30.0157|29.9171|98356076
2010-01-15|30.2286|29.41|30.1314|29.4143|130680837
2010-01-19|30.7414|29.6057|29.7671|30.72|161574329
2010-01-20|30.7929|29.9286|30.6914|30.2614|148014426
2010-01-21|30.4734|29.6014|30.2971|29.7486|145818463
2010-01-22|29.6429|28.1657|29.54|28.2514|205441418
2010-01-25|29.2429|28.5986|28.93|28.9286|216214306
2010-01-26|30.53|28.94|29.3986|29.4129|425729542
2010-01-27|30.0829|28.5044|29.5471|29.71|417601177
2010-01-28|29.3571|28.3857|29.2714|28.4714|281731401
2010-01-29|28.8857|27.1786|28.7243|27.4457|300374774
----

=== implementation-specific

TODO: this document should be stored as database table with indexes on both topic and sql implementation. furthermore, searching sql (with regex) is better than ripgrep.

==== output

.sqlite output modes

`.mode <mode>` changes output.

* pretty:
  ** `box` uses unicode box drawing characters
  ** `column`: clean
  ** `table`: boxes drawn with plus, hyphen, and pipe
* easily parsed:
  ** `list` (default)
  ** `json`
  ** `csv`
* special output:
  ** `html`
  ** `insert`: sql insert statements; good for copying from one table to another

all except `list`, `csv`, `insert`, `html` force headers to be displayed. other modes aren't good.

==== performance

* gather multiple successive statements into transactions (see your db's docs for the `TRANSACTION` keyword)
  ** at least in sqlite, all actions occur in a transaction, and creating & destroying transaction is non-trivial like creating & destroying pthreads.
* sqlite (and perhaps others?): prepare statements that will be executed multiple times. TODO: ipossile only in sqlite (which defines a bytecode) when invoking it from other langs (i.e. preparation isn't possible in sqlite's repl)?
  ** e.g. with connection `d` to db containing table `x(a,b,c,d)`, `(define st (prepare "insert into x values(?,?,?,?)")) (call-with-transaction d (λ _ (query-exec d st 1 2 3 4) (query-exec d st "A" "B" "C" "D")))`. note that the prepared statement can be free in its parameters' values.
* sqlite `PRAGMA synchronous=OFF` disables the usual waiting for data to be safely on disk, thus making writes faster but making corrupton possible.

[TODO]
* sqlite: can i prepare a transaction statement? i should be able to, if transaction is symmetric. otherwise i'll use transactions all of whose statements are prepared.

.exceptions

* akavache is designed to be efficient without the user trying
* sqlite in-memory dbs are probably fast no matter what

==== mutiple databases

[source,sql]
----
create table table1(x integer);
attach database "db2.db" as db2;
create table db2.table1(y integer primary key autoincrement);
insert into main.table1 values(56);
insert into main.table1 values(90);
insert into db2.table1 select * from main.table1 limit 1; -- table1 of file "db2.db" now contains 56.
----

.common

* `insert into t1 (a, b, c) select a, b, c from t2;`
* `all` (cf `distinct`) is often not supported. this is fine because it's the default anyway.

.sqlite3-specific execution

* to open a db as read-only, specify its location as a URI, then append a query: `file://<path>?mode=ro`

.quoting

|===
| single quotes | string literal
| double quotes | identifier (used to, e.g. use a keyword as a symbol
| brackets      | (non-standard) identifier, same as double quotes. used by MS-SQL server and sqlite
| backticks     | (non-standard) identifier. used by MySQL and sqlite
|===

see link:https://www.sqlite.org/lang_keywords.html[sqlite's documentation] on parsing quoted strings.

.csv to sqlite

NOTE: sqlite has a csv virtual table plugin

prefer using link:https://github.com/harelba/q[q] (not in nixpkgs,) which allows running sql on multiple csv files or sqlite databases.

use package `csvs-to-sqlite`. you'll probably want to use options `pk`, `d` or `dt`, `i` whose arguments are the column names as in first row of csv file. if you use these options, then you'll need to run the command for each table that you want to add, unless the tables share common columns for which the options apply.

it's likely in your best interest to add csvs as tables into a db, then use sql to create a new table, rather than doing this all at once programatically.

.list all tables

|===
| sqlite | .table
|===

.describe a table

|===
| sqlite | `pragma table_info(tableName);` (don't quote the table name)
| mysql  | `describe tableName`
|===

=== reldb programming

using (generally reldbs, currently practically sqlite) as a proglang.

* model: declarative, array-based
* bools are 0 & 1
* each shape gets a table
* `with` locally binds 
* virtual tables, table-valued fns & extensions e.g. https://www.sqlite.org/src/artifact?ci=trunk&filename=ext/misc/series.c
  ** TODO: explore
* control flow:
  ** recursion in `with`
  ** `case` 
* folds are called _aggregate functions_
* like a properly set-theoretic language, everything is sets. this is like apl and unlike lisp; in lisp `1` ≠ `'(1)`; if one were considering a datum that may be either a thing or a thing attached to some properties (e.g. `'(1 to 6)`), one would need to break symmetry: `(cond x [(number? x) ...] [(list? x) ...])`, which is just stupid. it's much better to store everything in sets, even if forced to name attributes—sql `with t(x) as (values(1)) select x from t`—which maintains symmetry and does not change form when generalized e.g. adding an attribute to `t`. plurality is a common generalization of singularity, and is thus a more appropriate form than supporting both singularity & plurality. this being said, the requirement for everything to be named does not imply that things must be named _in syntax_; any syntax that unambiguously translates to a product type is acceptable, and its brevity is welcome. for example, sql does this when saying `insert into t values(...)`: you do not need to specify column names, because sql infers this from values' ordinal positions. another brief form is `insert into t(x,y) values(...)` where t may contain many more attributes than `x` & `y`.

==== json

sqlite is an excellent json extractor and manipulator. it considers json as a set of flat tables implicitly nested by (`id`,`parent`) relations rather than recursively nested objects (which introduces scoping), thus making arbitrary traversal easy.

* `.mode json` outputs json to stdout
  ** `.once <file path>` writes next query's output to file (so can write table as json to file)
* if using sqlite as a library in another proglang, then conversion from rows to json is trivial
* json is stored as ordinary strings, except return value of `json`
* json is stored in table cells or string literals

.fns

json:: id fn but cod is string pseudo-typed as json.
json_valid:: 0 or 1 whether a value is a (valid) json string.
json_array(e,...):: constructor
json_object(k,v,...):: constructor
json_array_length:: obvious. useful in query predicates.
json_extract:: select elements from json tree. if one path arg given and selected value does not refer to json array, then returns single value as sql atom; else returns json array string.
json_insert, json_replace, json_set:: put: 1. unless exists; 2. when exists; 3. either; respectively.
json_remove:: duh
json_patch:: put (or remove if put to null) values in json object at keys. treats arrays as atoms.
json_each, json_tree:: json tree as sql tables, top set of children only, or children on all levels
json_group_array, json_group_object:: aggregate fn. return selection as json array or object (see example below). take 1 & 2 args respectively.

.operators

both introduced in sqlite v3.38.0 (2022-02-22). they're `json_extract` but:

->:: always returns json string.
->>:: always returns sql table.

.examples
[source,sql]
----
create table d as with x(k,v) as (values("j",'{"a":3,"b":[1,2,3,4],"c":{"d":"hi"}}')) select * from x;
select key,value,type,atom,id,parent,fullkey,path from json_each(v) join d where k="j";
┌─────┬──────────────────────────────────────┬─────────┬──────┬────┬────────┬─────────┬──────┐
│ key │   value                              │  type   │ atom │ id │ parent │ fullkey │ path │
├─────┼──────────────────────────────────────┼─────────┼──────┼────┼────────┼─────────┼──────┤
│ a   │ 3                                    │ integer │ 3    │ 2  │        │ $.a     │ $    │
│ b   │ [1,2,3,4]                            │ array   │      │ 4  │        │ $.b     │ $    │
│ c   │ {"d":"hi"}                           │ object  │      │ 10 │        │ $.c     │ $    │
└─────┴──────────────────────────────────────┴─────────┴──────┴────┴────────┴─────────┴──────┘

select key,value,type,atom,id,parent,fullkey,path from json_tree(v) join d where k="j";
┌─────┬──────────────────────────────────────┬─────────┬──────┬────┬────────┬─────────┬──────┐
│ key │                value                 │  type   │ atom │ id │ parent │ fullkey │ path │
├─────┼──────────────────────────────────────┼─────────┼──────┼────┼────────┼─────────┼──────┤
│     │ {"a":3,"b":[1,2,3,4],"c":{"d":"hi"}} │ object  │      │ 0  │        │ $       │ $    │
│ a   │ 3                                    │ integer │ 3    │ 2  │ 0      │ $.a     │ $    │
│ b   │ [1,2,3,4]                            │ array   │      │ 4  │ 0      │ $.b     │ $    │
│ 0   │ 1                                    │ integer │ 1    │ 5  │ 4      │ $.b[0]  │ $.b  │
│ 1   │ 2                                    │ integer │ 2    │ 6  │ 4      │ $.b[1]  │ $.b  │
│ 2   │ 3                                    │ integer │ 3    │ 7  │ 4      │ $.b[2]  │ $.b  │
│ 3   │ 4                                    │ integer │ 4    │ 8  │ 4      │ $.b[3]  │ $.b  │
│ c   │ {"d":"hi"}                           │ object  │      │ 10 │ 0      │ $.c     │ $    │
│ d   │ hi                                   │ text    │ hi   │ 12 │ 10     │ $.c.d   │ $.c  │
└─────┴──────────────────────────────────────┴─────────┴──────┴────┴────────┴─────────┴──────┘

select json_group_array(key) from json_each(v), d where k="j"; -- ["a","b","c"]
select json_group_object(key,fullkey) from json_each(j), d where k="j"; -- {"a":"$.a","b":"$.b","c":"$.c"}
----

* `path` is the path to the object that contains a given element
* `fullkey` is the path to the given element
* `atom` is not more useful than value, but should be considered a boolean (i.e. null or not) which is useful for query filters
* `v` is in `json_each`'s scope, implying that, in a join, attributes are unioned before virtual tables are computed.

=== triggers

triggers are very powerful. they enable reactive programming aka _hooks_. the excellence of this design pattern is freedom to not concern scope, and so nor code structure.

[source,sql]
----
create table x as with x(a) as (values(0)) select * from x; -- counter a := 0
create table y(b); -- just some table
create trigger tr after insert on y for each row begin update x set a = (select 1+a from x); end;
select a from x; -- 0
insert into y values(10);
select a from x; -- 1
insert into y values(10),(30);
select a from x; -- 3. if not FOR EACH ROW, would be 2. however, as of sqlite 3.39.2 only FOR EACH ROW is supported, so it's implicit.
----

as you can see, `tr` is a hook that increments counter `a` for each row inserted into `y`.

==== common programming patterns expressed in sql

never assume that a common pattern should be used; instead, *listen to the data*, *follow the implications of design specs*, and then see if the suggested system's (sub)structure(s) happens to exhibit a pattern naturally like a prior-known pattern.

.folds

a fold is a stateful traversal. in reldbs, state is obviously stored, as is everything, in relations. a recursive `with` may be more efficient, however. even more efficient is a fold written as a runtime-loadable extension written in c, loaded by sqlite from a shared library.

`foldl (\a b -> a ++ b) xs`:

[source,sql]
----
create table c(id integer primary key autoincrement, value string);
insert into c(value) values("hello"),("there"),("my"),("good"),("friend");

-- with trim, to remove the leading space character
with recursive acc(id,ps) as (values(1,"") -- initial value (base case)
                              union all
                              select id+1,printf("%s %s",ps,value) from acc natural join c) -- recursive case
select trim(ps) from acc
order by id desc limit 1; -- acc is a scan; get the last element to be effectively a fold

-- proper general solution for folds whose initial object must be the input lists' 1st element
with recursive
  x(id,ps) as (select id+1,value from c where id=1),
  acc(id,ps) as (select * from x
                 union all
                 select id+1,printf("%s %s",ps,value)
                 from acc natural join (select * from c where id>1))
select ps from acc order by id desc limit 1;
----

* we really do use functional style here. we can't use noe `with` clause over both an `update` and a `select` statement. rather than use `update` (a stateful, non-functional style), we can use recursion and nested ``select``s. each row is defined in terms of its predecessor.
* `acc` is the named tuple of the fold. `printf` (`format` in other sql engines) is used for string concatenation since sqlite has no separate such function.
* the proper solution binds `x` b/c `select * from c limit 1 union all ...` is invalid syntax; we can't use `limit` there, though `where` is fine there
* i'ven't yet ``explain``ed this query to see its efficiency
* we can't use aggregate functions in predicates; therefore `where id=max(id)` is not a valid alternative to `order by id desc limit 1`

of course, this fold is more easily done by the aggregate `group_concat`, but this example serves generally, when an aggregate may not be already written for it.

.functions

views (especially defined by cte) can represent fns. `create view f(f) as select sin(x + y) from t` is the sql version of `f x y = map (\[x,y] -> sin x y) sql(conn,"select x,y from t")` haskell-like pseudo-code. yes, `f` is the name of the view and the name of its single column. if you've ever defining a fn in code that's using a sql connection, think about how easily you could express that fn as a sql view. views are a sort of variety of prepared statement, except that they're standard sql and are stored by the sql engine internally.

pointwise-with-aggregate array programming example:

[source,sql]
----
create table things(name string, value real);
insert into things values("a",40),("b",16),("c",5),("d",4);
-- equal weight to all things
with weight(weight) as (select 1.0/count(*) from things) select name, weight, weight*value as adjusted from weight, things;
┌──────┬────────┬──────────┐
│ name │ weight │ adjusted │
├──────┼────────┼──────────┤
│ a    │ 0.25   │ 10.0     │
│ b    │ 0.25   │ 4.0      │
│ c    │ 0.25   │ 1.25     │
│ d    │ 0.25   │ 1.0      │
└──────┴────────┴──────────┘
----

notice that the ordinary join (cartesian product) of a single value with a row of values is effectively equivalent to scalar expansion (or w/e it's called) in apl `0.25 × values`.

.local binds

[source,haskell]
----
a = 9      -- dummy value
let a = 20 -- shadow a
 in a + 4  -- returns 24
----

[source,sql]
----
create table scope(a);        -- unlike haskell, we must define a in a table. its dummy value is implicitly [].
with scope(a) as (values(20)) -- local scope(a) shadows global one for duration of this select statement
  select a + 4 from scope;
----

* by naming tables `scope` i mean that tables are scoping mechanisms
* `with` is not properly its own clause; it's a clause of the `insert` statement, as well as `select`, `delete`, & `update`

sql binds cannot be , e.g. in a `create trigger` statement's final clause where it takes a sequence of statements, each statement may have each its own local binds, but local binds over all statements are not supported. instead, you'll need to create a (global) table then have the body statements use it, then drop or reset it as the last body statement, if appropriate. the table may be created before the trigger (being just a global table used only in the trigger) or may be created as the first statement of the trigger's body.

the ability to choose either demonstrates that local binds, like all scoping mechanisms, are not necessary, but instead exist only as a namespace management tool, namely to allow multiple homonomic data across different contexts. sql is unique in that all data must exist in tables, and tables are scoped, so namespacing is more of a constraint than an option. in contexts with homonomic data, sql gives us `as` clauses to disambiguate.
