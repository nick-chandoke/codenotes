== sane computing

TODO: check-out link:https://fossil-scm.org/home/doc/trunk/www/index.wiki[fossil], a vcs bespoke for sqlite, that uses a sqlite db instead of `.git/`. cf *dragonfly bsd*'s _hammer_ filesystem (viz b/c it has historic records & mirroring [redundancy] (cf RAID).) remember, though, that any filesystem based on lies (viz disk cylinders) is undesirable. i ideally want no disk partitions and no filesystem, but instead, a datasystem (i.e. a database, though not necessarily a tabular one.)

NOTE: i use _data_ and _information_ interchangably.

remember that much like how we want code and not programs, and a database instead of filesystem, we want a distributed os. the pattern here is to avoid (really _defer_) partitioning or other constraint as much as possible. dragonfly bsd seems to be quite good in the respect of being distributed over hardware.

users usually prefer fuzzy search rather than regex.

see also _best paradigms_ and _just use lists_. this document discusses the user's experince with using a computer—common tasks like writing & reading information, configuring their system, communication among code, guarding themselves against incorrect operations, recovering from accidents, communicating with other machines, extending the functionality of one's machine, &c.

this document expects all users to program, but for programming to be no more difficult than the problem that the program aims to solve i.e. the programming itself is trivially simple, and in fact quite fun, since it should use notation much superior to natural language, and is beautiful. anything else is inadmissable.

=== ideal 

living, organic, self-sustaining, self-repairing, context [environment]-sensitive, helpful, adaptive, polymorphic information manipulation & parsing system. it seeks to _help understand my will, then help me fulfill it, rather than being a dumb, dangerous machine that takes my orders._

* forget _programs_; think of just _code_
  ** all code should execute in shared memory and have direct access to hardware
* forget _languages_; think of [notations for] simple abstract machines (e.g. stack, register, array, or list machines)
  ** your notation [graphical representation] should be elegant and terse
* forget text, and forget _editors_; have a single data manipulatiion program. data may be parsed by any pattern, expressed by any form (graphical, audial, &c) and manipulated by any gesture, where _any_ means _whatever appropriate_.
* never represent non-textual data by text. for example, never should the text string "1245.657" exist; that should always be a number! parse bytes, not text!
* hierarchical filesystems suck; as with most sucky things, they impose unnecessary constraint: namely, for starters, being a tree rather than general graph; however, even a graph is overconstrained: it assumes discrete nodes, whereas data is continuous. prefer a database.
  ** blobs still have their place; some things, like media or books, are to be viewed by themselves, and so should be stored with definite bounds (considered as closed sets rather than an open ones.)
* no thing's constraint should affect other things' constraints, unless a constrained group of things is considered, in which case some subset of those things must modify their constraints in order to satisfy the group's constraint.
* _better than web_ paradigm: rather than http, requests are db queries & responses are some form readable by the db. the *data viewer* program can present & manipulate these responses just as it does of any data.
* code should be able to be paused. this may happen manually or when an error occurs. a paused program should be 1. manipulable while running, and 2. writable to persistant media; then resumable from either (1) or (2).
* "data soup" (implicit definition): specify things without regard to order, then allow any order(s) to be calculated. metaphorically, prefer identifying/selecting data by pulling out from a pile rather than selecting a cubby hole; in a pile there's just stuff (mass noun) rather than things (countable noun) and delimitation (subset selection) is done on-demand, not on-creation. examples:
  ** a la prolog, specify states (by predicate, even if that predicate is equality with an arbitrary nominal label, "λx. label(x) = such-and-such-state") and maps from states to successor states
  ** efficiently have multiple files as views of data; we may have many items in a database, and a file that is a function of them all e.g. the data are a set of facts; a (not _the_) file of them is generated on-demand: the facts are sequenced as bullet points in asciidoc format, a corresponding table of contents is generated, then the whole document is converted into html then displayed, all on-the-fly without writing to disk. any number of views may be defined, and they all reference common data, so that nothing must be stored redundantly, and knowledge may be had in any amount, focused on any particular subject, arranged for any particular audience.
  ** hooks are implicit definition: rather than insert an operation at a particular point of execution / control flow in a program, a hook specifies a relation between a (named) point (generally 1+ point(s) satisfying a predicate) of execution context and some function. the hooks of a given execution context usually run in indeterminate order, btw.
  ** put into dbs instead of into a file. for files, you must seek to the correct place (assuming that only one exists) to insert the data; dbs have no such restriction.
* messaging (async communication among code) is good e.g. π-calculus or racket's thread mailboxes. in fact, generally concurrent systems are best: they're parallel and generalize to being distributed over multiple machines, but most importantly concurrent programs that work tend to have better designs than non-concurrent programs.
* persistent and volatile storage should be shown to programs as a single thing. TODO: how? link:http://metamodular.com/Common-Lisp/lispos.html[apparently] this was first done in the 1960's.
* all specification of constrained data must specify, as you're entering it, and with tab-completion/antiparsing, the set of valid elements, so that any ultimate input from the user is guaranteed to be sensible
* proglang uses free & bound vars, requiring disambiguation / binding only as necessary

===== benefits of dbs

* acid resists malformed states/data.
* there's no difference, in code, between a local vs remote db
* supports information soup, non-unique data, and overlapping data
* optimized for storage, access, and modification
* often serverized, so machines can communicate
  ** supports the _better than web_ paradigm
* no _pipes_; pipes (at least as currently used) support only linear pipelines of byte streams.
* rows are parsable as collections of distinct attributes
* can modify more efficiently than files? but databases are stored as files on filesystems; TODO: how can dbs more efficiently reshape themselves than filesystems or files (e.g. editing a csv file, which is a [linear] blob instead of a tree or rope)?
* supports data soup (see above) instead of files & filepaths. there are more appropriate, elegant, and powerful organization schemes than *linear strings* of data (the contents of any single file) *partitioned into separate chunks* (so no file can share data with other files) whose *names are mandatory* (which leads to inappropriate, misleading, or nonsense names, since some things are anonymous, like how lambdas are more appropriate than named functions; or multiple files are all equally deserving of one name) (and part of the name is dually a _location_; what the hell is that about?) organized in a *tree* structure (which is less capable than a dag or even more generally, a graph). the last constraint is relaxed by hard & soft links, but these are obvious addendums to the scheme and are therefore awkward, forcing us to consider, generally for any filesystem object, whether it's a link, hard or soft, and whether to follow it or not, and whether to delete the linked file or unlink.
  ** the fact that filesystem paths are dually the separate concepts of location and name causes trouble for globs, making globs potentially unsafe. it also forces us to deal with, for _every single program & function that deals with the filesystem_, recursion, and whether an object is a directory, file, or link. we see this as all programs supporting an optional _recursive descent_ option. it also causes nonsense trouble that shows inconsistency in the filesystem design, such as being unable to write to file at a filepath whose basename is a directory that does not already exist. furthermore, at no fault of the filesystem, but of the developer who wrote the error message, we get the most idiotic & misleading description of this possible: "no such file or directory." that one is simply inexcusable, especially considering that that idiocy has been around for 40 years across multiple forks of unix-like operating systems.
  ** no filesystem that i know of supports arbitrary/extensible file metadata. that's why still in 2022, `grep` and `find` are our best tools for querying the filesystem. that's ass.
  ** the sole index that filesystems have is filepath. how about indexing by _data_? if you're lucky enough that your data is simple enough to be organizable by a tree, with data being neatly chunkable where each chunk can be described by a unique name, then good for you; otherwise what'll you do? your best strategy is to adopt naming conventions so that you can find common subsets of files easily e.g. regex `/([a-z]+)([0-9]+).(.+)/` corresponding to 1. a name, 2. a uuid, 3. the file type (and if you want something to be of multiple types, then you'd better ensure that your type string can be matched against multiple regexes, e.g. extension `.media.mp4` matches `/*.mp4/` and `/*.media(.[a-z0-9]+)?/`); this allows you to select media generally or mp4's specifically. massively modifying filenames to support arbitrary predicates does not generalize well! in fact, even this specific example fails: it matches a hidden file called `.media`! as any decent sql user says, regex is an inefficient and error-prone way of selecting data! it's far superior to have each separate attribute stored separately. btw, separateness of data is ok in a sql db because selecting functions of arbitrary subsets is easy, so any data boundaries can be as easily ignored as `cat *`. indeed, any general-use, non-extensible system that doesn't support overlapping predicates is doomed to be a pain, requiring the user to twist their arms just to enable themselves to make the system technically succeed, but painfully so.
  ** in my experience, it's much more a pain to work with filesystem apis than sql
* implicative tags (tags plus implication rules) implement subset hierarchies e.g. tagging raviolli as `pasta`, when rule `pasta => food` is defined, makes raviolli match searches for each of both `food` and `pasta`.

==== tech currently nearest to the ideal

* TODO: is there anything better than linux?
* on *nix systems:
  ** for db fs, make a [virtual] fs; open, write, &c are simply sql statements. this allows one to use a db instead of hierarchical fs, but serves as an interface for current h.fs programs (e.g. picture viewers) so that you can continue to use them as they are.
* programs can communicate via http/tcp, udp, unix sockets, websockets, cmdline, pipes, or writing to & reading from shared state e.g. files, dbs
  ** to make a program interactive, daemonize / serverize it; allow it to run in the background, and accept input from socket, stdin, reading from a file &c
* if it's appropriate to use a poor language, then at least there's probabily a lisp or scheme of that lang.
* because often data is represented by strings, you should know a good parser well. parsing expression grammars (pegs) are very good. however, the only lang that i know of that uses them is janet, which is a poor language. haskell has good parsers (megaparsec) but haskell is a bit high-level. racket has megaparsec but its implementation seems to be buggy/flawed. fortunately, if you know programming well, then writing parsers is trivial. in fact, ease of writing parsers is a good measure of how good a programmer you are, specifically how well you understand ad-hoc and/vs symmetric structures.
* for text ui, use kakoune to manipulate text, then pass text to a backend program that actually parses it and performs an action and/or modifies the buffer.

=== design principles

.non-technical

* computers don't do much: they just change [byte] values at given locations in memory. any other presumption about what computers do is merely an interpretation that's only appropriate if accurate and useful. remember that you can always choose to just move bytes; you don't need to burden yourself with unnecessary suppositions. now, naturally, since we're dealing generally with ordered information, you'll want to encode information by groups of bytes and define transforms (or an algebra) on them.
* eschew unnecessities & redundancies
* code should be easy to refactor; this is afforded by making small subsets of code meaningful, where they, if abstract in meaning, are concretely meaningful in the contexts in which they're placed, e.g. a sentence fragment is syntax that is meaningful by itself, but is not a complete thought; it can be associated with other sentence fragments of particular form in order to constitute o complete thought.
* language is a tool, a representation of truth, not the truth itself! do not allow language to mislead you! indeed, choose a _notation_: a _direct representation_ of truth by symbols, so that you can manipulate truth while benefitting from the ease of reasoning enabled by symbolic reasoning!
* keep particular _principles_, techniques, or other _abstractions_, not particular tools (including langs)!

.technical

* _constraint_ has two forms: ad-hoc and symmetric. ad-hoc is arbitrary grouping. symmetric is whether a thing follows a predicate or not. constraints are the domain of a "branching" map (really _partitions_), whose cod is any object. partition functions are the basis for *parsing*.
* _code_ is order (vs chaos). code is not necessarily executable. however, as any (orderly) thing may permit multiple interpretations, one of those interpretations may be as executable instructions.
* the order of the structure (i.e. the form of a structure considered as a duple of mass & form) directly corresponds/represents operations on / traversals over the structure.
* use metaprogramming i.e. use a framework that does not distinguish between executable & non-executable code. avoid macros (as e.g. picolisp does) if you can.
* trees are isomorphic with nested lists. this is universal, not particular: `cons` (ad-hoc binary association) is the primitve association operator; trees are the result of recursing on `cons` produces binary trees, any subset of which may be interpreted as a list. `cons` is the mechanism that enables grouping physical data; sets defined by predicates define abstract & symbolic data.
* create/identify structures that increase brevity by encoding symmetry implicitly in the structure's algebaric axioms. matrices are such an example.

.princples

* seek elegance; minimalism & beauty always follow, though seeking the latter two do not guarantee elegance.
* seek simplicity; safety will follow. seeking safety will not guarantee simplicity.
* ignore how things are done; consider only naïve ideals, then identify an optimized version thereof, constrained by any [currently] inescapable constraints (namely constraints of the implementing system)
* resist data types; store everything as groups of bytes, and allow any group multiple interpretations. if data should be interpreted particularly, then make it difficult to interpret (parse) it as (into) any other data.
  ** magic numbers are easy solutions
  ** if a thing fails to match a predicate, then it should fail to match as early as possible
* maximize unambiguous polymorphism

.useful particularities

* using delimiters instead of indentation means that anything can be a one-liner. this is often useful when mixing languages, e.g. `ls -1 | janet -e '(loop [l :in (string/split "\n" (file/read stdin :all))] (when (string/has-suffix? "adoc" l) (print l)))'`. this example is not so good because it uses both starting and ending delimiters, which can be unruly to keep properly nested; instead, a stack lang would be much better for one-liners.

=== using non-ideal systems

* use others' code, if available, rather than writing your own, unless you can implementat (more) elegantly, quickly, efficiently, and easily enough.
* use external invocation (`execl` in c, `system` in racket, `os.execute` in python) and stdin & stdout, or sockets, servers &c to wire dataflows independent of language. if you can't call fns directly, then wrap the fn in a main method that accepts (from stdin, a file, db, cmdline arg &c) the data that you want.
* to resume from a crash, write program state to a db or file.

.stability & sanity

programming as a field is always seeing new tools, people, techniques. often we're expected to know them because new, useful software uses them, or because an employer or customer demands so, or because we're collaborating with others who use these novel things. keeping up with it all is hopeless: there's too much, and much of it isn't even useful! often "new" technologies are just common ones being marketed differently. for example, currently blockchain, machine learning, and orchestrated containerization are being applied _everywhere_, though they're needed (or even useful/appropriate) in few places.

we find ease in the things that do not change: algorithms, data or abstract structures, and even common software that's been around for a very long time and/or is known to be reliable.

.prefer (sql) databases

databases are the most advanced common software. they implement all the most difficult aspects of programming:

* concurrency
* atomicity
* optimization for both speed and memory for large datasets
* memory (databases are assumed to be much larger than RAM, and their operations account for this)

and they implement some less-difficult yet appreciable conveniences:

* sorting & grouping
* union & intersection
* repl (effectively, by transactions)

therefore to use a database is to make an efficient program. the only places where databases are as good as general purpose proglangs are:

* certain algorithms
* IPC or interaction with remote services
* stateful imperative logics
* hardware interaction

basically, databases are good for everything that involves data, but inappropriate or unaccomodating to everything else (namely anything involving i/o.) not only this, but databases may work locally as a program, or run as a server, which makes database code automatically work for either single-host or distributed use cases.

.beneficial imperfection, and non-symmetric exploitation

know when you need to program for perfection or not. for example _linearize_ (use a linear approximation of) mathematical expressions, or estimate mathematical expressions over reals by a series of bitshift and linear algebra operations. know when it's better to use a hard-coded lookup table or use an algorithm to produce values. code for your purpose rather than a "good" implementation. for example, your situation may call for random numbers. your choices are a random number source like `/dev/urandom` or a pseudo-random number generation algorithm. you can use the former if it provides enough data. if using an algorithm, then it only needs to be seemingly random—something that depends on what the value is to be used for. don't waste your time making a super-unpredictable algorithm if no user will notice the difference. an algorithm may be convincing enough for pseudo-random game events but horribly obviously not truly random for producing a grayscale image of white noise.

remember: this is coding, not mathematics. we often can't afford perfect mathematical precision, whether it be real analysis or combinatronics. for most applications it's better to use approximate solutions then adjust their results for sensibility, than to calculate as exact a solution as could be considered reasonable.

this may seem obvious, and maybe it's only a problem for few people, but please resist any inclination to make the best solution that you can simply because it's the best and you can; prefer simpler, faster, lesser yet sufficient solutions (except when you're uncertain about how the solution may need to generalize in the future. this can be tricky to predict, and is very particular to each situation.)

.fundamental computer science

programming is just recursion, lists & maps / alists (i.e. lists of pairs) / tagged unions (lua shows that these are all the same structure,) and concurrency. computer science is implementing mathematics by these. vectors, lists, stacks,...they're implementation details, which can be important, but only for efficiency rather than result state. graphs are the most general data structure (though not the most general mathematical structure) but are implemented in terms of arrays & maps. ADTs are useful, but they're expressible recursively by lists and maps—more general and thus more flexible structures. strictly, the cons pair is the smallest data structure. it corresponds to the fundamental mathematical principle of _association/relation_—the basis for all super-singleton structures.

given pairs' fundamentality, we see that every structure can be considered or traversed as: itself naturally; a tensor/matrix; a graph. if you're familiar with these structures, it should be clear how databases or parallelized GPU operations can be very useful here.

again, *keep it basic*. much of programming or computer work today—even what's considered brilliant and popular—is really just about making needlessly complicated things simpler—even though they end-up being still overly-complicated (or limited, or difficult to use outside a very specific use case.) let's not forget how simple things are, and be very careful when promoting anything more complex than maps & lists. and guard yourself against anything more complex! there are many such things, and they sound good, and they do work, and so they're tempting! it's very easy to accidentally find yourself in an ocean of complexion, wondering how you strayed so far from simplicity. obviously this is true only for large programs/systems. however, i encourage that you not go too much out of your way to try to discover/learn the hottest tech or try to learn all the tech in order to make yourself seem versatile. there's too much, and it'll corrupt your mind. however, on that note, i do encourage, if you're so inclined & capable (i'll offer a course later on this,) to consider mathematical structures' applications to computer science, such as universal algebra / category theory, linear types, or using tensors for general computations; or cs-specific things like AVL trees. considering these problems and solutions will improve your programming. again, though—generally—mathematics affects how the program is described, whereas cs affects the efficiency of the program.

everything (all data, and functions) can be represented by *pairs/lists* as used in scheme. maps (isomorphic with *alists*) are structures composed of pairs. *tagged unions* are isomorphic to maps from symbols to values. lua is a good language (semantically) because its one structure is a list/table. these are the same structure: a table is another term for a map: lookup values by indices (of any type.) a list (again, specifically in lua) is just a table whose indices are always positive integers. javascript has objects that are similar, and so javascript would be (and used to be) as good as lua; however, recent revisions of javascript introduce special semantics and syntaxes that void that elegance of simplicity.

all programs can be described by the lambda calculus, wherein functions are represented by _lambdas_: simple mappings from inputs to outputs, e.g. `(lambda (a b) (* 2 b (+ a 3)))`. the meaning is obvious. the fact that this is an s-expression implies that it is data—namely it's isomorphic to its quoted form in its evaluation context.

so whenever someone mentions something like chef, ansible, kubernetes, or any of many popular softwares whose name gives absolutely no hint whatsoever as to what it does, and you go to each's respective website, and you encounter astonishingly vague language, or it describes some revolutionary new system or some junk, ask yourself: how do i express this thing as a graph, table, list, or abstract mathematical structure? for example, ansible is basically `map`, but maps stateful modifications over a list/set of machines. nix is a system for executing arbitrary pure functions (usually to an executable program or a library) whose domain is dependencies, with caching support. dependencies is a graph (specifically a DAG.) people love telling what you can do with their software, but that's hardly a concern for us hackers, since hackers understand structures (including functions) and muse about all the different ways that they can use them. besides this, a software's ability tells us nothing about what it is, how to think about it, etc.

this thinking removes all mystery. for example, scheme continuations are usually difficult to learn, but if you realize that all programs (and very clearly lisp programs) are trees (viz ASTs) and that there's a map (table) from identifiers to syntax contexts with values, then continuations are very simple to understand: they're just nodes in a tree, and moving around continuations is just looking-up in a map. despite being moot, continuations' brilliance is that the objects of the table and map are execution contexts! that's the kicker. haskell is a relatively good language simply because it associates data with types, and types are logical constructs that support implication and testing. the _association_ and _logic_ make it good. that's the magic. how is the logic implemented? there's a loop over a couple sets of logical propositions. that's a significant portion of the implementation of a professional programming language! programming isn't hard. the only reason that programming (or using computers) is difficult is because either 1) you're using bad tools or techniques; 2) the problem is inherently tricky, even if not initially obvious. for example, computing the integral of e^(x^1) is easy, but e^(x^2) is not. in other words: we typically consider a solution to a problem, but encounter trouble when expanding it to a general solution. while you should always strive to know how general your solution needs to be, predicting future needs can be very difficult, so just do your best with what you have. though not particularly covered in this course, there is a technique to design systems for flexible generalizing. i might offer that in another course, but it requires a strong foundation in a variety of mathematics that i alone have identified and haven't finished my seminal book on.

almost always, the more that software obscures the simple structures that underlie it, the worse the software is: it's difficult to keep track of options, there are more options than appropriate, the options or operations do not compose well (or at all,) and there's a decent chance that the software will make certain operations easier than others, which may or may not be a problem for you depending on your use case.

.special techniques

* fuzzing
* parsers & antiparsers
* typing (note that types are predicates, i.e. logical statements)
  * composing types and seeing which programs they beget, e.g. a list or tree or dag or graph editor, which would work on bookmarks, spreadsheets, playlists, etc
* streaming
* parallelization
  * MIMD is better than parallel threads
* concurrency
* purity
* memoization

.saneware

software is only as good as it is when it fails. when software works like it's supposed to, then that's good, but it should be expected that it'll fail (or that you'll want to use it in an uncommon way,) and when that happens, if you can't overcome that error or find a way to implement your desired behavior, then the software is worthless.

these wares follow the description of sane computing: simple, serverized or main-shimmed, use funcalls and standard ports. these wares use self-descriptive names and have neither special usage nor installation guides. furthermore, as a practical consideration, these wares do not suck (they do what all they're supposed to and have no needless quirks.) each program does one thing, and for programs that are commonly used work together, any new user does not need to know about these common usages in order to use any subset of tools together.

* link:https://github.com/mawww/kakoune/blob/master/doc/design.asciidoc[kakoune]
* language server protocol (lsp)
* link:https://w3c.github.io/webdriver/[webdriver]
* link:https://nyxt.atlas.engineer/article/technical-design.org[nyxt] (uses xml-rpc to bridge controller (nyxt/lisp) & view (webkit))

== sane "os"

TODO: experiment with / use porteus linux, then discuss its design here

unlike _sane computing_, this document deals with code that interfaces with & manages hardware including persistent and volatile memory, graphics cards, drivers, &c. that's what an os is: code that:

. the motherboard firmware (namely uefi) or bootloader runs
. runs other code
. allows direct access to hardware or device drivers at varying layers of abstraction

operating systems are not necessary. in fact, they're harmful because they're useless, and anything useless that's enforced is just cruft that you need to navigate around—needless constraint. instead, just have code that is intended to make the system run without the user running the code explicitly—so-called _system code/software/programming_. at some point, though, there must be a _resident monitor_: code that loops infinitely, either running itself or running other code then returning to the infinite loop. after all, we don't want to power-on our computers, let it run a program, then the program's done and the system shuts-down!

oses typically:

* come with libs, but that's not necessary; we should just use external libs, just as we use external programs.
* run "programs." a _program_ is just code that arbitrarily considers one of its functions as being special; that function is called the _entry point_.
  ** programs commonly accept arguments, just like functions, except that unlike functions their arguments must all be strings—a useless limitation.
* describe ways of "managing" programs. this is hardly necessary; no code needs to be managed by other code. in fact, i _want_ to be able to directly interface with hw! that's _simple_ and easy: just write & read bytes.

what an os should be: some code that sends & recieves data from hw, and practically, acts as an abstraction [virtualization] layer to certain hw (e.g. primary and/or secondary memory, physical threads)

given current *nix-inspired designs, the most sane ffi/ipc is either:

. running an external program then reading its output (from stream or other data store)
. directly using a shared object (in picolisp, since all other langs' ffi's are needlessly not simple/plain)
. for bytecode of a lang X, writing a small program (or program that writes a program) in X that accepts module/library name/path, function name, and function args, and outputs the result to stdout; then reading from that stdout

.questions

* what's with different oses? the machine code is particular to instruction sets, not oses, right? and all os libs are just code that can run on a given architecture, right?
  ** e.g. any c program compiled for x86 should run on any x86 chip regardless of os, right? why not? how are machine code blobs loaded into the cpu?
* is there considerable benefit to _programs_ (meaning _a blob of machine code_) instead of running it dynamically à la picolisp?
* look at minix again; iirc it gives programs direct access to hw but is fault-tolerant.

.langs that compile to machine code

really, how beneficial is compiling to machine code? i mean obviously machine code is all that actually runs; so basically what varieties of vm are sufficiently efficient, especially for code that we can pause and edit its state then resume it, which is ideal? compare rust, which is extremely optimized but non-dynamic, and picolisp or a stack machine. on modern hw, especially when using matrices to exploit gpus as a main vector of computation, what's a good optimization/hackability tradeoff?

_TODO: see lisps.adoc

=== writing a sane os

see link:https://www.youtube.com/user/Computerphile[computerphile] for vids on low-level computing.

the contending implementation langs:

* scheme48
  ** failing that, chicken
* pil
* link:ulisp.com[ulisp] (μλ)
* link:http://ferret-lang.org/[ferret] (see link:https://nakkaya.com/2016/06/10/ferret-a-hard-real-time-clojure-for-lisp-machines/[this example project])
* cl (with one of these compilers: embedded common lisp, clozure, sbcl)
* link:cons.io[gerbil scheme]
* nim
* go
* asm
* d
* spark ada

c didn't make the list because, despite being low-level and simple, it lacks macros, has highly redundant and non-tacit syntax without a macro system capable enough to feasably overcome, and most considerably, relies on compilers to find & link libraries—a task that shouldn't be problematic, but also should be done automatically; neither of these is actually happening, though.

qualifications of the chosen lang:

* system lang
  ** efficient
  ** direct hw access
  ** good semantics & syntax
    *** hacky (no restrictions; no data types, memory access restrictions, purity, overly-restrictive scoping, &c)
    *** tacit

compiling should be done only where appropriate (hot-loading machine code would be better) and _linking_ should be considered very uncommonly; rather than have static vs dynamic linking, just have dynamic, and version control everything and/or allow multiple copies of things. linking static libs is not practically better than compiling the lib's source along with other code into one executable; though more efficient, such an efficiency gain is unconsiderable for good, terse code compiling on modern hardware. if linking is to be done, then it should appear to the programmer as simple as importing a racket or lua library. most certainly, at least, having link:http://www.yolinux.com/TUTORIALS/LibraryArchives-StaticAndDynamic.html[separate `.a` and `.so`] types is outright tomfoolery; code is code, and may be either embedded into an executable or dynamically loaded.
