.practical wisdom

all of coding/programming is just 3 things, and they aren't even complicated: grouping data, arithmetic, and sequencing io. in other words, one of the simplest example programs is one that partitions words by whether their first letter is lowercase or uppercase, then printing all the lowercase ones as uppercase before all the uppercase ones as lowercase. case conversion is either a bitwise operation (for ascii), addition/subtraction (possibly for other codepoints), or transposition via a lookup table. a lookup is nothing more than a sequence of sequences—more specifically, a sequence of arbitrary length each of whose elements is an ordered pair. we see it just as well in turing's famous abstract machine: data related to each other by sequence position or selected by programmatic rules, then reads or writes performed in a particular order. the arithmetic is in deciding which value to set at a given index. most people consider `if` to be non-arithmetic, but it can just as well be described arithmetically. by the way, i think that sql programs are nice analogues to turing machines; they're the same idea, but obviously practical rather than underwhelming. to be fair, turing's machine is useful for theory, not use, but its simplicity is beautiful, and i'm sad to see students learn about a thing so dissimilar to programming languages that the student can hardly relate them, and mostly forgets turing's machine as some abstract, impractical, theoretical nonsense that their professors may care about, but what they do not, thus beginning their descent into the nonsense madness that is arbitrary language features, designs, and idioms, quickly losing sight of the actual _computation_: the storage and manipulation of data, all stored in one simple, given, universal, efficient structure.

NOTE: one may suggest that reading & writing are separate, important operations that i didn't mention as fundamental. however, they are exactly equivalent to arithmetic: firstly, all values are representable as numbers; secondly, one must load this number, and the number is only useful if we first do something with it—i.e. produce some transformed value from it—then do something with that result: either piping to an io resource or storing the data (setting it somewhere). more simply: "reading & writing" is a mere rephrasing of "input & output".

.universally applicable, philosophical wisdom

_computing_ is just interaction. what are commonly known as "computers" are no more particularly computers compared to any other interaction. they are notable, however, in that they're _programmable_ i.e. that manipulating them to do arbitrary desired tasks is easy.

all meaning is relation. therefore all computation is relation. all relation is symmetric or asymmetric. computation over asymmetric relations entails branching i.e. a computation per branch, and each branch is an asymmetry. asymmetries are partitions of symmetries i.e. some thing is by default symmetric, but when it's subsetted so that each subset can be related to a different computation/consideration, then it's been "broken into asymmetries." the once-symmetric structure is now _considered_ asymmetrically i.e. we've decided to *interpret* it so that its *meaning* is given by asymmetries. remember that data are matter, and computations are form i.e. relation i.e. meaning. we may call it "data", "code", or "information", but it's all the same thing. it's the "stuff", the matter, and matter itself can form other matter, and so of course even rectangles are parameterized by width & height, and can be generalized to other forms such as closed figures, which may have any number of sides or constraints, and can be generalized to curves simply by introducing more, special point parameters, such as bezier curves, and thus we have mutation of structure itself just as well as the mutation of the structure's constituent data.

value is value. values can be distinct (symbols) i.e. support equivalence, and i haven't explored that too much yet, but additional structure—order—is what gives us "numbers" and by "numbers" i mean "any totally-ordered value" e.g. naturals, reals, or sequences thereof, such as strings, which are just sequences of codepoints or otherwise of values supporting an alphabetical ordering. complex numbers may be totally ordered, but we decide for them not to be; only each of their components is ordered. these particular rules (algebra) that we enforce of complex numbers (i.e. that which makes an ordered pair a complex number) is fine, but note that it is a limation of computation. constraint can afford us efficiency, guarantees/provability, and hone our focus, but it constrains. always be careful the degree to which you constrain i.e. resist mutation. it can be useful, but it can limit you from discovery.

."low-level"?

tl;dr: we define things for brevity's sake. resolving definitions can be handled entirely at parse time, as macros. in fact, the majority of code should be done in a macro system with forth-like syntax.

what "levels"? there're just the 3 ops, and we can specify how the computer does them e.g. does it store as float vs int, and does it use the registers vs floating point stack to perform arithmetic. so the machine doesn't get in the way of the grouping nor arithmetic, and enables us reading & writing at any physical addresses e.g. sockets, file paths or handles, locations within a file, etc. we decide how to physically represent information in hardware such that the hardware can efficiently perform grouping & arithmetic! how could we not always consider the hardware? well...

* "levels" may refer to abstraction layers i.e. multiple dispatch i.e. selection—`case`, `cond`, or ad-hoc polymorphism—just a map from value to computation.
* somehow people tend to design systems of constraint upon each other, which they call "levels" and what i call "a mess"—exemplified by link:https://www.youtube.com/watch?v=aSEQfqNYNAc[hickey's `HttpServletRequest` rant].

i see functional programming as just another needless abstraction that complicates code in the name of "organization." ask someone who's used to a lambda-enabled language how to write a predicated linear search without lambdas. will they immediately, plainly know that `find : (a -> Bool) -> [a] -> Maybe a; even? find` is just as well semantically & syntactically as inlining the predicate into a loop body: `int i, L = length(xs); while i < L and not even xs[i]: i++; if i=L then i=-1;`? the problem with the c version is not that we have to inline the lambda; the issue is entirely different: that the syntax is verbose! functions/macros abstract that away just as well as a higher order function does! b/c of c's arbitrary design (not b/c it's necessary or anything), we can't elegantly abstract this boilerplate into a higher order function, but we can abstract it easily by a macro! but then ohes noes! macro hygeine problems! so one may devise e.g. scheme's hygenic macros, but those kinda suck, too. but then someone says, "hey, let's forget referencing variables by name, instead referring to them only tacitly, by e.g. their position on a stack", and thus the general abstraction problem is solved, and we're left with forth, and we're happy inside. notice that lambdas/higher-order-fns are rarely used in practice in j (an apl) code, yet the code is terse and elegant. j achieves this by using the special syntax (thus effectively a macro) called "trains"; without this syntax, one would need lambdas to express the computation. this is a rare example of demonstrating the *equivalence between lambdas and macros/syntax*. this is rather apparently seen in factor using quoted programs rather than lambdas, and that picolisp's fexprs are the same form as its lambdas.

i suppose a lot of what seems like magic in higher-order languages is that a lambda is a computation without a memory address like how functions have, but rather is just a value, yet the value is invocable via `call` [factor style] or just the `()` suffix [algol-style] or outfix [lisp-style] syntax, whereas in c the function is defined, then has an address, then that address is passed to other functions as parameters, so c supports higher-order functions, but not lambdas (no anonymous h.o.f.'s). but one is only as well pondering h.o.f.'s as they are about pondering the infinite multitude of abstract forms seen in haskell communities.

there is something to be said of macros simply being ordinary words evaluated at parse time. indeed, some things we simply want to evaluate then rather than at runtime. in this case, macros aren't about syntax manipulation; they just modify parse-time program state, or are, like ordinary functions, just abbreviations/templates, but eval at parse time. so really, macros should be as ubiquitous as ordinary functions, and should not be considered differently. one thing one must ask, however, is why they'd choose to define something as a macro as opposed to a function. if it's for better syntax, then you should probably use a better language like j or factor. if it's because your language restricts what can be done at runtime, then be clear about why you need this pattern that can't be expressed by anything other than a macro. for example, in factor, which has an always-enforced stack checker, it is better to define variable-effect words as macros, having them checked at parse time, rather than "stack casting" (like type casting), hoping that it doesn't crash at runtime. in that case, i know that i'm resorting to a macro because i choose to benefit from the stack checker, and that must be done at parse time (and it also requires that the argument quotation be known at parse time i.e. that it's a literal quotation or a defined word). but this business of "oh, you must be careful about macro hygeine b/c macro expansion is literal, having no consideration of namespaces" is just stupid. it shows both how namespaces / applicative code / lexical scoping are bad design, and how stupid is the inconsistency for the macro system, despite being a part of the language itself (unlike c pre-processor macros), to not consider namespaces (a foundational feature of the language) even though they're considered when parsing the code. simply, there's no good reason for macros to be treaded any differently than any other code; if there is, find or make a language where it isn't.
