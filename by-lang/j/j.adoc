= array programming in the j programming language
notes by nicholas chandoke
:toc:

personal refcard (arities omitted when obvious. 3 means both monadic & dyadic):

-----------------------------------------------------------------------------------
uniqueness: =/2 ~:/3 ~. -./2 /. e.
order: < > <: >: (lte,gte)
add: + +. >: , 
sub: -    <: -.
mul: * " *. I./1 #/2
norm: | # *.
div: %
iso: #. #:
  index transform: |.[!.f] |: $
discrete math: +. *. (gcd,lcm; also used for +*/2) | p: q: A. C.
real math: ^ ^. %. p. o.
ℂ: +/1 (real & imag) *./1 (len & angle) r. (angle) j.
indices/intervals & order: <. >. (floor,ceil) * (sgn, ℝ only) I./2 ;.12 /: i.:/3 E.
short-circuiting & deferral: i.[1] ^: F. ` `: @. ".
-----------------------------------------------------------------------------------

[1] `i.` is `{.@I.@=` but stops early. `e.` is the set-theoretic version.

NOTE: `I.@E.` is `i.` but matches substrs instead of elts.

NOTE: just as factor's stack checker enforces symmetry of branches, so should you code s.t. you don't need to branch; rather than selecting from multiple operations, express them as values passed to a least greater super-operation, usually leveraging identities and nullity e.g. conditionally printing a value can be expressed as printing a value or the empty string. this might not be a good example, since it's io, but w/e.

[TODO]
* syntax highlighting in kak for idioms; each idiom gets a different color depending on the kind of idiom [functionality].
* j ought to be more interactive. graphical tiered display of modifier trains, with annotations of the kind of modtrain pattern it is e.g. AAV, VVV, or VV. b/c trying to parse-out nested parens and break <code strings which represent trains> into parts is horrible. ofc we'd need a good interface for modifying these structures. for starters, though, just having adjacent displays of code and a tree would be amazingly helpful already. afterward we can have a fully opengl environment with keybinds for selecting subexprs.
  ** use `5!:6` to get defs. `par=:{{5!:6 <'g' [ (g=.u f.) :: ] 0}}` works like `(2++@-/&?)par`; it's an adverb which takes an expression. replace `5!:6` by `5!:4` to produce a diagram instead of parenthetical.
  ** use link:https://code.jsoftware.com/wiki/Vocabulary/Dissect[dissect]
  ** interestingly, because j's grammar is contextual, syntax highlighting requires semantic knowledge, namely which part of speech each entity is. that's pretty easy. semantic tools like we see in swi prolog should be easy in j, too, right?
* consider j primitives wrt group theory
* how to put quotes &al special or unicode or bytes in string literals?
  ** quote literals in strings are done by escape sequence `''` e.g. string `'it''s' hot today'`
* the ability to use `jbrk` w/or.t. a pid implies that j is one proc? then:
  ** how to run multiple j progs and use `jbrk` on only one of them? 
  ** how to modify a running j program?

everything in j works along the leading axis. when assembling, it concats along the leading axies.

TODO: consider `<jdir>/system/extras/util/boot.ijs` & `<jdir>/system/extras/config/profile.ijs`

== motivation/rationale

* terse syntax, efficient, elegant, suggestive primitive functions, and combinators.
* (multidimensional) arrays store data wrt their symmetries. verbs explicitly or implicitly relate the axes.
* discourages higher-order functions, or generally working with functions; instead it prefers working with data, which is superior design; e.g. rather than a higher-order `sort-by` function, the "grade" verb stores the order as a permutation (selection vector). i can store that information in a local variable, whereas `sort-by` implicitly uses that information within its body but then the information is lost when `sort-by` returns. in j we retain much of a computation's information at once, all expressed arithmetically, which is a great benefit. functions are a double-edged sword: they encapsulate functionality but also partition functionality; functions are interoperable with others only to the extent that they accept inputs (consider data) or return outputs (preserve its intermediate or terminal computation(s)).
* good type system: arrays of numbers or characters (homogenous), or mixed (boxes). no user-defined types. good implicit & explicit type conversion among precision or numerical class e.g. between ℤ & ℂ, or conversion among radixes. these well represent: equivalence classes, lattices, [boolean &al modulo] rings, fields, &c. booleans are literally ℤ/2.
* interpreted, dynamic, yet efficient. b/c j primitives are semantic objects, they can be reasoned about and combined s.t. e.g. `|.@:|.` evaluates to `]`. this does not actually happen in j9.0.4, but it could, and there was at least one variety of combined primitives that, to my pleasant surprise, evaluated to `]`.
* portable & easy to install (except that when i compile it, the repl starts but malfunctions; and when i download the prebuilt zip, i must run `execstack -c` on the shared object file(s) listed when i try running `jconsole.sh` but it fails with "cannot enable executable stack as shared object requires: Invalid argument"). i can't find any info on where execstack exists (though there's an aur package for it) except that it's written by jakub jelinek at redhat.
  ** upon first launch of repl, run `load'pacman'` then `'install' jpkg '*'`. see <https://code.jsoftware.com/wiki/Pacman>.

== debugging & inspection

* monadic `;:` tells how a line is parsed into words, with one word per box
* link:https://www.jsoftware.com/help/jforc/loopless_code_i_verbs_have_r.htm#_Toc191734338[fndisplay] outputs verb evaluation
* link:https://code.jsoftware.com/wiki/Vocabulary/bdotu[`b.`] tells information about _verbs_ but not other parts of speech. e.g. it doesn't tell a train's resultant part of speech. that's fine, though; we can exploit that only verbs & nouns execute; e.g. `every each` in the repl shows their definition and `(every each) 0` says "syntax error, unexecutable fragment (adv noun) which tells us that `every each` is an adverb.
* `3!:0` tells type

== shebang scripting

* the shebang line is itself a j sentence. it must not have side effects nor raise an error, which simply basically means that it should have no special characters aside from, for whatever reason, '/', even in the filepath of the shebang line i.e. the path to `jconsole`.
* there is a command `echo` which is `stdout` but writes a trailing 0x10
* like picolisp, unless you call `exit y` (y is an integer return code), the j repl will remain open after the script executes

== using j well

unlike nearly all other languages, learning j is best done by learning j's array model and primitives before learning the language semantics! j has small semantics and syntax, but small as they are, they're hardly concerned. most j code is just long expressions of array arithmetic (verbs) & trains, sometimes often with binding to identifiers along the way.

verbs to use most often: the (i.)-family, a class of verbs all based on `i./2`, which searches `x` for `y`. they have many variants and mostly linear performance.

* nub [sieve]: `~.` `~:`
* index of [last]; element of (equivalent to `1>.i.`): `i.` `i:` ; `e.`
* without: `-.`
* key: `u/.`

the following special combinations are also considered members of the family: `u/@e.` for `u` of `+. *. +`, and `([-.-.)`.

``x``'s rank alone (or `y` in the case of nub [sieve]) determines how `y` is partitioned (`y` may be multiple data, in a list, or an array): `x` is considered as a list.

TIP: for best performance: if items are numbers, prefer exact comparison; else if items only _contain_ numbers, use exact comparison; else use tolerant comparison.

link:https://code.jsoftware.com/wiki/Vocabulary/SpecialCombinations[special combinations &al optimizations] are essential to using j with a clean conscience, knowing that your computation is sensibly efficient, e.g. exiting loops early, or overwriting memory without allocating new memory, or dereferencing pointers needlessly, as one would in coding in c.

sql's calculus is simple yet very efficient & expressive, and its semantics doesn't even concern arrays (like prolog, it concern sets; still, i'd call it a "plural" language if not an "array" language), so of course it's feasible for an array language to be efficient. however, all other functional languages (excepting factor, perhaps), assuming that you're using their functional devices which differ them from c, execute quite inefficiently because they do exactly what you tell them to rather than optimizing. no _language runtime_ can afford to optimize like an array language can, because array langs are composed of a small set of known primitives. all non-array languages place the burden of optimization on the programmer. sometimes efficient code is clean, and sometimes not. honestly, i think my efficient c & factor code plain & direct; however, it's never as terse as j! also, yes, c compilers "optimize", but they do so by parsing a far more complex, less regular/constrained language (syntax & semantics) than j; thus c optimizers frequently optimize or not based on arbitrary things such as order of operations or how a computation is expressed. granted, also j requires that computations be expressed particularly, but it simply lists these short expressions in one html page. c code complects many data altogether, whereas (tacit) j sequences verbs.

a showcase example is in j how `#\y` is _faster_ than `>:@i.@#y`. in _any other language_ the former would be astoundingly brash, greatly sacrificing performance for brevity, and i'm betting that no c compiler can even recognize the "prefixes" pattern in code, let alone parse it thoroughly & intelligently enough to use such an optimization!

basically to code perfectly is to use sql/j operations/relations but store information as numbers and use S/MIMD.

.j vs sql
[options="header"]
| j             | sql
| `e./2`,`i./2` | in, where (`in` is used only for a search space of literal values specified at parse time)
| `I./2`        | where (binary search on indexed data)
| `I./2`        | join on < (take range)
| `#/2`         | where (general predicate)
| `/.` `cut`    | group by
| `"`           | join using (idx)
| `,`           | union all
| `~@,`         | union
| `@.`          | case

my model for all computation:
* modify traversals, not data
* store data attributes in a metadata bitset for each _needed datum_ (if i need only to consider one search space at a time, then i'll have only one bit vector)
* _index_ is a property of traversal, not of data! sql demonstrates: any table can have one attribute, in which case it's obviously a set; however, having multiple columns, none to many may be indexd. indexing is, by definition, whatever makes lookups fast.
* lookup & traversal are synonymous; traversal is just repeated lookup
* element/index(s) (both always stored together) of <SET>. the lookup is faster if the data are: ordered, for selecting substrs; or hashed, for selecting single elements; hashed is best if you want to select arbitrary elements. of course, what makes hashing fast is that we know the literal index from the value alone; no traversal necessary. same for substr selection: if we can compute the start & end idxs immediately, then we can select the whole range instantaneouly.
* all data should be consumed as streams; this allows selecting any size range to traverse, then traversing so long as the traversal code dictates, not necessarily traversing the whole search space. this allows sql LIMIT to work nicely.
* all efficiency is from exploiting arithmetic ranges (e.g. that a>b & b>c => a>c) & uniqueness. we also see this when unioning bit sets: set union for some booleans is to set each one in the bit set. in computing, all set data is ultimately indexed somewhere, asd if there's a unique mapping between element and index then we can union freely.
* [a,b] is described as natural number "index" traversal variable, `i`: `i=a,i<=b,i++`. testing elements takes more time than texsting the index b/c we must `lea`.
* _uniqueness is conditionality_. it's the very core of what says "do this" vs "do that"; all computation ultimately reduces to `switch` blocks or lookups on equality. commonly some search space reduces to an equality check e.g. ranges become causes via `I./2`, or predicates become indices via `@.`, or cond expands to if statements, each of which is testing against 0/False or 1/True (really 0 or non-zero in c-like langs)
* practically, `else` is a primitive. it means "the rest of the search space". we don't always use `else` (or `default` as it's called in `switch`), but it's a good primitive because it recognizes special cases (akin to asymmetries) vs a common case (akin to a natural symmetry).
* all combinations or union (choice, additive) or intersection (constraint, reductive)
* deriving efficient computation of code hinges on the primitives obeying a calculus that reduces to a small search space

=== the remaining j verbs

`I./2` is the only other particularly "array" verb in j; the rest are common to most programming languages, but where most languages use built-in syntaxes which complect a computation and an action on its result, j has you perform a computation to produce an index or mask, then separately pass that index or mask to a "control flow" verb. much of how j uses arithmetic is how early programmers did, when hand-coding assembly was common, and which techniques were brought into coding in c, a language that practically consists only of `for`/`while` (jump backward), `if`/`switch` (jump forward), arithmetic, and pointer dereferencing & inc/decrementing. however, unlike other languages, apls are suggestive, and they suggest to use integers almost entirely. the only reason that coders used integers so ubiquitously for prior computations is that it's all that they could afford to compute and the languages hardly supported anything else.

NOTE: reflect on how elegant c uses only `for`, `switch`, arithmetic, `*` (lea), and `=` (mov). everything that makes c suck is about its runtime, such as linking, or inconsistent or insanely complicated portability constraints. to call c portable is like calling a house portable. just because it's doable and commonly done by some few companies doesn't make it portable compared to, say, a cheeseburger.

ARRAY OPS EXPRESSED IN TERMS OF FOR (i.), SWITCH (@.), ARITHMETIC (NAMELY WRT RANGES), AND UPDATING ARRAYS:

[NEXT]

| j verb  | j version                            | common version
| `F:` &c | like haskell, only one loop variable | loop syntax
| `,/2`   | append                               | append
| /:      | grade                                | sort
| cut^*^ | 
* indexing modifiers: reverse, shift, rotate
* I./2 /: both concern order
* infix, outfix
* select
* cut/intervals (`I_A` in k) is elegantly expressed in a loop: just collect into a vector on each loop; and upon meeting a condition (e.g. current elt equals spilt character, or loop iteration number divides n, or loop iteration number equals the head of a queue of split indices), push that collection vector into another collection vector. to split on a string or other predicate (e.g. `E.`) quickly becomes the question of how to write a parser. at this point, just use a packrat/peg parser. every language should (as in, that would be good; not as in i expect it currently) come with one.
  ** head, tail, take, & drop are all just particular varieties of cut/intervals. "take n" is expressed in a loop as modifying the index variable's limit to be max(n,prior_max)
* `#.` & `#:` probably wouldn't be expressed as a loop, but were it: collect into an output value (shift left/right or divide/multiply, then add or bitor). mixed radix might require regrouping; i don't recall.
* for key [dyad], just use a hash map in the loop state
* agenda becomes switch/case
* index of (`i.`) of course just returns the loop number upon meeting a predicate of the loop state
* `e.` is linear or binary search

^*^cut can be expressed by `I./2` & `/.`; intervals map to group ids, and `/.` is sql's `group by`. ofc, like `;.n` vs `{`, `;.n` benefits from using an interval, which is a compressed [info theory] coding of an equivalent index set, and thus permits more optimal operations. cut thus is actually more conceptually interesting a primitive than just "split": it's "group by bin."

* `#/2 `& `I./1` both produce multiple copies of data but are commonly used with masks, and wherever a 0 appears, that corresponding data are omitted.

the remaining j verbs are special to j's model:

and the _actual_ remaining verbs, such as `A.`, are ones that i'm simply not going to discuss yet.

sadly, some j verbs, like `u;.0` (or maybe that's the only one, idk) break j design: rather than being one idea, namely "substring", it complects that with afterward applying a verb, and shaping it to ``x``'s shape. i suppose that complecting these behaviors may somehow be more efficient than performing them as separate verbs, but that would be very "un-j." more likely is that the language designers couldn't work a new verb in without making it an adverb and thus arbitrarily had it take `u` as an arg; or that binding the verb operand allows it to be applied with less consideration of framing fill which otherwise would need to be accomplished by boxing then immediately doing `u&.>`. granted, these are real concerns in j, but boxes are a silly design generally. it would be far better, and more consistent—ideally, at least—design to specialize select (`{`) to note when its permutation is an interval, then substring efficiently.

== semantics

* scopes don't nest
* verbs (fns):
  ** stored as strings. evaluated only upon invocation. e.g. `{{2 + f y}}` is `3 : '2 + f y'`. `f` needs to be defined only when `g` is invoked.
  ** functions are passed by name but values are passed by value. e.g.
* to compute at definition time instead of invocation time (like factor's `$[`), surround by `(( ))`. this is called "PPPP" in the special combinations page.
* trains have rank infinity
* arrays' rectangularity & homogeneity is ensured by _framing fill_. to avoid it, box.
* instead of traversing structures to extract substructures, in j we identify indices then apply some substructure primitive like _elements between_ or _elements at_ indices. everything in j is mask-oriented.
* no particular boolean type
* escape sequences are unsupported
* *identifiers can be dynamic*
* *verbs definitions are stored as text then evaluated at runtime!*
* `x` & `y` are implicitly the names of the left & right operands respectively and can be referenced as such in a verb definition
  ** *`y` is the identifier for unary verbs!*
* private & public namespaces exist separately. like globals and `static` in c.
* like scheme, all programs output their values. to output nothing, output a list with no output, namely `0 0$0`, which naturally does not even print a blank line.

== syntax

* `1 2` is an array but `a b` is not b/c words expand to their values in parens; `a b` = `(a) (b)` which is a syntax error.
* `_2` for neg 2, not `-2`
* `0.5` not `.5` (b/c dot is a special char)
* 16b1f means `1F` in base 16
* `_` is infinity. `__` is neg inf. `_.` is nan and should never be used in any program.
* identifiers:
  ** may not contain dot (.) nor colon (:)
  ** must begin with `/[a-zA-Z_]/`
  ** which end with `_` or begin with `__` have locale-specific behavior
* strs delimited by `'`. `"` is the "rank" adverb. only string, no char literal syntax.

=== definition

the following is literally how verbs are ultimately defined but usually we use {{ }} to define verbs.

[source,j]
----
a=.1+b=.5 NB. res: a=6,b=5
x ; y =: toupper x=: 3 5 $ 97}.a. NB. =: is just another verb, not special syntax! this defines x then y in terms of that then returns x;y once y is defined.

v:=[mon|dy]ad : '<def>' NB. define a monadic or dyadic verb
NB. alt form:
v:=[mon|dy]ad define
<def>
)

NB. define a verb monadically & dyadically:
v=:verb define
monadic def
: NB. colon starts the optional dyadic subclause; w/o it v would be monadic
dyadic def
)

pi=:o. :([*[:o.]) NB. monadic is o. . dyadic is a fork which multiplies the left arg by (the right times pi). [:o.] can instead be written o.@]
----

==== caveats

.static scoping, not lexical scoping

[source,j]
----
substrc=:{{
  't1 t2'=.x
  a=.t1(E.i.1:)y
  s2=.{{
    b=.t2(E.i.1:)y NB. s2's y, not substrc's
    if. b=#y do. '' else. (0,:b) ];.0 y end.
}}
  if. a=#y do. '' else. ((a+#t1),:_) s2;.0 y end.
}}
----

defines successfully but fails during execution, citing that `E.` has no monadic valence in `b=.t2(E.i.1:)y`. the error here is that `t2` is not bound within `s2`. if i change `t2` to `x` and use `(t2&s2)` instead of s2 in `;.0 y` then `substrc` works correctly. of course making t2 global via `=:` would make it work but with the side effect of keeping `t1` & `t2` bound in the global environment after executing `substrc`.

=== program execution

verb has left noun: dyadic; no left noun: monadic, right operand. thus you must know whether a token is a noun or verb! i.e. `u v n` sees `v` as monadic on `n` and `n v m` sees it as dyadic on `n` & `m`. thus `u v n` is `u(v(n))` i.e. `(u . v) n`. the simple way to check is:

. identify rightmost yet-unconsidered verb
. is the word to its left a verb?
. if no, then it's dyadic; else it's monadic and its result is passed to the verb on its left

there are no nullary verbs. effectively nullary verbs must be given a dummy arg.

== runtime (execution environment)

programs:

jconsole:: ordinary repl
jhs:: j http server. enhanced browser-bound j repl/ide. uri `http://127.0.0.1:65001/jijx` by default. run in bg unless you want to send an interrupt signal to j. (but why not just use `jbrk` instead?)
jqt:: Qt j ide. if it requires the `dev-qt/qtwebengine` ebuild (on gentoo) probably found by similar names in other repositories.

apparently _somewhere_ there's an _execution window_, whose name ends with `.ijx`, that is basically like drracket:

* accepts verbs to execute
* displays a log
* enables editing the running program's code

windows for editing code that interact with the execution window are called _script windows_. an example interaction is sending code to the execution window via `Run > File | Selection | Window` from the script window's menu bar.

to unset verbs, use `4!:55 <'expiredname'`.

=== environment variables (envars)

* var `ARGV` which is a boxed list of jconsole, script name, and arguments
* unary `getenv`
* unary `stdin` with dummy arg, and unary `stdout`, and `stderr` to read & write
  ** stdin & stdout are obverses. e.g. `toupper&.stdin''` is a program which prints an uppercase version of stdin
* `exit` takes a dummy arg

NOTE: if you do not invoke `exit` then the script will end in the repl

== misc

* to write output like you'd get in a repl to a file, you must convert it to a list of bytes.
* _fret_ refers to the item on an interval's boundary
* file ext `.ijs` means _j script_, which is just a library, which is just some j code. verb `load` accepts a filepath to load (run/eval).
  ** TODO: how to load a file's definitions into the scope that invokes `load`? this is probably a locale concern.
* the notation `,0` refers to a (rank-1) empty list though an empty array is denoted `0,...` and an empty table as `0,c` (∀c)

=== idioms

|=========================================================
| idiom                   | result
| (/:m&i.)y               | sort y by collation sequence m
| /:@i.{]                 | sort y by collating seq x
| ((dom ,a.) i. y){cod,a. | tr
| (#~p)                   | filter y by predicate p
| 'colN' {{y{"1~ x i.~col1;col2;...}} T | index by column name by using headers
| v&.>                    | <@v"0 but simpler
| '-'E.a.                 | ascii code of '-'
| (<:i){y                 | zeroes followed by a 1 at index i
| f@]^:["_1               | apply f to items of y based on mask x e.g. `(3&<!@]^:["_1])i.6`-->0 1 2 3 24 120
| (-:1&|.)                | test if all elts equal
|=========================================================

TODO: when to use `f@]^:["_1` instead of some kind of subset thing e.g.

[source,j]
----
----

it's also interesting to note that testing whether something is in an interval is a linear function: `(v,y,1) *./@:(0&<:)@:(+/) .* _1 1,1 _1,:a,b` tests whether `y` is on [v-a,v+b].

the `(/:m&i.)y` idiom illustrated:

----
   (/:'aCcb'&i.)'cCbaaba'
aaaCcbb
----

the hook `(/:m&i.)y` expands to `y /: m i. y`. here, m i. y is 2 1 3 0 0 3 0.

''''

= old stuff

== j's information structure: homogenously-typed arrays

. like static c arrays, j's arrays are non-ragged & homogenously typed. think of arrays as n-dimensional subspaces.
. _shape_ (aka, somewhat confusingly, _length_; it's a vector of lengths) is the sequence of _axes_ array dimensions e.g. shape 3 4 5 of an array corresponds to c array `int arr[3][4][5]`, which has 3 axes.
  .. the number of axes is called the _rank_.
  .. each axis' value is its length—the number of _items_ that it contains; this sees the axis a _list_ (aka _vector_) of its elements e.g. 3 4 5 is a 3-item list of (4 5)-_cells_; _cell_ is a term meaning _subarray_. each array can be split at any index/axis into a _frame_ and _cells_ (aka _suffix_) e.g. in 3 | 4 5, 3 is the frame. in 3 4 | 5, 3 4 is the frame and the last axis is a 1-cell (b/c 1 dimension) of length 5.
    ... technically _frame_ refers to the shape of the array, but whatever. i'll use _frame_ to refer to either that shape or the array subset that has that shape, if it's ever sensible to do so.
    ... n-cells index from the innermost (aka _trailing_) axis e.g. the 2-cells of 3 4 5 have shape 4 5.
    ... _n-cells index from the outermost (aka _leading_) axis and *drop axes* e.g. the _2-cells of 3 4 5 have shape 5; we drop the 1st 2 axes.
      .... lists are frames. relative to a frame/list, items are _1 cells
    ... the 0th axis is not ever shown, and refers to the atoms independent of (excepting order) shape
    ... technically, if it matters, "if n is negative in u"n, the actual rank of u"n will be infinite, but u"n will apply u to n-cells of the argument."
. axes may be length 0
. the items (e.g. the ints of `arr`) are called _atoms_. atoms have rank 0.
  .. _non-atomic_ means _rank-1+_
  .. an atom has one item: itself
  .. an atom can be interpreted as a degenerate, rank-0 array with 0 items i.e. an empty rank-1 array

NOTE: scalars are isomorphic but not equivalent to singleton lists! they have different semantics! they're notationally ambiguous, so use monadic `$` to disambiguate.

with this terminology and model understood, let's explore how we _program_—relate subsets, i.e. select subarrays then pass them as arguments to functions—in j:

TODO: confirm my understanding while revising this whole section by reading <https://code.jsoftware.com/wiki/Vocabulary/FramingFill>

.the truth
----------
consider x with shape 2 3 4 5, v with rank 1 3, and y with shape 2 3 4 5 6.
then v breaks x & y into [2 3 4 | 5] & [2 3 | 4 5 6] respectively, taking the innermost 1-cell and 3-cell.
then [2 3 | 4 | 5]     [2 3 | 4 5 6]
     ----       -      ----   -----
      cf       cell     cf     cell

common prefix is useful only:
. of argument shapes: that a verb is *valid* over them
. of frames: the common frame after cells have been identified from verb rank

in this example, "1 3 pairs each of the 5 1-cells with each (4 5 6)-cell as per usual verb/noun agreement; the frame/cell breakdown is (2 3 4 | 5) & (2 3 | 4 5 6); their cf (prefix) is 2 3. this leaves cells 4 5 and 4 5 6, to which the verb is applied, and then the cf frames it.
----------

TODO: think about & discuss verbs as always being of two steps: 1. determine & 2. populate result arrays; all verbs can be represented by `$` and some other function, yeah?

. every verb has a rank for its monadic argument and each of its dyadic args. these ranks determine how the argument arrays are each partitioned into frames & cells before the verb is applied to those cells.
  .. for the monadic case, this is obvious
  .. for the dyadic case:
    ... the frame is the common shape prefix (called the _common frame_) of x & y e.g. if $x is 2 4 9 and $y is 2 4 5 8 then their common frame is 2 4; by this partition there remain what i'll here call _x-cells_ & _y-cells_—in this example's case, x has a 1-cell of length 9 and y has a 2-cell of length 5 8.
    ... the x & y-cells are passed to the verb, and must _agree_ with the verb e.g. if the verb has dyadic rank 0 1 then the rank of the y-cells must be exactly 1 greater than that of the x-cells
      .... agreement is considered after replicating or filling
    ... whichever cell has a smaller rank is either:
      .... replicated, if there's exactly one item in its list
      .... filled otherwise
      .... the fill-vs-replicate dynamic is demonstrated by +++'abc',:'*b'+++ vs +++'abc',:'*'+++

verb's ranks can be amended (not overridden) by using the _rank conjunction, "_. v"r splits [partitions] an array into r-cells and a frame, then applies v to the r-cells, then combines that result with the frame.

common prefix (aka frame) is required b/c that implies same number of items in both lists (n-cells & m-cells of x & y), which gives pointwise (1-to-1) relation between the set of m-cells & n-cells. example: in `4 2 5 6 v 4 2 8 9`, j matches 8 (5 6)-cells with 8 (8 9)-cells. technically j could more generally permit equal cardinality common frames, but that'd possibly put too much burden on the programmer to do the frame dissection & assembly.

that cells must match dyadic rank makes reasoning easy; it's explicit! for example, v"1 2 explicitly tells that both args will have some common prefix followed by a 1-cell for x and a 2-cell for y.

the rank used by a verb, given an arg or two, is min(verbrank,argrank,0). naturally this partitions into frame and cells. TODO: update this phrasing so that it doesn't bear mentioning, and more precisely & appropriately discuss negative ranks.

NOTE: allow replication to be automatic! don't specify rank 0 if equivalent output would be inferred from replication. the interpreter only _usually_ optimizes that poor loop structure. see <https://code.jsoftware.com/wiki/Vocabulary/quote> point (5) about using floating point (e.g. `1.`) to force non-suppression of the rank conjunction.

.when acting on each row might seem like acting on columns, which is an illusion
----
   i. 3 3
0 1 2
3 4 5
6 7 8

   }: i. 3 3 NB. seems to remove the last column but actually only effectively does so by literally removing the last element for each of the rows.
0 1 2
3 4 5

   ]a=.2 3 $ 10 20 30 40 50 60
10 20 30
40 50 60
   1 2 3 +"1 a NB. what appears to be summing over columns is actually summing 1-cells. also, "1 is short for "1 1.
11 22 33
41 52 63
----

.some simple rank examples
----
NB. ] prints `a` after assignment
   ]a =. ? (2 3 4 $ 100) NB. parens for beginner's readability, not disambiguation
40 81  5 54
96 53 14 47
78 93 89 42

19 98 98 51
20 85 90 58
53 88 68 29

   +/"1 a  NB. (40+81+5+54) ...; folds over 6 lists (specifically 2 3-lists each of length 4) of 0-cells
180 210 302
266 253 238

   +/"_1 a NB. (40 81 5 54 + 96 53 14 47 + 78 93 89 42) ...; folds over 2 lists of 1-cells
214 227 108 143
 92 271 256 138

   +//. 4 4 $ i.3 NB. +//. is ((+)/)/. b/c adverb-verb binding is high precedence and left-associative.
0 2 6 0 3 4 0

   ]a =. 2 2 4 $ 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0`
0 0 1 1
0 0 0 1
 
0 1 0 0
0 0 1 0

   #.a NB. because #. accepts a list (rank 1 array), the frame is 2 2; thus the result is 2 2
3 1
2 4

i.4 5
 0  1  2  3  4
 5  6  7  8  9
10 11 12 13 14
15 16 17 18 19

   1 0 _1 0 |."0 1 i.4 5 NB. each atom of x corresponds to a row in y and tells how much to rotate that row. consequently $y must be 4 n.
 1  2  3  4  0
 5  6  7  8  9
14 10 11 12 13
15 16 17 18 19
----

.dyadic rank examples
----
   10 100 30 +"0 1 i. 3 4 NB. 3 & 3 4. common frame is 3 (rank 1); 0-cells & 1-cells respectively (as taken from shape arg to ") are of shape 3 & 4. 3 gets replicated into 3 4.
 10  11  12  13
104 105 106 107
 38  39  40  41

   10 100 30 +"1 1 i. 3 4 NB. 3 & 3 4. common frame is 3 (rank 1); remaining cells are rank 0, length 3, and rank 1, shape 4. 
length error: frame mismatch: 3 vs 3 4

   10 100 30 +"1 1 i. 4 3 NB. 3 & 4 3. common frame is 0,...; _1-cells are 3 and 3. result is 4 3.
10 101 32
13 104 35
16 107 38
19 110 41

   10 100 30 +"0 1 i. 4 3
length error: frame mismatch: 3 vs 4 3

   10 100 30 +"0 1 i. 3 3
 10  11  12
103 104 105
 36  37  38
----

=== deeply nested relations by repeated application of "

i'll break down the example given at <https://code.jsoftware.com/wiki/Vocabulary/quote#More_Examples>:

   gs=.;:'RA Ra rA ra'
   ((<@:(/:'RrAa'&i.)@:,&:>)"0"0 1)~gs
┌────┬────┬────┬────┐
│RRAA│RRAa│RrAA│RrAa│
├────┼────┼────┼────┤
│RRAa│RRaa│RrAa│Rraa│
├────┼────┼────┼────┤
│RrAA│RrAa│rrAA│rrAa│
├────┼────┼────┼────┤
│RrAa│Rraa│rrAa│rraa│
└────┴────┴────┴────┘

always start with the outermost rank. v"0 1 matches atoms to rows: [(atom,row)]. then for each in that list, v"0 matches atoms with atoms, which, as demonstrated by `10 ,"0 (1 2 3 4)`, shows that it matches each atom with each item of each row: [(atom,[atom])] which is expressed flatly via distribution as [[(atom,atom)]]—rank 2. the distribution can be seen:

   genotypes (,<)"0 1 genotypes
┌──┬─────────────┐
│RA│┌──┬──┬──┬──┐│
│  ││RA│Ra│rA│ra││
│  │└──┴──┴──┴──┘│
├──┼─────────────┤
│Ra│┌──┬──┬──┬──┐│
│  ││RA│Ra│rA│ra││
│  │└──┴──┴──┴──┘│
├──┼─────────────┤
│rA│┌──┬──┬──┬──┐│
│  ││RA│Ra│rA│ra││
│  │└──┴──┴──┴──┘│
├──┼─────────────┤
│ra│┌──┬──┬──┬──┐│
│  ││RA│Ra│rA│ra││
│  │└──┴──┴──┴──┘│
└──┴─────────────┘

obviously thereafter you can see how RA is combined with RA Ra rA ra, then Ra is combined with.... note that the 1-to-many relation makes replication occur.
think of v"r as adding a traversal to v, e.g. `fmap@T v` for some T, except that T is here cells. repeated use of " is akin to nested fmap's or other traversals in haskell. the outer traversals are applied, leaving the inner traversals to associate subsets, and then for each subset we repeat.

=== fills & replication

* added during _assembly_, *after* a verb is applied to cells!

'' or 0 is used as a dummy filler element in arrays that're "extended" to have shapes as large as the largest shape in that cell, to avoid producing ragged arrays.

----
   4 4 $ i.3
0 1 2 0
1 2 0 1
2 0 1 2
0 1 2 0
----

=== resultant shape

process: split into frame f and cells -> replication -> pointwise association -> werb app -> extension -> padding -> result is framed by f.

a: is the framing fill for boxed things. btw do not confuse _framing fill_ with the verb called fill, `!.f`.

see https://code.jsoftware.com/wiki/Vocabulary/Agreement and https://code.jsoftware.com/wiki/Vocabulary/FramingFill for deets.

1. consider x : 3 4 5 and y : 3 4 9 6. the cf is 3 4. this frames the output! it is just a shape! there's no data there! all the *data* are in the 5 and the 9 6! 3 4 just tells how many (and the shape) of the data (and the output!) there are 3×4 length-5 things pointwise associated with 3×4 9 6 matrices! so we associate each 5 with each 9 6, which works b/c there are the same number. ok, so what's the shape of the output? easy: it's 3 4 S where S is whatever the verb's output shape is! discussing frame as a shape really is perfectly apt! it FRAMES the data, and the data is in the cells!

2. consider x:5 and y:9 6. then x v y will replicate *then* pad! they are not alternatives! here 5 becomes 9 5 via replication, then 9 6 via padding. replication ensures the correct number of *items*!

NOTE: _extension_ is like 5 -> 1 5; a vacuous appending of singleton axes to increase rank.

*padding* occurs exactly when some of the results of a verb being applied to cells have smaller lengths than other results.

some part of extension entails the resultant shape being, for each axis, the max of each length e.g. 1 0 & 0 1 -> 1 1. all extended axes are filled.

=== empty lists

TODO: throughly discuss 0 vs empty list and singleton lists vs scalars both in theory and practice. similarly, `1 5 $ 1 10` is not equal to `5 $ 1 10` because `1 5` is not equal to `5`.
* `$1` is an empty list yet `#1` is 1.

* scalars' shapes are empty lists e.g. `$'a'` is the empty list. `$$'a'` is 0
* the shape of an empty list is 0: `$''` is 0.
* there are many shapes of empty list! the empty list is not a singleton category!
* the _de facto_ empty list, when any empty list (of any type) suffices, is an empty list of characters, `''`.

== specific functionalities

=== filesystem

use link:https://code.jsoftware.com/wiki/Standard_Library/dir[`dir`] e.g:

[source,j]
----
   ,.5{.2 dir'codenotes/*.adoc'
┌────────────────────────┬──────────────────┬──────┬───┬──────┬──────────┐
│7z.adoc                 │2023 4 23 12 36 36│195   │rw-│------│-rw-rw-rw-│
├────────────────────────┼──────────────────┼──────┼───┼──────┼──────────┤
│README.adoc             │2023 4 23 12 36 36│10981 │rw-│------│-rw-rw-rw-│
├────────────────────────┼──────────────────┼──────┼───┼──────┼──────────┤
│ai.adoc                 │2023 4 23 12 36 41│1158  │rw-│------│-rw-rw-rw-│
├────────────────────────┼──────────────────┼──────┼───┼──────┼──────────┤
│best-paradigms-lang.adoc│2023 8 9 17 7 55  │72562 │rw-│------│-rw-rw-rw-│
├────────────────────────┼──────────────────┼──────┼───┼──────┼──────────┤
│best-paradigms.adoc     │2023 4 23 12 36 36│240491│rw-│------│-rw-rw-rw-│
└────────────────────────┴──────────────────┴──────┴───┴──────┴──────────┘

   ,.2{.1 dir'codenotes/*.adoc'
┌─────────────────────┐
│codenotes/7z.adoc    │
├─────────────────────┤
│codenotes/README.adoc│
└─────────────────────┘
----

you can do `1 1 dir y` to include subdirectories, but it's not recursive; it lists the given directory's files & directories, and the directories' files & directories, i.e. `1 1 dir d` is like bash `find "$d" -maxdepth 1` except that, unlike `find`, `d` is not included in the result set. `dirtree` is recursive and produces the same result as `find(1)` *but excludes subdirectories* e.g. given the directory structure

----
 A
├──  a1.txt
├──  a2.txt
├──  a3.txt
├──  B
│   ├──  b1.txt
│   └──  C
│       └──  c1.txt
└──  D
    ├──  d1.txt
    └──  d2.txt
----

`find A` produces 11 results:

----
A
A/a1.txt
A/D
A/D/d2.txt
A/D/d1.txt
A/B
A/B/b1.txt
A/B/C
A/B/C/c1.txt
A/a2.txt
A/a3.txt
----

and `dirtree'A'` produces 7 results, lacking the input directory, `A`; and the subdirectories `A/B`, `A/B/C`, and `A/D`:

----
┌────────────┬──────────────────┬─┐
│A/a1.txt    │2023 8 19 13 21 32│0│
├────────────┼──────────────────┼─┤
│A/a2.txt    │2023 8 19 13 21 33│0│
├────────────┼──────────────────┼─┤
│A/a3.txt    │2023 8 19 13 21 35│0│
├────────────┼──────────────────┼─┤
│A/D/d2.txt  │2023 8 19 13 21 18│0│
├────────────┼──────────────────┼─┤
│A/D/d1.txt  │2023 8 19 13 21 16│0│
├────────────┼──────────────────┼─┤
│A/B/b1.txt  │2023 8 19 13 21 28│0│
├────────────┼──────────────────┼─┤
│A/B/C/c1.txt│2023 8 19 13 21 51│0│
└────────────┴──────────────────┴─┘
----

NOTE: despite the docs, at least on linux, filenames' cases are preserved, not converted to lowercase.

== "relational j", and j vs sql (nonsense follows)

example challenge: express `select x*y from x join y on x+y=7` in j:

it was easy to build-up incrementally by usual repl-driven development: parenthecizing these trains then executing one at a time to see the result, then using the result as a hint about what to do next:

. `+"0 _` each `x` plus all ``y``'sr
. `7=+"0 _` convert to mask. same shape as `y`.
. `((7=+"0 _)#])` parenthesize that then use it to select from `y`.
. `((7=+"0 _)<@#])` those results had padding: either rows of zeroes, or some zeroes in given columns. box to avoid padding.
. `([*&.>(7=+"0 _)<@#])` multiply `x` by the subsets of `y`, which naturally must be done under unbox. result is good except for aces (empty boxes).
. `;@([*&.>(7=+"0 _)<@#])` raze away the aces.

in factor it's `[ [ swap [ + 7 = ] curry filter ] keepd v*n ] curry map`. `curry` corresponds to each left/right.

=== summary of j vs sql

[options="header"]
|========================================================================================================================
| sql                                                    | j
| declarative, readable, easy, verbose                   | terse, obscure, procedural
| flat sets & join                                       | 1+-dimensional arrays & rank
| join filters cartesian product by predicate on values  | predicates produce masks which are selection vectors
| no support for sequence ops that change size           | sequence verbs that change size is fine, but may introduce fill
| no lambdas. composed expressions only.                 | lambdas exist but are rare. usually just compose computations.
| each column has its own type                           | each column in stored as a homogenous list
| atomic strings                                         | strings are arrays of characters
| one-to-many join flattens into a table e.g. `x join y` | rank preserves one-to-many relation e.g. `,"0 _`
|========================================================================================================================

* `A join B` can be expressed as `map (select from B [where] [group by] [order by]) A` where the selection is really of B's attributes (since all attrs are stored separately as vectors) so scoping is not an issue i.e. there's no need to union attribute sets. the result is a 3+ rank array which can be flattened or rearranged as desired. in fact, we can make this more efficient by filtering each of `A` & `B` before mapping selection.
  ** consider `A join B using (key)`, and assume that all of A's and B's attrs are stored in individual vectors, and that you want to union each row of `A` with a corresponding attribute from `B`. we have a "table" `A` which simply means that there are some vectors of the same lengths, where the nth row is given by vectors at the nth index. the vectors belong to a namespace; they are unordered and present exactly when referenced in an expression. *the point of join is that it turns non-1:1 maps into 1:1 maps.* following our individual vector attribute encoding, we desire a new vector whose values relate to `A`'s values by index equality. the solution is to represent `B(key,value)` as vectors `key_B_` and `value_B_`, then `value_B_ {~ key_B_ i. key_A_`.
    *** TODO: how does this generalize? `value_B_ {~ key_B_ i. key_A_` creates a new attribute vector whose values are effectively functions of `key_A_`: namely looking-up keys in a map key->value. this resultant attribute vector has the same length as `key_A_`. generally (in sql) `A join B` results in a table of count `A*&#B`, which is returned as a transient table. the only information that `join` adds to any other query is the map between rows of `A` with those of `B`. all queries are always only of the input attribute vectors; thus our concern of how to translate sql to j is, separately & orthogonally: 1. queries, and 2. a relation of `A`'s indices with those of `B`, which is generally represented as a table with a column for each table being joined. yes, the concept of tables still holds despite us using only individual attribute vectors! attribute vectors "being of a common table" is the fact of their data being related by common index. naturally it follows that the join among tables is itself a table: a matrix of indices where the column tells which attribute vector to index into.
      **** NB. can i use ~: instead to be more elegant?
    *** insofar as i'm using an array model instead of prolog, i'd like to represent joins as i would any other relation, elegantly, lazily, in terms of relations (of indices, to defer lookup and avoid any potential efficient data packing complications). i want the query and expressions of relations to be as implicit as they are in prolog, done as an (e)DSL in j.

overall j bests sql for working with data in-memory without ACID. j does not have indexes, which might appreciably affect efficiency when the table is modified in a way that changes its sort order. i imagine that j marks sorted arrays specially so that e.g. it uses binary search when appropriate, but this is of no help if e.g. a new element is added to the relation, because then the whole relation must be re-graded. unless you need extreme efficiency as achieved by indexes. however, TODO: perhaps jd handles such cases well. TODO: compare efficiency of sqlite vs j wrt selecting by index. also, j cannot open large databases because j reads in files entirely. also, j has no facility to modify a small part of a file; instead, it overwrites the entire file—much less efficient than sqlite!

=== array-relation equivalence

TODO: how do i relate relations and arrays? relations aren't as amenable to arithmetic. how do we express computations in j vs in sql and why & how do they differ?

each axis corresponds to a sql attribute, and each corresponds to an axis of an n-dimensional space where n is the number of axes or attributes. attribute order is irrelevant in sql. axis order is considerable in j with k-cells corresponding to subspaces; however, axes can be freely permuted by `|:`, so the question is: how and in which contexts is axis order relevant? the answer is simple: rank. recall that rank is a property of verbs. therefore the axis order, though stored within the array, is merely an _accidental property of the array_, but is a _significant property of the verbs_ that act on the array! j supports tacit expressions, and indeed tacit is a preferred style. sql does not support tacit expressions; all expressions must explicitly reference attributes. sql hardly uses functions (with ordered parameters), instead using general expressions. in sql, the output expression does not use (ordered) sequences of (input) data; thus ordering the attributes would be insensible.

==== generally dealing with data relationally in j

===== how is j relational?

arrays obviously relate by indices with each index being a symmetry e.g. `∀j∃iarr[i][j]` is `<(<i;<a:){arr` in j. in j arrays are rectangular but may be sparse. the relational model does not recognize sequences necessarily, though, as prolog does, it may do so elegantly as a very useful builtin. generally, however, indices are no different from values so we may say e.g. `R(1,"bat").R(100,"cat").` to mean the sparse array R[1]="bat" & R[100]="cat". this is akin to a hashmap that supports efficient lookup by keys or values ambivalently. naturally, relations are the most general structure. effectively implementing a hashmap by them is obvious. arrays are implemented by them by sorting by their attributes, since an array is nothing more than an ordered set; even if the indices are multidimensional, they're still totally ordered.

so there are set operations, which are most general; then there are operations that support only indexed sets i.e. arrays.

obviously all unary atomic operations apply to all data structures. all binary ones can be done by joining [relalg] arrays. generally all n-ary operations can be done by accumulating arguments (currying) e.g. `x+y[x=.1 2 3[y=.10 20 30` can be `x&+y` i.e. `(1&+ 2&+ 3&+)y`. furthermore, j relates elements of `x` with those of `y` by the join predicate `xidx=yidx`—`x(I,X),y(I,Y),R=X+Y` in prolog, or `select X+Y from x join y using (I)` in sql. there's clearly less desire to curry in prolog or sql which support arbitrary-arity relations. generally all n-ary functions are applied to arguments, and those arguments are derived from a join i.e. an intersection of predicates. the arguments are maps from argument identifiers to values; when the keys of the maps are monotonically increasing incremental integers, we call it a sequence. sequences are nothing special in this context, though: they're maps from keys to values just like anything else. the fact that their keys [indices] permit ordering properties is irrelevant to all interests outside operations that change length (namely adding [at any indices] or removing [from any indices]) elements from the sequence. even their index order is irrelevant because we can sort anything to derive such an order. j is just sql with terser syntax, semi-first-class functions, some implicit joining rules, auto-index updating for length-mutating operations, and some sequence-related primitives. consider the following table:

[options="header"]
|===================================================================
| j                              | sql
| `"`,`,/u"_1 _"_ _1`            | `select u(a,b) from x join y`
| `#`                            | `count(*)`
| `(#~p)`                        | `where p`
| `,`                            | `||`, `union all`, `group_concat`
| `/`                            | aggregate fn
| `/.`                           | `group by`
| `/:`,`\:`                      | `order by <asc|desc>`
| `;.±[12]`                      | no nice way to do this
| `;.3`                          | join & recursion
| `;`                            | n/a; sql doesn't have boxes.
| `\`                            | window fn
| `i.`                           | `where attr=e`
| `;.0`                          | `between`
| `{.`,`{:`,`}.`,`}:`,`x u;.0 y` | `limit`, `offset`, `count(*)`
| `{`                            | `select`
| `|.`,`;.0`                     | `order by ... desc`
| `}`                            | `update`
| `~.`                           | `distinct`
|===================================================================

`,.`,`,:` demonstrated:

[source,j]
----
   ('cat';'up'),('hat';'right'),:'bat';'left'
┌─────┬────┐
│cat  │up  │
├─────┼────┤
│hat  │bat │
├─────┼────┤
│right│left│
└─────┴────┘
----

is expressed in sql: 

[source,sql]
----
create table y(i1,i2,y);
insert into y values(0,0,'cat'),(0,1,'up'),(1,0,'hat'),(1,1,'bat'),(2,0,'right'),(2,1,'left');
┌────┬────┬───────┐
│ i1 │ i2 │   y   │
├────┼────┼───────┤
│ 0  │ 0  │ cat   │
│ 0  │ 1  │ up    │
│ 1  │ 0  │ hat   │
│ 1  │ 1  │ bat   │
│ 2  │ 0  │ right │
│ 2  │ 1  │ left  │
└────┴────┴───────┘
----

ohes noes! it's not pretty-printed like j does! but it's exactly as accurate a model, and it's a more general model, too. anyway, if you want it to be _output_ differently—and i do mean output, which should have little to do with the underlying model!—then these should suffice:

[source,sql]
----
select group_concat(y,'|') as output from y group by i1 order by i1,i2;
┌────────────┐
│   output   │
├────────────┤
│ cat|up     │
│ hat|bat    │
│ right|left │
└────────────┘
----

you _can_ do the following:

[source,sql]
----
select * from y as a join y as b on a.i1=b.i1 and a.i2<b.i2 order by a.i1,a.i2;
┌────┬────┬───────┬────┬────┬──────┐
│ i1 │ i2 │   y   │ i1 │ i2 │  y   │
├────┼────┼───────┼────┼────┼──────┤
│ 0  │ 0  │ cat   │ 0  │ 1  │ up   │
│ 1  │ 0  │ hat   │ 1  │ 1  │ bat  │
│ 2  │ 0  │ right │ 2  │ 1  │ left │
└────┴────┴───────┴────┴────┴──────┘
select a.y,b.y from y as a join y as b on a.i1=b.i1 and a.i2<b.i2 order by a.i1,a.i2;
┌───────┬──────┐
│   y   │  y   │
├───────┼──────┤
│ cat   │ up   │
│ hat   │ bat  │
│ right │ left │
└───────┴──────┘
-- demonstrating that it works correctly by "reversing the list"
select a.y,b.y from y as a join y as b on a.i1=b.i1 and a.i2<b.i2 order by a.i1,a.i2 desc;
┌───────┬──────┐
│   y   │  y   │
├───────┼──────┤
│ cat   │ up   │
│ hat   │ bat  │
│ right │ left │
└───────┴──────┘
----

but it's a hack; it does not generalize well: we'd need to join `y` with itself for each additional column in the original j array. this is consistent with the relational model using one index for each dimension, which is consistent with j, too: each j array is a disjoint pair of data—shape & atoms—and the atoms correspond to one attribute of a sql table, and each atom of the shape corresponds to an attribute of the sql table, too. clearly the dimensionality of j arrays is their rank plus one to hold the associated atoms at their indices, which is consistent with prolog predicates corresponding to n-ary functions relating n arguments to 1 output (or m outputs, which would make the relation m+n-ary).

in prolog this is `y(0,0,"cat").y(0,1,"up"). [...] ?- y(A,B,C),y(A,B2,D),B2>B.`.

sql would need to support sequences especially in order for us to use sequences with it. we cannot emulate this functionality in sql. the simple demonstration is: given a table without indices, associate a unique natural integer with each row, s.t. these integers cannot be derived of the table. immediately that requires the table to have an order, which is does not, because it is only a set. orders can be derived of it by `order by`, however. then again, if we can `order by` a clause, then associating natural number indices would be redundant. therefore the only sensible table-as-a-sequence is one that begins as a sequence and preserves its sequence throughout mutations. this being said, when do we even insert into lists in the course of programming? i know that we accumulate them often and traverse them...but when do we insert into a list? i know when we insert into _sets_—db updates—but when into a _list_? when is it necessary or helpful for us to insert our own order of anything instead of using its natural order? why do we do them in common programming paradigms, and how do they generalize? it's drop or append, often under rotate, or removing matching rows (updating them to null). put another way: when must we, and how can we, introduce orders when they aren't already given? furthermore, which orders do we deal with? temporal? all other orders are given by data themselves and honestly when does even _that_ matter? for algorithms? perhaps that's it: some algorithms are expressed nicely in terms of indices/(sub)sequence, whereas some other algorithms work well with recursion on partitioned sets. and if so, why do algorithms benefit from order? how can they be written w/o.r.t order? i'm starting to wonder if order is an arbitrary encoding scheme that became popular for exploitation in algorithms, even though other relational schemes would have done just as well, and we may have nearly come to live in a world where sequences were not popular, but instead some other relations were.

sadly, sql does not support defining functions on tables. if it did, then we could define `append(t1,t2)` as a union or join of `t1` & `t2` after updating one of `t2`'s attributes `a` to `a+t1n` where `t1n` is `count(*)` evaluated of `t1`. it's understandable that sql does not have functions b/c typically tables' attribute sets mostly differ. also, such a method is not possible in prolog because prolog rules do not generally correspond to literal data; therefore counting the number of rules is silly, and trying to compute the number of data entailed by a set of rules is silly because they're typically infinite.

''''

ultimately all computing is relations which group distinct/disjoint data as needed. all multidimensional arrays can be seen as a single linear array with non-trivial indexing e.g. a table can be referenced two-dimensionally by an index `i` and the number of columns in the table `nc`: `i mod nc`. all joins are relations of sets of indices which is ultimately expressed as a set of tuples of indices. thus the only special property of sequences/arrays in addition to sets is that indices auto-update when the set's size changes.

array models like j suggest the programmer to keep data in order during assembly, traversal, and disassembly; relational models like sql & prolog suggest the programmer to know by which relations data are related. the array model imposes inappropriate overhead which also limits how the programmer reasons [models data]. however, it is convenient for cases of data being related by indices. namely sequence operations (namely `,` `;.±[12]`, `/`, `\`) and `"` are useful for such relations by index. one may wonder whether one can relate by indices just as well as relate by predicates or sets. TODO: explore index-based (sequence) models vs set-theoretic/relational models (which may be indexed).

''''

though link:https://code.jsoftware.com/wiki/Essays/Sorting_versus_Grading[sorting is faster than grading], it's still best to store each column in its own vector, (assigned to a name) then grade one and sort the rest (as needed) by that grade, given the benefits of having each column be a vector rather than keeping them in a table together:

. each vector's type is irrelevant to others'
. indexing into a vector is easy: just use its name/locative rather than `n&{"1 tbl`
  .. example: sql `select x+4*y,z from t where y<z order by x` is j `((Y&{<Z&{)"1 t)#(Z&{,~4&*@(Y&{)+X&{)"1 t['X Y Z'=.0 1 2` but with the result ordered, which i won't even bother to do; read-on to see why. the query becomes horrible because `order by x` and `y<z` use `x` & `y` which are not present in the sequence of selected expressions. thus: 1. our code is littered with `n&{"1`, and we must use forks to reasonably avoid that; and 2. even worse, we can't express sort elegantly! we must sort a filtered list by a , which means that we must either: a) include `x` in the selection just to make sorting easier, then remove or ignore the `x` column later; or b) filter `F=.X&{"1 t` by the same mask that filtered the selection then grade the selection by `F`.
    ... with `X`, `Y`, & `Z` all being column vectors, the sql is, in j: `(m#X)/:~m#(X+4*Y),"0 Z[m=.Y<Z`. much better, and my code doesn't feel like a ship in a bottle that i may break by modifying the code—namely here, adding the sort. i don't need to track forks, ranks, or otherwise just any parts of the whole expression. it's just less stressful.
      .... this is straightforward and avoids concerns that have nothing to do with the actual desired behavior but are instead concerns of arbitrary structure, such as wondering whether to compute the filter mask by `([:</_2&{.)"1 t` instead of `Y<Z`

===== translating sql into j

* use locales instead of relations/tables, and in those locales, simple names instead of attributes/columns
* i'm not considering constraints (including primary & foreign keys, uniqueness, etc) nor triggers (which implement reactive programming)
  ** however, if we assume that `unique` (incl. pk) constraints are obeyed, then we can use `i.` instead of `#` to identify the single row `where` a predicate is satisfied, especially when that predicate is equality. `(p i.1:)` checks a predicate `p`. `(n i.1)` is equivalent to `(=&n i.1:)`.
* sql is mostly a combination of the oop & array designs. this is directly reflected in how i translate sql to j.

TODO: how to handle views? if tables<->locales and columns<->names, what about dynamically generated tables? we'd need to use 2D arrays for those, right? well, no, we can probably use named locales for that! that would be a bit inconvenient though, if they're used just in a query such as `select 1+attr from view`; the inconvenience is that invoking `view` would create a new locale which we'd then need to `destroy`. the point of locales is that 1. it's convenient nominal indexing, and that 2. each column's type is unrelated to other columns' types. generally we only must relate arrays to names, and names to tables (if even having multiple tables is worthwhile, which it very well may not be, seeing as they aren't a necessary part of the model; the relational algebra's unit is the _attribute_, which is a vector in j. sql tables only make joining & selection (i.e. selection/indexing) more convenient; however, in j, we opt to keep all columns separate anyway! we refer to each column by name. `join using` may be inappropriate in j! check this. well,...maybe not; recall that join can be generally expressed as nested `select` clauses, and particularly when there's a 1:1 map among attributes, then the attributes can be encoded as vectors implicitly related by common indices. *1:1's among attrs can always see those attributes of a common table.* non-1:1 maps are expressed via rank in j, though this is a bit more limited than join. for example, `with x(x) as (values('bat')), y(y) as (values(1),(2),(3),(4)) select u(x,y) from x join y` is `'cat' u"_1>:i.4`. cartesian product is `,/u"_ _1"_1 _`. also, we can apply a predicate a la join by using `f@]^:["_1` to apply f to items of y based on mask x e.g. the fork `(3&< !@]^:["_1 ])` applies factorial to all y greater than 3.

[source,j]
----
NB. create table t(a integer primary key autoincrement, b text not null, c integer not null, d integer references t(a)
cocurrent't'
a=:b=:c=:d=:0$0

NB. create temp view f(col) as select min(t1.x)+sum(t2.y) from t1 join t2
f=:{{(<./x_t1_)++/y_t2_}}

NB. with x(n) as (values('tim'),('lars'),('frank'),('tommy'),('tyler'))
NB.   select x.n,y.n from x join x as y on substr(x.n,1,1)=substr(y.n,1,1) and x.n!=y.n;
NB. |--filter (join on)--|-reduce dimension-|-cart prod-|-[join] with self-|-----------------table data-----------------|
    (#~(-.@-:*.=&{.)&>/"1)       ,/           ,"_ _1"_1 _          ~       'tim';'lars';'frank';'tommy';'tyler';'filbert'
┌───────┬───────┐
│filbert│frank  │
├───────┼───────┤
│frank  │filbert│
├───────┼───────┤
│tim    │tommy  │
├───────┼───────┤
│tim    │tyler  │
├───────┼───────┤
│tommy  │tim    │
├───────┼───────┤
│tommy  │tyler  │
├───────┼───────┤
│tyler  │tim    │
├───────┼───────┤
│tyler  │tommy  │
└───────┴───────┘

NB. variant 1: select count(*) from ... group by substr(x.n,1,1)
NB. ({.@:{."1&><@:({{x,',',y}}&>/"1)/.]) ...
┌───────────┬─────────────┐
│tim,tommy  │frank,filbert│
│tim,tyler  │filbert,frank│
│tommy,tim  │             │
│tommy,tyler│             │
│tyler,tim  │             │
│tyler,tommy│             │
└───────────┴─────────────┘

NB. variant 2: ... order by x.n;
NB. (/:{."1) ...

NB. update t set a=e where p
a=:e(I.p)}a NB. using vector a, not using 2D arrays. this form works ONLY when e is a constant, not a fn of t!

NB. update t set a=fab from (select a as id, f(a,b) as fab from t) where a=id NB. t(a,b)
NB. i'm not even going to bother trying to do a solution that uses the gerund form of amend (}) where a & b are columns of a table t. it's too complicated.
NB. the following concern a & b stored as separate vectors, not stored within a common array.
a=:b (>&4@:[ (":@:[ <@, >@:])^:["_1 ]) a NB. this isn't even correct! the main part, (":@:[ <@, >@:]) (i.e. {{<(":x),>y}}), applies to the mask of b, not b itself! we can't simply say (":@:b <@, >@:]) b/c then that uses the whole b, not just i{b where i is the current iteration. furthermore, if we must consider more than merely a & b, then we must pack them into a common array then unpack them in the u of u^:v.
a=:b}a,:b f a NB. composite offers the most j-like solution. note that composite is akin to agenda (using index to decide choice/fn) with appropriate rank. this form is entirely flat.

NB. example of b}a,:fab[fab=.b f a
a=:;:'bob tom jer lyn betty lars jon bobo'
b=:1 2 4 6 7 8 9 11
a=:(-.2|b)}a,:(":&.>b),&.>a
┌───┬────┬────┬────┬─────┬─────┬───┬────┐
│bob│2tom│4jer│6lyn│betty│8lars│jon│bobo│
└───┴────┴────┴────┴─────┴─────┴───┴────┘
----

very common in functional languages is that some data y are selected at their positions P, but then those data must be related to other data (commonly f(y)) wrt P. thus P must be used twice: once to identify y, and once to replace y at P. haskell does not follow this model; it takes functions of y to apply at P. but haskell supports only that model! it does not support the j model of taking P twice! both models should be unified! all that must be done is returning indices rather than data! this requires structures to have index schemes. TODO: how does j fail this? don't its primitives take indices and return indices, excepting `{` which obviously exists expressly to return values at indices? an example: x m} y should allow x to be mapped pointwise with y. that it does not is very un-j. that m cannot be passed to } the same as x & y, because it's an adverb argument, is also bad. the fact that { & } allow indexing into arbitrary dimension is also bad for the same reason that nesting is bad: it's too damn difficult for humans to reason about, AND it's too complex, so we're led to stupidly constricted code OR code that gets around those restrictions by doing things like [un]packing or &.|: or {"1 ! sql tables are flat, which is nice, but even being 2D was not ideal: vectors are grouped arbitrarily (either that the grouping is arbitrary or that the fact of them being grouped is arbitrary). it should have been vectors only!

the following operaters are useful for reducing dimensionality:

* `,/` concat along leading dimension
* `,&>/` combine boxes that all have tables of some number of columns: effectively sql's `union all` where each box corresponds to a table.

=== structuring relations

`I.` is likely fastest. it requires a sorted list. it can accomplish BETWEEN <somehow>.

there are many reasons that you're behooved to use multiple vectors rather than them joined together into a table:

* `i.` works only on exact equality, so if you want to say "where attr=val" then
* you can sort on
  ** however, if you want to sort on column 1 then column 2, etc, then sorting a table is perfect

=== relations among relations

* in sql, join is the single device for relating data (records). for consistency's sake, the syntax should be `join where <pred>` instead of `join on <pred>`; this was likely not done just to make parsing easier. it's really just multiple select statements stuck together i.e. it's the only mechanism in sql to include multiple tables in the scope of a query. in j we can merely do `t1 ,"r t2` instead of `t1 join t2 on pred`. join unions columns (i.e. brings multiple tables into scope) and maps each row in one table to many in another table. unpredicated join maps each row of the left table to all of the rows of the right table i.e. `(u"1 _"_ 1)` or `,"1/` (or `u"2 3/` to pair all tables with cubes. nicer than `u"2 _"_ 3`) in j. this actually returns a cube; if you want to flatten it into a table then apply `(,"2&.|:)` to it.
* j has multidimensional arrays and transposing, which, depending on the situation, may be more or less elegant expressions as sql's
* j relates elements by array indices (arrays are inherently ordered) and axis order & rank. for example, the link:https://code.jsoftware.com/wiki/Vocabulary/IFamily[`i.` family], or dyadic `{`, or `,` identify then combine subsequences. being that all sequences represent (multi)sets, all set-theoretic (and hence all sql) operations are available in j.
* j also has cartesian product primitives unary `{` and binary `/`, though these always select the whole cartesian product rather than efficiently selecting a subset thereof. `{` is n-ary cartprod whereas `/` is binary only.

* sql uses `group by` parameterized by an aggregate function, including window functions. all non-window sql aggregates are commutative.
* j uses adverbs `u/.`, `u/..`, `u;.n`, unary `u/`, `u\`, `u\.`

unlike sql, it's apt at dealing with sequences.

==== join

TODO: join vs nested lookups ("queries") in j vs sql

is stuff like `select A.id,A.type,B.title,A.title from moz_bookmarks as A join moz_bookmarks as B on A.parent=B.id`, which uses the parent id to lookup the parent name in the same table in order to have the query return, for each element in the result set, the parent name instead of parent id, ever needed? is there some accident of sql's relational model that makes this query design appropriate in sql but not in j? the need for join here is, as we're seeing, that "join" is the same as dereferencing a pointer (more properly a _reference_ i.e. index) i.e. a transient query into another table (though here, the same table). `join` is therefore describeable as a nested query or sequence of queries e.g. here: `(2}~((moz_bookmarks&i.)@:(2&{)))"1] id type parent title {"1 moz_bookmarks`. here i used `moz_bookmarks&i.` instead of `y&i.` because: 1. it's closer to the original sql statement; 2. it generalizes to other relations easily; 3. it's simpler code to read than adjusting the tacit expression.

`(1}~(%:@:(1&{)))"1]2 6 4 {"1 i.10 10` is analagous to sql `select 2,%:6,4 from (i.10 10)` except that columns are specified by ordinal, rather than nominal, index. if i were to, instead of `%:`, use a form of lookup e.g. `othertable&i.` then in sql i'd use join. this shows that join is quite odd; it's just another function with a curried argument, but in sql it's treated as a separate, and even essential part of the language; however, it is _not_ essential! its essence is actually in the sql analogue of `i.`—namely the `select` statement!

actually, in sql nested `select` statements is considered an antipattern, and that `join` should be used instead. why? is this design more efficient necessarily (using what optimizations it affords), or is it more efficient just given how sql was arbitrarily designed? is there an analagous version of join in j (probably), and in j how do the efficiencies of the the nested design and the flat design compare? which is more ergonomic or flexible [refactoring]?

''''

NOTE: `{` allows us to get columns of any order just like in sql e.g. `(2 6 4&{)"1`; for tables j is practically sql; the ordering of axes is the same in j as in sql, though we can use `u`v`...`z&.|:` for aggregates.

[source,j]
----
NB. A(name,age,favorite_food)
   ]A=:('harold';40;'cranberries'),('frank';15;'strawberries'),('tom';12;'blackberries'),:('lizzie';25;'blueberries')
┌──────┬──┬────────────┐
│harold│40│cranberries │
├──────┼──┼────────────┤
│frank │15│strawberries│
├──────┼──┼────────────┤
│tom   │12│blackberries│
├──────┼──┼────────────┤
│lizzie│25│blueberries │
└──────┴──┴────────────┘

NB. B(berry,color,kCal_per_serving)
   ]B=:('blackberries';'black';50),('strawberries';'red';220),('blueberries';'indigo';190),:('blueberries';'blue';190)
┌────────────┬──────┬───┐
│blackberries│black │50 │
├────────────┼──────┼───┤
│strawberries│red   │220│
├────────────┼──────┼───┤
│blueberries │indigo│190│
├────────────┼──────┼───┤
│blueberries │blue  │190│
└────────────┴──────┴───┘

   ]fulljoin=:A ((-@:(+&(#@:{.))) ]\ ,@:(,"1/)) B
┌──────┬──┬────────────┬────────────┬──────┬───┐
│harold│40│cranberries │blackberries│black │50 │
├──────┼──┼────────────┼────────────┼──────┼───┤
│harold│40│cranberries │strawberries│red   │220│
├──────┼──┼────────────┼────────────┼──────┼───┤
│harold│40│cranberries │blueberries │indigo│190│
├──────┼──┼────────────┼────────────┼──────┼───┤
│harold│40│cranberries │blueberries │blue  │190│
├──────┼──┼────────────┼────────────┼──────┼───┤
│frank │15│strawberries│blackberries│black │50 │
├──────┼──┼────────────┼────────────┼──────┼───┤
│frank │15│strawberries│strawberries│red   │220│
├──────┼──┼────────────┼────────────┼──────┼───┤
│frank │15│strawberries│blueberries │indigo│190│
├──────┼──┼────────────┼────────────┼──────┼───┤
│frank │15│strawberries│blueberries │blue  │190│
├──────┼──┼────────────┼────────────┼──────┼───┤
│tom   │12│blackberries│blackberries│black │50 │
├──────┼──┼────────────┼────────────┼──────┼───┤
│tom   │12│blackberries│strawberries│red   │220│
├──────┼──┼────────────┼────────────┼──────┼───┤
│tom   │12│blackberries│blueberries │indigo│190│
├──────┼──┼────────────┼────────────┼──────┼───┤
│tom   │12│blackberries│blueberries │blue  │190│
├──────┼──┼────────────┼────────────┼──────┼───┤
│lizzie│25│blueberries │blackberries│black │50 │
├──────┼──┼────────────┼────────────┼──────┼───┤
│lizzie│25│blueberries │strawberries│red   │220│
├──────┼──┼────────────┼────────────┼──────┼───┤
│lizzie│25│blueberries │blueberries │indigo│190│
├──────┼──┼────────────┼────────────┼──────┼───┤
│lizzie│25│blueberries │blueberries │blue  │190│
└──────┴──┴────────────┴────────────┴──────┴───┘

NB. select name,age,favorite_food,color,kCal_per_serving from A join B on favorite_food=berry. computed as a filter of the full join
   0 1 2 4 5&{"1 (#~(-:/@:(2 3&{)"1))fulljoin NB. using / here is a little odd but terser. note that the column that was removed is (i.(-@:(+&(#@:{.))))-.}.2 3.
┌──────┬──┬────────────┬──────┬───┐
│frank │15│strawberries│red   │220│
├──────┼──┼────────────┼──────┼───┤
│tom   │12│blackberries│black │50 │
├──────┼──┼────────────┼──────┼───┤
│lizzie│25│blueberries │indigo│190│
├──────┼──┼────────────┼──────┼───┤
│lizzie│25│blueberries │blue  │190│
└──────┴──┴────────────┴──────┴───┘
----

this is the general, unpredicated join. it is the least efficient, as it computes the largest possible join. we can always use it and then filter it, but if you know that you're going to concern only a subset of A or B, then it's best to filter either then join them then filter the join. it's also best to entail only the columns of A & B that you'll select; `A,"1/B` builds a larger set than necessary. due to `/`'s O(n^2^) complexity, it's especially important to filter irrelevant data before applying it.

of course, this is already a boxed array, so, depending on our needs, we may choose to use boxes to keep the one-to-many relations as single rows instead of distributing the relation over into multiple rows:

[source,j]
----
NB. the indices of B for which each A matches
(2{"1 A) {{x,<x-:"0 y}}"0 1 ((0{"1 B)) NB. you can add _2&]\ which surprisingly gives the same result as _2&]\@:,
┌────────────┬───────┐
│cranberries │0 0 0 0│
├────────────┼───────┤
│strawberries│0 1 0 0│
├────────────┼───────┤
│blackberries│1 0 0 0│
├────────────┼───────┤
│blueberries │0 0 1 1│
└────────────┴───────┘
----

join is essentially a map from row ids of A to row ids to B, encodeable by a r×2 array: a set of ordered pairs (a,b). the joining of the tables is separate from the fields which one will select of the tables; it's a relation of rows of A with rows of B. this is useful when we want multiple queries over a common joined table, where the queries select different column sets; this join has efficient storage: an m×n array of unboxed integers where m is the number of joined tables and n is the count of the joined table. the number of columns is independent of the number of columns of each table; however, the number of rows is dependent on the count of the tables' columns, since that affects the size of the cartesian product. still, the join allows us to access only parts of any tables, rather than holding an entire joined table in memory.

[source,j]
----
   ({&A)`({&B)"1 (|:sel) NB. select from our r×2 selection array. TODO: generalize to multiple tables, thus removing the gerund and instead putting A, B, ... in an array.
----

* `A join B on pred` is subest of cartesian product
* `A join B on pred where pn=val` could be seen as a subset of the subset of cartesian product, but that's grossly inefficient compared to `lookupJoin (n{"1 A) i. val` where n is the column number of `pn` and `lookupJoin y` uses a selection table to get the yth items of A and the yth items of B, stitching them togetehr. we see that i. is a specifically efficient case of `#` (filter) that assumes that there's uniquely one `pn` whose value is `val`, 

helpful related ideas:
* `x,:y` makes a table where x & y are rows and y is above x.
* `x,.y` transposes x & y then adjoins these column vectors with x on the left. this is equivalent to natural join using row_id. generally, however, join is a one to all mapping, not one to one. ,. is a very specific case of join: it requires for both A & B: 1. order (which is always defineable for all types, but still), 2. uniqueness of elements permitting said order.
* implicit grouping by common array index supports only one-to-one maps, not one-to-many maps, because indices are non-duplicate in every array.
* `#` (filter) generalizes `i.` from getting only one meeting a predicate to all meeting a predicate

=== selection refinement (viz `where`)

generality:

. general predicate
  .. range (`between`)
    ... equality (`<val>=<constant (or index value?)>`)

TODO: can checking equality against an indexed value still fast? seems so.

=== self-relations

hook. TODO: is this section appropriate (viz wrt sql?)

=== `group by`

TODO. /. obviously.

=== `order by`

cameron's apparently correct notes except for the following "NOTE":

----
'p q'=:col&i.'ac'
(p+i.q-p){(/:/:col){T
NB. original; wrong.

'p q'=:(/:~col)&i.'ac'
(p+i.q-p){(/:col){T
NB. ((.../ (/:~col)&i.'ac'){(/:col){T
NB. verified correct.
NB. this is unintuitive operation. cf naive method of sorting T by col: (p+i.q-p){(T/:col)
NB. the advantage over the naive is small; it merely replaces a total selection (the one hidden in T/:col) with a partial one.

NB. (/:col){~(/:/:col){~col i.a,b
NB. is equivalent to
NB. (/~col){~(/:~col)i.a,b
----

TODO: this assumes that a & b are in the index; however, this is actually generally untrue; e.g. all elts should be returned if a is __ and b is _. the fix is simple: replace `t i. a` by "index of least element whose value is greater than or equal to a" i.e. (m&I.), not ((>:&a)i.1:) b/c we can do binary search rather than linear search. btw we see that `x&i.` is expressed by its more general form, `((=&y)i.1:)`.

`select * from t where v between a and b`:

[source,j]
----
t=.y
v=.v{"1 t
idx=./:@:/: v
p=.(t i. a){idx
q=.(t i. b){idx
((p+i.q-p){idx){t
----

terser version:

[source,j]
----
idx=./:@:/:v{"1 y
NB. ({&B)@:(A&i.) is effectively A join B. this is obvious when you consider that join is the only way to relate tables in sql; therefore any expression involving multiple arrays is isomorphic to a selection of the join of those tables.
a ([+[:i.-~)&(({&idx)@:(y&i.)) b
----

TODO: cf I. & m&i. ; they both use efficient lookups.

== verbs

note that each row of link:https://code.jsoftware.com/wiki/NuVoc[nuvoc]'s table is _operator_ then _operator with dot_ then _operator with colon_.

one can use gerunds for conditionality e.g. +++f`g`h@.(m&i.)+++ or if you want `cond` like in lisp, then you'll need to defer evaluation of both conditions and corresponding bodies; to do this in j, simply have all your conditions and bodies both be gerunds; then fold (`F:.`) through your conditions, returning (exiting early using `Z:`) the index of the first one that evaluates to `1`, then pass that to `@.`.

NOTE: to avoid the usual b.s. about packaging into tuples, then extracting, performing ops on each, then repackaging, to make the accumulator be a single (composite) datum, just keep each separate datum on each row then use gerunds & rank (`"`) to compute over all rows simultaneously. it's common to use `u/` to combine the result of 2 gerunds.

foldr1 example: ` >(#@:[+])&.>/(;: 'hello there friend how are you today'),<0`. ofc we'd actually do ` +/(#@>)` b/c we're using an array lang not haskell/scheme.

NOTE: fold accumulates a relation of relations. they fold through no more than an input sequence. cf `^:`, which can be used e.g. like `{~^:a:`.

.structural operators

ord:: _1: discards order; _0: keeps order but not indices; 0: keeps order; 1: introduces (new) order
out #:: _1: fewer; 0: same; 1: more. multiple out nums means that many are possible e.g. _1 0 means "subset". when 0 is used of binary args, then the output retains all information of the inputs. 1 is used only for ? & ?. which produce data from no provided inputs; and # which may make multisets of sets.
out:: vals | mask | markers. _markers_ is where each output elt represents information of the ordinally correspondent input elt. _mask_ is a boolean marker vector.

i consider which information is added, removed, or preserved, since that's all that determines each operation. each column represents one of the basic informations.

all joins do not add new information; they only relate information that we already had. generally all combinatory operations are representable as join on some relations? how to represent `append` in such terms then? anyway, the random value function is the only one that produces something from nothing; it's necessarily the only fn whose output is unrelated to its input.

[options="header"]
| symbol | ord | out # | out  | note
| ~.1    | 0   | _1 0  | vals | nub
| ~:1    | 0   | _1 0  | mask | nub sieve
| |.1    | 1   | 0     | vals | reverse items. cf ;.0 which reverses all axes.
| |.2    | _0  | 0     | vals | rotate
| |.!.f  | _0  | _1    | vals | shift
| |:12   | 1   | 0     | vals | permute axes. affects `u"n`; see _§j vs sql_. `(<0 1)&|:` extracts diagonal. generally boxed vectors (sets really) select where those axes' indices are equal; that's why `(<1 0)$|:` selects diagonals: it's the array [(i,j)|i=j]. boxed x selects subsets by index equality across axes.
| ,:1    | 0   | 0     | vals | adds information only of j's shape algebra

the good news about array axes as they're freely efficiently reorderable is that *they are not nested;* they are true relational structures. their axes' order is arbitrary, much as are sql column sets' orders irrelevant to relalg semantics.

=== essential verbs, relationo-algebraically organized

GOAL: complete classification of input>-primitives->output relations where each input is considered for its important information and the output restructures, discards, or introduces new information. as examples, bijections preserve information (b/c they're reversable), but injections & surjections lose information.

organization: there are operations that operate on collections ((sub)sets), and those that operate on types, which have corresponding sets, but which we ignore; e.g. we are not concerned with the whole set of complex numbers; more aptly, we're interested in the algebra of complex numbers, and as we know, algebras are free over their sets. however, for arrays (our ad-hoc relation structure), we are particularly concerned with the relations, which are always ordered. the set of complex numbers is not ordered, nor stored in memory; it's purely symmetric and infinite, unlike arrays. with this distinction in mind, i'll partition j's operators into separate categories: those of symmetric (algebraic) relation, and those of ad-hoc relation. TODO: note whether ad-hoc operations are closed over the set of arrays. also i avoid using the term _structure_ because _relation_ already implies structure. of ad-hoc relations, whether or not in a given context the relation's order is significant information will be noted i.e. if ab has the same information content as ba. i'll also use semigroup notation for operations e.g. ab instead of a<>b.

a great deal of good coding relies on exploiting iso- or homeo-morphism between arbitrary objects and numbers e.g. cyclical groups and integers modulo n. thus many operations may be written as computations under subsets of numeric domains. another useful coding technique is exploiting multiple interpretations of objects e.g. a vector considered by multiple partitions (generally a relation considered by multiple sub-relations, or more generally information considered by subsets thereof) or data by multiple interpretations e.g. logical vectors as partitions and as counts of number of elements satisfying a predicate. usually one thinks of such a number as an integer, because it's the canonical reduced form, but to consider things by such reduced forms trades expressivity for efficiency, which is only sometimes desirable! be aware of insidious inelegances such as computations over a 2×n array when a vector of complex or rationals would be more space-efficient and express your computation more elegantly! considering this example further, not only may the common computation be easier, but you may find an easier time implicitly generalizing reals to complexes or integers to rationals rather than generalizing a 1×n to a 2×n. *always attempt numeric operations before relational ones!* in this case `%` (reciprocal) is like `|."1` but with numeric reduction. if you don't want numeric reduction then complexes would be a 2D number that works, though they don't support swapping real & imaginary parts.

==== elegant primitive-structure combinations

primitives & structures (given by their information content) together have a degree of elegance or not. this section discusses which primitives to use in order to manipulate information of given structure where the structure is significant e.g. sequence in a sequence, as opposed to a sequence representing a set i.e. it's practically equivalent over permutation.

consider the longest consecutive 1's problem e.g. its solution to 0 1 0 1 1 1 1 0 1 0 1 1 0 1 is 4 b/c the longest substring all of whose elements are 1 has length 4. this problem pivots on elements' ordinal relation i.e. a relation of all pairs (a,b) where a is (i,u) & b is (j,v). to determine which primitive would be useful, we observe the situation's essential accidents: sequence order matters; therefore numeric operators are irrelevant but instead we must use a relational/array operator; we're exactly concerned with substrings; in regex terms, we'd match against all substrings of form `/[^0]+/` yielding a vector x; then our answer would be `>./#@>x`. anyway, we note that the absolute indices are irrelevant but instead that only relative indices are relevant; thus, as long as we ensure that the first or last elements are the delimiter 0, then the result is invariant under rotation.

my solution is `>./(0 E. y)+/;._1 y` which is appropriate because `E.` & `;.` identify then take substrings, and substring is exactly the relation that we desire.

''''

ad-hoc relation hierarchy:
seqs (relations with meaningful order)
  sets (relations without significant order)

symmetric relation hierarchy:
we consider algebraic structures specifically wrt j's types: complex, real, rational, integer, modulo, boolean (mod2). thus i will say that fields are a superset of groups.
fields
  groups
  ℂ
    ℝ
      ℤ
        ℤ/n # TODO: explore this vs ℤ/2
          ℤ/2

properties:
* associativity
  ** division & subtraction are non-associative. these are inverses of operations + & × which combine information together but in doing so lose information; with a+b=c, given c alone a & b cannot be known. with string concatenation this is still true. however, with `,&<` it is. we see a more general example with exponentiation, which is non-commutative, and thus has two inverses: log & root. with subtraction & division 
aRb=c is expressed as relation R(a,b,c), R∈{-/^}; any two values of the triple leaves enough information to determine the third.
a-b=c => a=c+b, b=a-c
a%b=c => a=b*c, b=a%c
a^b=c => a=c^(%b)=b%:c, b=a^.c
* distributivity (i.e. factorability)
* divisability
* identity (support of a default/nonce, for symmetry)
* closure (analagous to loops: the operation's result is a member of a set; repeated application is either cyclical or convergent. in j idempotence terminates a loop, which prevents divergence by loops [graph theory: a uninode cycle]. i'm visualizing a graph whose edges are an operation and whose nodes are inputs thereto. this interpretation unifies graphs, algebras as categories, and state machines.
* invertibility (undo/reversability)
* commutativity (not useful to us as programmers except that we may avoid unnecessary ordering operations)

combinators:
* perhaps it's appropriate to see stack-based langs as simple combinator langs; then when compared to j, they're just j but with functions that take or return too many paratemetrs instead of leveraging multitudes by arrays; and of course they lack the power of array operations, framing fill, &c. the generality of arity of fns is unnecessary, leads to poorly-written code, and does not support arity-determined functionality e.g. `~` being reflex or flip depending on whether `u~` is called monadically or dyadically. because unary & binary arities are common and special (namely atomic [smallest i.e. binary] relation, reflex, or mere fn application to a thing), it's practical to support them especially. the pattern of `x` being a control structure is very good, too, because that's so common e.g. in the case of exponentiation and its inverses.
* combinators natural use in tacit programming suggest that perhaps combinator-based programming & tacit programming are the same
* i like how the D~2~ combinator is expressible in bqn as a⊸b⟜c by expressing the relation of abc as multiple (two) relations ⊸ & ⟜. this is decoupling and, along with brevity, is what gives j primitives their power to express sentences or subsentences much better than black-box functions!
* as hoekstra's 2022 paper, _combinatory logic and combinators in array languages_, specifically §8, demonstrates, using combinators is elegant only if they're terse, namely that the representation of their composition is not graphically verbose, and that the underlying model may be manipulated easily. the fact is that _combinators_ must be _combined_ in order to be useful; if combining them is verbose, then they don't appear as composites, but instead inappropriately as relations of distinct parts, which is obviously technically correct but irrelevant to our consideration of the combinators' composite.

an abelian group has all these properties and one operation. rings & fields have 2 operations. rings generalize fields by removing <properties>.

common structures: polynomials (expressible as vectors), groups (expressable as integers)

numbers are simple and have much built-in structure with which mathematicians are commonly familiar. they have the field operations, or act as rings, &c. so that's e.g. (ℝ⊂ℂ,+-×÷), (ℤ/n,|). similarly we consider j array (i.e. non-arithmetic) operations like (array of given structure,operations) s.t. the pair exhibits some useful algebraic properties.

algebraic sequence hierarchy:
  multilinear maps (arrays), which is a recursive type whose base case is the linear map, which is, like all true base cases, a binary relation.

GRADE:
x/:y does nothing if x is monotonicity increasing, because /: computes an order of x, so for monotonically increasing x, the derived permutation sequence that /: uses is `i.#x`.
x/:y is ((/:y){x) which demonstrates that dyadic grade is actually a weird combination of its essential function (grading) and selecting from an array.

* /: & /. are similar in that they're about arbitrary maps between indices and data; in grade's case, the indices are used for order but in key's case they're used for grouping. we can generalize them by simply both allowing duplicates in the collating sequence and considering the order of the collating sequence! this would allow us to simultaneously group & order. however, there is no j primitive for that.
  ** bqn's "group" operator actually already does this: `2 1 2 0 ⊔ "abcd"` -> (d|b|ac) which corresponds to order 0 1 2.
* /: works the same as you'd use an arbitrary sort order in sql.

TODO: is a group though ℤ is only a ring. remember cyclic groups, too.
TODO: consider algebra of intervals. note that each interval corresponds to a substructure of an indexed structure, e.g. substring/subarray, and that intervals are a subclass of subsequence. consider relative to a set of indices to index from. interval is merely a variety of subset that obeys an exploitable property of its elements' symmetric ordinal relation.

*the essential concerns of computing*:
. subsetting [by predicate]. NB. predicates specify aspects of a program's a/symmetry
  .. maps/relations [of distinct data]
    ... choice i.e. conditional branching
  .. by equivalence classes. commonly used transitively e.g. sql graph traversals e.g. (a,b)>-lookup by (=b)->{(b,c),(b,d)}>-lookup by (=c) or (=d)->...
. commutative folds
. order [such as permits a lattice]
  .. non-commutative folds
  .. window functions

NOTE: fold generally considers elements' ordinal relation but folds parameterized by commutative functions do not. then there are primitives that generally do not consider order e.g. `/.`.

i'll consider the general mathematical structure called _relation_. the term refers to its general mathematical meaning and is canonically studied in relational algebra, which uses it as sql does: as the general form of the primitive binary ordered relation ∃ a,b. (a,b) which is isomorphic to the indexed set {0:a,1:b} which is isomorphic to the tagged union ∃ x,y. {x:a,y:b}. this sees isomorphism of multidimensional arrays and sets of tagged unions supporting indexes, which is technically always the case in coding because all digital data are isomorphic with bytestrings, and bytestrings have a canonical order. similarly indexed relations / arrays are isomorphic to bytestrings with associated logical vectors for partition & order.

`eval` is not a concern so much as a fact. it's assumed that the data may be _programs_ i.e. code which can be sensibly interpreted as io or relations. the program evaluation model is assumed to enable all desired manner of control flow; there exist many program models that can express the same set of programs as a model that allows arbitrary jumps [goto].

the further from the machine code model that a paradigm evaluator is, the more responsibility the evaluator has to elegantly transform (optimize by systematic reduction or rewriting) the specified program.

''''''''''''''''''''''''''''''''''''''''''''''''''

TODO: a study of whether code that avoids boxing is hairy:
flat (non-boxed) thing to consider: sub each subvector of N indicated by Av (translated from aplcart.info):
[source,j]
----
NB. flat version of +/;.2 NB. ;.n effectively boxes without boxing as do sql aggregate fns effectively work on subtables without actually making per se subtables
   0 0 1 0 1 1 {{2-~/\0,x#+/\y}} 10 20 40 100 200 500 NB. i can instead use the semantic where x always starts with a 1 and i use ;.1
70 300 500
----

thoughts:

* cut is a good primitive! it's the substructure primitive! that GENERALLY is a computational imperative! it boxes in apl (like (+/"0) <;.2) which makes it inefficient and makes flat code attractive for its efficiency! this is appropriately not so in j b/c u;.n is an adverb!
* still this questions generally how to deal with subvectors with(out) boxes. cf sql.

example 2:

original: `Av{⍵⌷⍨⊂z⍳⌈\z←⍋g[⍋(+\⍺)[g←⍋⍵]]}Y`—cumulative maximum (⌈⍀) in each subvector of Y indicated by Av (fast ∊⌈\¨Av⊂Yv). see codenotes/langnotes/j/so-cum-max-apl.html

[source,j]
----
NB. >./\;.1 again with 1={.x
{{x{~i.z>./\z=./:g{~/:(+/\x){~g=./:y}}
----

''''

verbs i've yet to classify:
* ? ?.
* ~:1
* $.
* ^: NB. apply op n times, n∈ℤ, with particular consideration for n∈ _1 0 1 .
* |. |:
* S: L: L. NB. S: is like &> and L: is like &.> . L. gives greatest level of nesting.
* #
* #. #: p.
* /: \:
* /. /.. NB. explicitly group primitives: the group ids are the control argument
* / NB. in dyadic form, applies dyadic u to cells of x and all of y. "The rank of the cells of x is given by the left rank of u; use u"n/ to set the cell-rank of x."
  ** table just modifies rank: `u/` is `u"(lu,_)`. i think that "table" is much a misnomer! honestly i think that / should be deprecated in favor of explicit rank specification, which is clearer code.
  ** TODO: cf `u . v` which is u@(v"(1+lv,_))
* .
* \ \. NB. `x u;.3 y` is more efficient and more powerful (viz higher dimensions and more powerful & symmetric control over overlapping or generally choosing subarrays of y) than `x u\y`. e.g. `(1,:2)<@,;._3 y` is the same as `_2<@,\y`. however, \ should be used whenever you can use one of its SC's e.g. for tabulating: `_2]\y`.
* }1
* I. _interval index_. NB. _fret_ is an interval boundary. NOTE: {.@:I.@:pred for first match is an antipattern; use SC (pred i.1:)
* i. i: NB. x is the search space. #x (the value returned if lookup didn't match) is useful for selecting a default when said default is appended to x: `x`; this is a relational thing w/default. (S&i.) computes indexes [sql] so if S will be searched many times, then define (S&i.) to generate the index only once per many searches.
* "
* e. NB. scheme's `member?`. E. is the same but tests for subarrays. E. is to -: as e. is to = . y is search space, x is (singular) search term. USE ON CHARACTER ARRAYS ONLY.
* u:
* p: q: m. (operation in modulo space)
* ;:2 parser/tokenizer. relative slow but extremely convenient. i'm curious how its speed compares to common packrat parsers.
* "bread & butter" primitives:
  ** subset:
    *** elements: {
    *** substructure (subarray, a generalization of substring):
      **** slice: ;.0 NB. delimiting by element `u;._2` is expressed by the more general delimit by arbitrary indices form, `(u;._2~ delim&=)`.
        ***** `(1 ,~ 2 ~:/\ ]) <;.2 ]` is an impressive use of fold to cut at locations determined by relation of adjacent elements viz when an element stops repeating.
        ***** [{}][.:] are convenient specific forms of ;.0: take or drop first or last [n]
      **** split by start/end markers as element or indices, including or excluding said markers in results: [x];.±[12]
      **** general substructure: ;.±3
  ** TODO: rest
* verbs that support cyclic gerunds: "12 [\/][.]12 ;.n12
* o.

append (combine):
, rank _ append. note that unary `,` generalizes `,/`
,: append rows (or add 1 to dimension then append). x,(,:y) is equivalent to x,:y
,. ,"_1
; boxed append
NOTE: ; and ,: both preserve original inputs to some extent

reshaping;
, linearize
,. tabularize

special syntaxes:

* <A>p<B>: <A>×exp(π,<B>)
* <A>r<B>: integer A divided by integer B with remainder e.g. 6r2 is 3 but 6r4 is 3r2
* 0b[01]+: bitwise literal
* `u` & `v` represent any part of speech, though `m` & `n` must be nouns

==== linguistic devices & metaprogramming

|===================================================================================================================================================================
| symbol  | name/description                                | notes
| < >     | un/box                                          |
| $       | shape (get or put)                              |
| =. =:   | assign                                          | returns assigned value e.g. `b=.6+a=.3` leaves a as 3 and b as 9. common idiom for multiple assignments (like scheme's `let*`) from rtl: `a f b[b=.v2[a=.v1`
| $:      | verb reflex (in definition)                     | enables recursive λ's and defining [either] monadic or dyadic parts of verb in terms of each/the other
| ~       | verb reflex (in invocation) or flip             |
| :       | define part of speech                           | rarely used since `{{ }}` was introduced
| ".      | eval                                            |
| m~      | value of identifier whose name equals m's value | enables dynamic reference; with `a=:+/ b=:'a'`, b refers to a whose value is the one at the time of evaluating `b~`; `b~ 10 _5 3` evaluates to 8. we can do `".b,'10 _5 3'` instead. `".` is more general and so more capable: with `a=:+ b=:'a/' ".b,'10 _5 3'` evals to 8, and `b~` fails with error "ill-formed name." if we redefine `a=:*` without redefining `b` then `".b,'10 _5 3` evals to _150.
| ;:      | parse j code or other codes                     |
| ` `: @. | delayed verb execution                          |
| f.      | express a verb in terms of primitives only      | usually j is evaluated dynamically; verbs are stored as strings, and the strings are evaluated when the verb is. `u f.` returns an equivalent version of `u` whose definition is defined entirely by j primitives. also enables any special combination recognition that would've otherwise not occurred b/c named verbs were composed.
| 4!:n    | view & modify bound variables                   |
| {{ }}   | lambda                                          | may be multi-line, with last line ending being exactly `}}`
|===================================================================================================================================================================

see <https://code.jsoftware.com/wiki/Vocabulary/GerundsAndAtomicRepresentation> for discussion of quoted programs.

NOTE: it's wise to use ALLCAPS local binds to avoid using any of the special variable names: x,y,m,n,u,v.

the best (most elegant) metaprogramming device available in j is boxed character arrays. these preserve distinction, support all string operations (e.g. `,`—namely flat array ops), and all array operations (namely the complex ones like rank).

metaprogramming example:

[source,j]
----
NB. using ".
   ops=:'*&5';'%';'*'
      ".(>(, '`'&,)&.>/ops) ,'`:0 ] 10 _20'
 50  _100
0.1 _0.05
  1    _1

NB. using gerunds
   ops=:(, ;`''&,)/ >:`'' , <:`'' , %`''
   ops`:6 ] 10 _20
┌──────┬─────┬─────────┐
│11 _19│9 _21│0.1 _0.05│
└──────┴─────┴─────────┘
----

.cond

there are many possible varieties in design and implementation of choice operators. here's one that works like lisp's `cond` macro, directly translating a sequence of expressions into an ast of agenda:

[source,j]
----
NB. pp & ins not for export
pp=:{{'(',y,')'}}&.>
ins=:{{<(>x),m,(>y)}}

cond=:{{".(":x),(;('`'ins)`('@.'ins)/|.pp'`'cut m,'`',n),":y}} NB. x psfs cond def y e.g. f=.'>:`*'cond'!' then (6 f~ 4),6 f 4 --> 15 24
----

.gerund/string mp stuff from cameron (TODO: consider)
------------------------------------------------------------------------------
gerundToStringVb=:  {{ _3}. y`:0 (1 :'5!:5@< ::]^:2]''y''')  }}       NB. verb
    ger=:  ({.(?+2-|.)`])       NB. single gerund
    gerundToStringVb  ger
(? + 2 - |.)
    gerChain=:(#$%*!)`%.`(? + 2 - |.)     NB. 3 gerunds
    gerundToStringVb gerChain
(# $ % * !)`%.`(? + 2 - |.)
    gerundToStringVb"0 gerChain
(# $ % * !)
%.          
(? + 2 - |.)
    '`'  cut  gerundToStringVb  gerChain
┌───────────┬──┬────────────┐
│    (# $ % * !)         │%. │    (? + 2 - |.)           │
└───────────┴──┴────────────┘

     {{ _4}.}. y`:0 (1 :'5!:5@< ::]^:2]''u''')  }}   ger      NB. if you don't want parens in result
? + 2 - |.
    gerundToStringAdv=:  {{ _3}. m`:0 (1 :'5!:5@< ::]^:2]''u''')  }}     NB. adverb
    ger  gerundToStringAdv
(? + 2 - |.)
------------------------------------------------------------------------------

.lex & dex and ident accept nouns (TODO: conisder implications)
-----------------------------------------------------
  3 [. 6
3
   ? [. 6
?
   6 [. ?
6
   ? 5 ]:
3
   5 ]: ("_)
5"_
-----------------------------------------------------

see <https://code.jsoftware.com/wiki/Vocabulary/PartsOfSpeech#Call_by_name_and_Call_by_reference>

TODO: convert between integer & character, and how to literally specify bytestrings by hex codes?

.assignment

* multiple assignment is 'string'=.value where value is a vector. if value is an array of boxes then values are unboxed before being assigned.
* we can dereference symbols to strings then assign to identifiers of the same string value e.g.

[source,j]
----
   x=.'cat'
   (x)=.50
   cat
50
----

TODO: learn about locales

==== jections

all type conversions lose, gain (assume default), or retain exactly the dom's information.

[options="header"]
|==================================================================================================
| symbol | function     | dom      | cod       | x   | jection | nb
| <. >.  | floor & ceil | ℂ        | ℤ         | n/a | sur     | operates on both real & imag parts
| *      | signum       | ℤ        | {_1, 0 1} | n/a | sur     |
| r.     | angle        | ℝ        | ℂ         | n/a | bi      | x r. y = x * r. y
| ~.     | nub          | multiset | set       | n/a | sur     | discards multiplicity
|==================================================================================================

==== arithmetic conveniences

these can make for nicer expressions—especially tacit ones.

[options="header"]
|=====================================================
| symbol | operation            | link:https://en.wikipedia.org/wiki/Hyperoperation[hyperoperation] index
| <: >:  | decrement, increment | 0
| -: +:  | halve, double        | 1
| *: %:  | square [root]        | 2
|=====================================================

remember that inverse operations are operations with inverse right arguments e.g. root(x,y) is exp(x,-y).

==== polynomials & encodings

TODO: expound

polynomials are extremely versatile. some things they can represent:

. numbers of a given radix
. a set (addition, which is commutative as is set union; coproduct generalizes them both) of non-commutative (multiplication, generally product) operations each applied a given number of times (exponentiation). this is a group-theoretic consideration.
. linear transforms (including converting [expressing a relation] between radixes)
. equations. polynomials are canonically expressed homogenously i.e. as an expression equivalent to zero.

we can represent ACF~16~ as a couple of vectors, `10 12 15` & `16 16 16`, or by `'1012F',2 2 1,10 10 16`, etc.

[options="header"]
|===========================================================================================================================================
| symbol | name                                                                                                                  | default x
| #:     | base x by digit vector y i.e. polynomial with coefficients encoded by x at value y. accepts mixed radix e.g. HH:MM:SS | 2
| m b.   | [signed] bit shift or rotate (m=34, m=33, m=32 respectively) (neg x for right); or bitwise op; see below              | 0
| p.     | TODO                                                                                                                  |
|===========================================================================================================================================

`#.` (one dot) produces an item and `#:` (many dots) produces a list.

===== bases

every integer is expressable as a polynomial `+/b^i.n` for base `b` an n-degree polynomial `b` represented as a row vector e.g. 11~10~ = 1011~2~. this would usually be expressed by `+/2 2 0 2^i.4`, but `+/(b*l)^i.#l` where b=2, and l is a logical vector, illustrates relation to the 1011~2~ form:

[source,j]
----
   b=:2
   n=:11
   ]l=:b(#.^:_1)n NB. n in base b. ^: is needed b/c we don't know #l in advance
1 0 1 1
   +/(b*|.l)^i.#l
11
----

l generalizes to p simply by generalizing each of its elements from a logical value to an integer.

TODO: `(3.5&*)` is a composite operation: `((3&*)+-:)`. consider numbers as structures, as maps, or precursors thereto, similarly to how matrices can be considered maps. there's also the fact that a numeral x can become its reciprocal by prepending `1`, and that a number may be negated by prepending a `1` (similarly to how a bitvector is negated by flipping its msb) i.e. that numbers encode multiple data. funny how numbers do that. they encode multiple data and have their own algebra. how can array structuring primitives

===== bitwise `b.`

`b.`'s `m` is given by a length-4 logical vector encoding a truth table by being interpreted as a table. suppose m=0bWXYZ; then the truth table is

  | x y
--+----
x | W X
y | Y Z

b=0b0111 is or because `or` satisfies the truth table x L y where L=or:

    | y=0 | y=1
----+-----+----
x=0 | 0   | 1
x=1 | 1   | 1

you can view the table by `0 1 (7 b.) table 0 1`. `table` is of the stdlib.

* add 16 to m to run the bitwise op on integers as bitvectors rather than logical arrays.

example of j being badass: `showbin=:'01'{~(32#2)&#:`.

==== partitions (aka groups, collections)

structure derived of uniqueness (equivalence relation).

[options="header"]
|==============================
| symbol | name
| ~: =   | [not] equal (rank 0)
| -:     | match (rank _)
|==============================

.`=` vs `-:`:
----
   6 5 = 1 5
0 1
   6 5 -: 1 5
0
   6 5 -: 6 5
1
   (<'hello')-:<'hello'
1
   (<'hello')=<'hello'
1
   'hello'='hello'
1 1 1 1 1
   'hello'='hellow'
length error
   'hello'-:'hello'
1
   'hello'-:<'hello'
0
----

[NOTE]
* _not match_ is `-.@-:`
* `=` works on atoms, including boxed atoms

==== sequences (natural encoding)

===== sets (seqs w/o.r.t. arbitrary order)

| symbol | set operation
| -. | \\
| #  | [specify] (sub)set cardinality

==== lattices

structure derived of an _order_ [math, not info theory].

[options="header"]
| symbol    | operation
| < > <: >: | less or greater than [or equal]
| <. >.     | min & max | n/a

NOTE: conjunction `!.` changes tolerance

NOTE: min, max, <, & > are informationally equivalent to < alone; they all form the same lattices up to orientation (start vs end), which is no matter considering that one may traverse structures in either order. if the lattice is an unordered graph then all of the ordered structure's relations are the same; else one is the reverse of the other. note that generally _infinum_ (aka _meet_) alone is the basis for ordering. (to be fair, this note is really only insofar as complex numbers. i'm assuming that these semilattices naturally give complete lattice definitions based on common fields.)

==== link:https://en.wikipedia.org/wiki/Distributive_lattice[distributive lattices], modulus, modulo rings, and rings

obviously this section considers various structures fluidly. as such and as usual, i'll use the general (co)product instead of join/meet vs union/intersection vs and/or &c.

namely boolean rings (namely ℤ/2) and ℤ. because j has primitives for modular arithmetic, we may consider many boolean or other modulo rings.

[options="header"]
| symbol    | operation
| +.        | gcd/or
| *.        | lcm/and
| +:        | nor
| *:        | nand
| ([-.-.)   | intersection (literally A\(A\B)) the fork is used dyadically, so it expands to (x[y) -. (x-.y)
| _ | union

==== groups

TODO: currently this section has only inverse (NOT), which is of groups,...and i suppose that no other common algebraic structure that has an inverse.

| symbol | description
| -.     | not for both booleans and probabilities. literally y==0?1:1-y.

==== fields

namely ℚ,ℝ,ℂ.

[options="header"]
|=====================================
| symbol | name     | default x
| +      | coprod   | n/a
| -      | inv(+)   | 0
| *      | prod     | n/a
| %      | inv(*)   | 1
| ^      | exp      | euler's constant
| ^.     | log      | euler's constant
| %:     | root     | 2
| !      | offset Γ | n/a
|=====================================

log, exp, & root are closed over ℂ. log is strange in that, afaict, it is inexpressible by the inverse identity, -1. otherwise it's used as a transform (e.g. logit) and link:https://en.wikipedia.org/wiki/Logarithm#Inverses_of_other_exponential_functions[expresses group isomorphism], though i don't see how to benefit from that (yet).

===== link:https://code.jsoftware.com/wiki/Essays/Complex_Operations[complex numbers]

[options="header"]
|===============================================================
| symbol | description
| +      | complex conjugate
| +.     | break complex number into array of real & imag
| *.     | length [abs, modulus, magnitude] & angle [arg[ument]]
| j.     | imag
| j.     | create complex number of real & imag parts x & y
|===============================================================

==== combinatorics

[options="header"]
| symbol | name
| !      | yCx

==== arrays (relations)

.generation

i.1 i:1 NB. [0,n] or [_n,n]

.rearrange/reshape

NOTE: $1 & #1 are statistics but $2 & #2 reshape, so i've included them together because each their monadic corresponds to their dyadics: getting vs setting.
NOTE: `$` always returns a list whereas `#` always returns a scalar.

$12 NB. shape. use $. for sparse arrays
|.1 NB. reverse
|.2 NB. rotate
[x] |.!.f y NB. shift. x defaults to _1 (right shift 1). f is the fill item.
|:1 NB. reverse shape -- leading axis. for tables, this is transpose. TODO: when would one use this? when would one even transpose? it's done in linalg, but why?
u;.0 y NB. reverse all axes then apply u, which may be ] . cf |. which reverses only the leading axis.
|:2 NB. rearrange (permute) axes by specifying the last axes as x. axes are 0-indexed. TODO: see example on its nuvoc page
#12 NB. get or set number of times that an item appears in a list. number of atoms is #@,y or */@$y
A.2 NB. lol, idk. combination can be encoded by bit vectors and thus integers

.subset identification

subset selection is usually thought of as extraction, though this is folly; there's no extraction; there's only identification. thus subsetting, partitioning, and grouping are all the same concept: marking, anyhow, subsets. permutation is grouping but with order and, usually, with the constraint that #y=#~:y, though this constraint may be dropped by using behavior like #2.

u"n NB. select axes. if n is a b then y's rank is b for both monadic & dyadic case, and x's rank is a.
{. }. {: }: NB. { means "take", } means "drop", . means first, : means last. thus }: means "drop last". NOTE: for `{.` and `}.`, x<0 works from the end.  thus `}:` & `{:`, both of which have only monadic valences, are redundant anyway; they're equivalent to `_1&}.` & `_1&{.` respectively.
~.1 NB. nub. equivalent to (~:y)#y
~:1 NB. a logic vector of items found of the nub; it replaces newly-encountered items by 1, and those already encountered by 0.
{2 NB. subset by indices. mnemonic: { looks like ∈.
|:2 when x=< 0 1 NB. extract diagonal
x ];.0 y NB. subarray. TODO: how different from {2?
/. selects oblique diagonals. remember special form of |: to select non-oblique diagonal. idk when either would be used, though apparently it's for polynomials. TODO: explore radix/polynomial encodings!
/: \: NB. grade up & down, respectively. permutes *x by permutation y*. monadic uses numeric or lexiographic order. dyadic uses order from x. /:~y (i.e. y/:y) sorts /: rearranges elts whereas |: rearranges axes. /: should be named "permute." \: can be expressed by /: and others permutation/rearranging primitives but that'd be less efficient. use grade down when appropriate and don't worry about the fact that it is redundant wrt /:. note that grades generally express permutations; the C. primitive is a separate thing that's apparently useful for group theorists.
m}y NB. requires #m=#y. when y is a list of choices/alternatives, m's ith item, v, selects the vth row of y as the output's ith item. e.g. 2 1 0 0}'smol','holy',:'cats' => cool. the dyadic case is what you'd expect; x is the replacement set and m is a vector of list positions (or exact coordinates if boxed e.g. <0 1;2 3). `var=[.:]x m}var` or `var=[.:]var,x` make } to modify in-place. use I.1 on x if necessary.
NB. you probably want to use ^: rather than }
{::2 NB. path (index) into deeply ragged y. {::1 y with the same structure of nested boxes, but each box's value is replaced by a path to it—the value for x in {::2.
e.2 NB. boolean: x∈y. (#y)~:y i.x . e.1 is, for each boxed item i in y, for each j in ;y , j∈i. aside from identify matrix e.i.y, idk when it'd be used, but hey, maybe somewheres~
E.2 NB. e. but x is a list; checks for subarrays rather than elements. *DO NOT USE FOR INTEGER LISTS.* it'll _corrupt the j session!_
i.2 NB. 1st index of *y in x* else #x. if x is a nub then i. can be thought of as "lookup the index"
i:2 NB. last index of y in x else #x

sort example:
----
t=:_2 ]\ 'taylor';20;'steven';40;'lars';23
   /:~t
┌──────┬──┐
│lars  │23│
├──────┼──┤
│steven│40│
├──────┼──┤
│taylor│20│
└──────┴──┘
   t/:>1{"1 t
┌──────┬──┐
│taylor│20│
├──────┼──┤
│lars  │23│
├──────┼──┤
│steven│40│
└──────┴──┘
----

.supersets (including grouping)

,2 NB. append
{y NB. when y is a list of boxes, cartesian product of the boxes elts

.complex subset selectors with aggregates

[x] u;.1 NB. split y on 1st item of y then apply u to each subinterval e.g. +/;.1 (0 1 2 3 0 10 20 30) => 6 60. ;.2 is the same but matches from the end and with the last elt. _1 & _2 are like but don't include frets in resultant subintervals. if logical vector x is provided then it's the beginning (1) or end (2) frets.
x u\y NB. apply u to x-chunks of y. windowed if x>0, not windowed if x<0. _n ]\ y is a common pattern to turn list y into a table with n columns.
u\.y NB. apply u to y then to its tail .... optimized for fold i.e. u/\. .
\1 NB. like scan but does not necessarily accumulate; each row's output is unrelated to the others' outputs. this makes it a very poor choice for scan i.e. the u/\ form.
u/. & u/.. NB. x of y. `x agg/. y` is equivalent to sql `select agg(y) group by x` where x is commonly a fn of y. for each group, `agg` is applied to each list of all y commonly grouped by their unique, correspondent elt of x. requires that #x=#y. maps `agg` over a datum of shape [(x,[y])]. /.. passes the keys (of x) to u i.e. sql `select agg(x,y) group by x`. agg is commonly `v/`, so get used to `+//.`
x u .v y 2 NB. array product. preceeding space is required. equivalent to `x u@v"(>:lv) _]y` (or `x u@:v"(>:lv) _]y`?) where lv is v's left rank. like the common matrix product, the array product requires, at least for rank-2 arrays, that they be of shapes (a b) (b c). this reflects `v"(>:lv) _`—that each element of x is matched to all of y (rank 0 y), and each cell of each of x's row is matched to y's column (see example below).
u\.2 NB. like \ , u\.2 is a window fn, but the complement of \'s windows; rather than each row being a fn on [i,i+x], it's y but with the subarray of indices [i,i+x] removed.

NOTE: u/.y is oblique; x u/.y is key, and x u/..y is key dyad! key always requires the "group by" expression!

array product example:
----
   (2 2 $ 700 300 600 1100) ] .+ i.2 3
 700  701  702
 303  304  305

 600  601  602
1103 1104 1105
----

an example where we must use a verb and its rank more generally than array product can accomodate:
----
   6568 * 1.03 1.04 1.05 ^/ 5 20 NB. can't use . b/c shapes 3 & 2 mismatch! so we use outer product i.e. table. v/ is v"0 _
7614.11 11862.5
7990.98 14391.3
8382.62 17426.9
----

key examples:
----
   1 1 2 1 2 4 4 2 1 3 </. 'catepillar'
┌────┬───┬──┬─┐
│caea│tpl│il│r│
└────┴───┴──┴─┘

   y=.'hullabaloo'
   |:y{{x;#y}}/..y NB. select x,count(x) from y group by x
   NB. (<"0~.y),:(<"0 y#/.y) is equivalent but more verbose, using /. instead of /..
┌─┬─┬─┬─┬─┬─┐
│h│u│l│a│b│o│
├─┼─┼─┼─┼─┼─┤
│1│1│3│2│1│2│
└─┴─┴─┴─┴─┴─┘

   ]a =. _2 ]\ 'Fred';100;'Joe';200;'Fred';50;'Sam';30
┌────┬───┐
│Fred│100│
├────┼───┤
│Joe │200│
├────┼───┤
│Fred│50 │
├────┼───┤
│Sam │30 │
└────┴───┘

   (0{"1 a){{x,<+/>y}}/.. 1{"1 a NB. select col0,sum(col1) from a group by col0
   (0{"1 a)(,<@(+/)@:>)/.. 1{"1 a NB. tacit (hook) version. note that i needed to parenthesize +/ ! note also that the λ is terser, more readable, and doesn't concern operator valence!
┌────┬───┐
│Fred│150│
├────┼───┤
│Joe │200│
├────┼───┤
│Sam │30 │
└────┴───┘
NB. more verbose /. equivalent: (~.0{"1 a) ,. <"0 (0{"1 a) +/@:>/. 1{"1 a
NB. (~.0{"1 a)   ,.      <"0    (0{"1 a)                  +/@:>                  /.    1{"1 a
NB. |--------| |----|  |------| |------| |------------------------------------| |---| |------|
     nub(col0) stitch  map box    col0    for each group: unbox cells then sum   key    col1
----

.other relations

I.2 NB. with sorted array of frets, x, tells which interval each of y falls into e.g. 0 6 10 30 I. 4 2 20 => 1 1 3. another interpretation: the index at which i would be inserted into x while maintaining x's order. x may be ascending or descending.

===== folds

u/1 NB. generalization of fold. literally inserts u between entries of y e.g. +`-/1 2 3 4 is 1+2-3+4-5+6. x u/ y is x u"(lu,_) y where lu is u's left rank.

.the F:. & derived operators

x (u F<s><t> v) y where s∈{(: multiple (scan)) (. single (fold))}, t∈{( unlimited (use Z: anywhere in u or v)) (. forward (right fold)) (: reverse (left fold))} NB. fold. x is initial object. y is the traversable. v is the recurrence relation, and u is applied to each intermediate result of v e.g. +++4(-&:>)F.:;1 2 3+++ produces +++_1 _2 _3 _4+++. the scan would pad results with zeroes:

----
  4(-&:>)F::;1 2 3
_3 _4  0  0
_2 _3 _4  0
_1 _2 _3 _4
----

which is like a ring buffer!

* u is commonly ]

TODO: how to use x∈{_1,0,1} wrt Z: ?

==== grouping (subset selection)

i.~ maps elems to group ids. TODO: how?
/. implicitly uses i.~ on x

==== gerunds

applying verbs cyclically, e.g. to :

[source,j]
----
   (<:`>:)"0]3 10 6 30 NB. equivalent to (<:3),(>:10),(<:6),(>:30)
2 11 5 31
----

this works because:
. rank turns the gerund into a verb
. rank is a _partitioning verb_, which allows it to work with cyclic gerunds. it's the verb that enables cyclic application of gerunds but does nothing.

==== loops

[x] u^:n y NB. x like hook: x u^:n y is equivalent to (x&u)^:n y. performs u to y n times. in math notation this is denoted f^∘_n_^. if n is a verb then that verb's result of application to y and x if given, is n. cases of n:

|==============================
| _1            | obverse
| 0             | identity
| integers      | apply verb k times for each k of the integers
| _             | repeat until convergence. use `a:` to collect results like a scan.
| boxed integer | do n times, collecting intermediate results like a scan
| verb          | [x] u^:v y applies v to x and/or y, thus determining the number of times to apply u to x and/or y. it's a little odd, yet natural, that v is also used dyadically. of course you can always bind to its left argument e.g. `x u^:(m&v) y`, or if you want monadic v then do `v@:[` or `v@:]`.
|==============================

special case: `[x] u^:v^:_ y` where v produces a boolean: repeats u until not v (i.e. once more than while v), or until u(y)=y—literally `while(v(y)&&(u(y)!=y))y=u(y);` except an expression, not a statement.

the boxed version is nice. i wish i'd known it yesterday when i wrote:

[source,j]
----
a=.10 5 6 4 _5 _76
   (,1|.{:)^:(<:#a),:a NB. (1) my original
   1|.^:(<#a)a         NB. (2) boxed version
   (<@:#(1&|.^:))a     NB. (3) tacit version of (2)
   1(<@:#@:](|.^:))a   NB. (4) alternate of (3), useful if you want x to be a parameter of, rather than embedded in, the verb
NB. all produce the following output:
 10   5   6   4  _5 _76
  5   6   4  _5 _76  10
  6   4  _5 _76  10   5
  4  _5 _76  10   5   6
 _5 _76  10   5   6   4
_76  10   5   6   4  _5
----

NOTE: you may be surprised by the order of (3). `(1&|.^:)` is an adverb; adverbs' arguments go on the left. here that argument is the verb `<@:#`. applying a verb to an adverb produces a verb whose noun argument is the same as the verb before being applied to the adverb.

==== symbols, language, (meta)programming

~ NB. given identifier x with value v, x~ evaluates to v (as an identifier, i think)
: NB. define verb. usually use `{{}}` though; in fact idek when you wouldn't
:. :: NB. associate [ob|ad]verse with a verb. used in definitions but it itself does not define. it may be used inline to override a verb's obverse.
{{ ... }} NB. define verb
;:1 words
[ ] NB. left & right or identity
".1 NB. eval? i don't understand this one.
".2 NB. string -> number. x is numeric value assumed on word-as-number parse failure

NOTE: both ".1 & ".2 convert strings to numbers but ".2 is much faster.

==== convenience or otherwise seemingly unnecessary verbs

~ NB. monad: (u~y) = (y u y). dyad: swaps arg order
,1 ,.1 NB. convert any array into a list or table. x ,. y is x ,"_1 y. basically: array as column rather than row.
,:1 NB. make shape y array into shape 1 y. dunno what it's good for.
,:2 NB. append with two dimensions. usually used like `x,y,:z`
;1 NB. in the simple, useful, common case, raze the structure; makes any shape into a flat list.
;2 NB. dual of ;1: creates ragged (boxed) arrays from lists e.g. 1 1 2 1 2 3 3 2 1 4 ;/.. 'catepillar' => {1,caea;2,tpl;3,il;4,r}. ; is ,&:<

==== matrices

%.12 NB. divide, inverse
u.v y NB. fn of minors & cofactors. prohibitively slow for arrays larger than 15×15. TODO: exactly identify, and study.
-/ . * y NB. determinant (lin alg). tuned.
x +/ . * y NB. dot or matrix product (lin alg). if x is a list then it's treated as a row vector. if y is a list then it's treated as a colvec.

link:https://www.jsoftware.com/help/dictionary/intro25.htm[`.` is useful for linear functions].

==== parser

;:2

==== combinators & tacit (pointfree) function relations ("trains")

TODO: this section needs great revision now that i've considered the nature of tacitity and combinators' inherent flaw.

.systematic tacitifying example

(historical note: this is the consideration that got me into j and back into factor from scheme! combinators made me want to really see how _reduced_ code could be. a year or two later i'd find that terse, information-dense encodings are indeed important!)

consider `(f4 a) f3 a f2 y[a=.f1 y`. seems like it'd be nicer if tacit i.e. without mentioning `y` nor using local binds. in factor that's `dup f1 f2 _f4a f3` where `_f4a` is some expression that i've yet to identify; to me the hook pattern `dup f1 f2` was obvious, then of course the result of that is one of the two arguments to `f3`; that's how i arrived at this incomplete expression thus far. the trouble is that applying `f2` consumes `a`, removing it from context. replacing `f2` by `dup [ f2 ] dip` satisfies. so `_f4a` would be a higher-order fn that takes `f2` as its parameter. so a complete solution is `dup f1 dup [ f2 ] dip f4 f3`. it would be more appropriately expressed as `dup f1 [ f2 ] keep f4 f3` if `keep` were defined as `dup call`. another interpretation, but not one that i find immediately easy, is that both `f4` and `f2&y` are applied to `a`.

diagram:

---------
     y
    / \
  f1-->f2
 /      \
f4------>f3
---------

this diagram accidentally kind of abuses notation: it has arrows going from functions to other functions (the arrow implicitly being from higher items to lower ones) rather than binding to data then having arrows from those data. that turns-out to be fine, and even offers a better persective, because `(g.f)(y)` is equivalent to `g a[a=.f y`. also, likely a useful consideration is that all functions can be made unary by composition or binding, and binding should be seen as just another variety of composition i.e. `d&` should be a unary higher-order function that binds an argument to value `d`. should generalize to `p=v&` to bind parameter `p` to value `v` within the context of some implicit function. in fact, this can be phrased as "p=v in the context of function f" and that's likely a better model than saying that functions take parameters, since it's the same model used outside of functions, and thus unifies functions with bound variables, and generalizes functions to contexts.

anyway, the diagram shows that we can express the expression as `((f3@f2) f1)y`. it quite clearly & easily represents nested forks.
in fact, to identify a tacit definition, i.e. a stack one, i.e. one without local binds, we can re-express without the binds then combine functions. the steps follow:

----
(f4 f1 y) f3 (f1 y) f2 y NB. no local binds
(f4@f1 y) f3 (f1 y) f2 y NB. combine succession of unary fn app into single app of composition of unary fns
(f4@f1 y) f3 (f1 f2]) y  NB. factor into hook (expressed more generally as fork). now we have both f4@f1 and (f1 f2]) as functions of y, and they're both passed to f3. this follows the hook pattern: (f h g) where f=f4@f1, h=f3, g=(f1 f2]).
(f4@f1 f3 (f1 f2]))      NB. finished refactoring into tacit expression.
f1{{(f4@u) f3 (u f2])}}  NB. it'd be nice if a tacit modifier pattern AVA existed, which would itself be an adverb s.t. (A1 V1 A2)V2 evaluates as the fork (V2 A1) V1 (V2 A2). it does not, so using an anonymous adverb definition is the tersest that we can do to specify f1 as such only once. it's specified twice transitively by u being specified twice and it being equivalent to u.
----

that was surprisingly easy. interestingly the stack version only tacitly repeats anything, by using `dup`. it saves the result of `f1` to the stack and thus does not need to specify `y f1` twice nor even just `f1` twice. still, the stack version of the tacit modifier version is `dup f1 [ f2 ] dip [ f4 ] f3`.

demonstration:

[source,j]
----
   f1=:toupper
   f2=:,
   f3=:,~
   f4=:}.
   z=:'abc'
   {{(f4 a) f3 a f2 y[a=.f1 y}}z NB. original
ABCabcBC
   (f4@f1 f3 (f1 f2]))z     NB. tacit: fork with f1 twice
ABCabcBC
   f1{{(f4@u) f3 (u f2])}}z NB. tacit: fork with non-tacit adverb specification
ABCabcBC
----

[source,factor]
----
USING: unicode sequences ;
: f1 ( x -- x )   >upper      ; inline
: f2 ( x y -- z )      append ; inline
: f3 ( x y -- z ) swap append ; inline
: f4 ( x -- x )   rest        ; inline
: z ( -- x ) "abc" ; inline
! i forgot about how factor's arg order differs from j's; hence the swap's:
z dup f1 dup [ swap f2 ] dip f4 swap f3 .
"ABCabcBC"
----

''''

NOTE: the fork is ubiquitous because the even tines are unary fns and the odd ones are binary. with functions, all outputs are only useful if they're passed as inputs. forks accomodate both (unary) composition (use `@:` or `[:`) and binary application. because ternary fns are rare (and don't even exist in j), the fork works well for most computations. forks still don't elegantly express asymmetric computations, though.

one should really think in terms of _combinators_ rather than _tacit_. trains are useful as combinators. there's no benefit _per se_ to avoiding lambdas, though.

TODO: consider `x(v4(v6 v0 v1 C v2 v3)v5)y` where C accepts v4 & v5 as arguments, but, as per usual, v6...v3 accept the outputs of `x v4 y` & `x v5 y`. this is obviously possible in langs with higher-order functions (a symmetric & recursive consideration of functions, as opposed to j's ad-hoc specification of parts of speech.) a good syntax for higher-order combinators would, like all notations, be in terms of a/symmetries. something like (fork v4 (fork (*-.C)) v5)

a _train_ is a relation of multiple functions, denoted by <juxtapositions of functions> various forms. they come in two varieties: _hooks_ are trains with an even parity; _forks_ are those of an odd arity. a hook is of the form A B, where B is a fork or single verb. A B evaluates to A(x,B(y)) or A(y,B(y)) if x is missing. a fork ... C Y B Z A is evaluated as Y(C([x,]y),Z(B([x,]y),A([x,]y))); every 2nd verb V from the right is used dyadically and combines the running computation from the right with V's left arg, as per usual dyadic verb evaluation. for readability, to immediately know a train's parity, you should parenthesize hooks' second part e.g. A B C D should be written A (B C D).

trains' verbs' args can be specified as nouns (which are used as constants i.e. they are used instead of x or y), or you can use `[` or `]` to use x or y instead. for example, `3(1%2+*)5` is 1%(2+(3*5)); firstly, it's a train with odd parity, so it's parsed as a fork. next, the fork is given both x & y, so it's used dyadically. it's broken into (1%)(2+*); the right parenthesized expression is a fork that uses 2 instead of x, so it applies `*` dyadically to x & y, then `+` dyadically to 2 & the result of `x*y`; then the next verb is `%` and its x argument is the constant 1 instead of x. thus the result is 1/17. instead of the literal 1 we could use x or y by using `[` or `]`: `3([%2+*)5` is 3/17. `3(%2+*)5` would not be 1/17 because its evaluation would be quite different because its parity is even, meaning that it'd be interpreted as a hook: % (2+*) which evaluates to 3 % (2+*5) which is 1: *5 is signum(5)=1; add 2 to get 3; 3 divided by itself is 1.

forks are like `Applicative` in haskell except of course limited to binary & unary verbs because those are the only arities that j uses. e.g. `5 (* , % , [ - ]) 3` produces 1.66667 15 1.66667 2; it does `(5*3) , (5%3) , (5-3)`. cap (`[:`) makes the verb to its right monadic e.g. `5 ([: }: * , % , [ - ]) 3` produces 15 1.66667. because cap affects only the single verb to its right, there can be multiple capped verbs in any train. "cap" just means "use monadic version." as with ordinary monadic verbs, capped verbs apply to whatever's accumulated on the right side yet e.g. inserting `[:{.`—`5 ([: {. [: }: * , % , [ - ]) 3`—produces 15. and of course, like any fork, we may stick on a left argument and a (dyadic) verb to continue the fork: `5([*[:{.[:}:*,%,[-])3` produces 75.

the dyadic hook is like the dyadic fork except that all but its leftmost verb operate on y alone, monadically. e.g. `5 (, *: , % , [ - 1:) 3` produces 5 9 0.333333 2; it's `5,(*:3),(%3),3-1:3``. using `[` is misleading b/c it's used monadically; `]` is preferred. monadic fork and monadic hook are nearly identical:

.summary: hook & fork
[source,j]
----
   (  - *: , % , [ - 1:) 3 NB. monadic hook
_6 2.66667 1
   ([ - *: , % , [ - 1:) 3 NB. equivalent monadic fork: just add the identity function^*^
_6 2.66667 1

   10 (- *: , % , [ - 1:) 3 NB. dyadic hook, identifiable by its missing leftmost function
1 9.66667 8
   ([: 10&- *: , % , [ - 1:) 3 NB. equivalent monadic fork: just curry x with leftmost verb, then cap it.
----

^*^i used `[` instead of the canonical `]` because it parallels adding `[:` to fork-ify the dyadic hook.

if your train needs access to both x & y then it must be a fork. given that all forks can express all hooks quite easily, and computations that cannot be expressed by hooks, one should probably use only forks. true, the dyadic hook is nicer syntax by eschewing the cap and bind. so i suggest that one consider that there's only one concept—fork—and that hook is just prettier syntax. so do whatever seems nicest. just don't wonder about "forks vs hooks." hook is just nicer syntax for a class of monadic fork.

the relation between forks and function composition: `[:%:[:+/*` is equivalent to `%@:(+/)@:*:` and although there are NVV trains there exist no VVN trains. this makes sense in the monadic case b/c there's no reason to have a function that discards its only argument. in the dyadic case you'll need to use some form of constant function, probably `n"_`, but that's generally g(f(x,y),c) which can be coded tacitly as `[:g&c f`. while VVN `f g c` is neater, that parse pattern probably already denotes something else.

===== using bind (`&`)

binding x to a train is the same as making the train dyadic with its left argument bound:

* `x&(uv)` is equivalent to `(x&u v)` is equivalent to `{{x(u v)y}}` is equivalent to `{{x u v y}}`
* `x&(ghf)` is equivalent to `(x&g h x&f)` is equivalent to `{{x(ghf)y}}`

modifiers (adverbs, conjunctions) compose verbs. , works! 

re-expressions in the function model:

* constant fns effectively cast nouns to verbs. `f@n` is a terse equivalent of `f@:n"_`. note that only `@`, not `@:`, works.
  ** `x&f@y` is equivalent to `(x f y)"_`.
    *** generally, conjunctions are used to derive verb forms of nouns, which is useful to delay evaluation. these are a bit mroe ergonomic than wrapping <an expression that evaluates to a noun> in `{{ }}`. nouns are evaluated immediately, whereas verbs are evaluated only when they're invoked. conjunctions (generally modifiers, though) are thus similar to lisp macros: they're morphisms from programs to programs, where the arguments are not necessarily evaluated. modifiers may be defined tacitly or explicitly.
* use `u@[` or `u@]` to use a unary fn `u` where a binary is expected.
* +++`''+++ casts verbs to nouns.

.{{}} and "_ are not interchangeable!
[source,j]
----
   f=:(j+k)"_
   f''
|value error: k
|       f''
   k=:4
   j=:100
   f 0
|domain error in k, executing monad k
|       f 0
   f=:{{j+k}}
   f 0
104
----

"monad k" tells us the problem: `(j+k)` is parsed as a fork.

NOTE: it's impossible to tacitly express `(f x)&g` because, being tacit, we can't use `x`; we can only use the _verb_ `f@:[`, and `&g` is an adverb, so applying another verb to it will result in a verb; however, we want to pass a noun to `&g`! there is no facility in j to say "evaluate this verb then, as a noun, bind it to g`; in other words, `&` is, in a tacit expression, always used as compose, never as bond! therefore modifier trains are actually not turing complete!
TODO: update this to tell how to use a tacit modifier to do this.
TODO: actually, one can use gerunds like how is done for tacit amend, right?: smth like ``f`g`h}`? ask cameron. also `x&v"1 y` is equivalent to `x v"_ 1 y`. check-out `(*:+:&)` vs `*:(+:&)`.

===== link:https://code.jsoftware.com/wiki/Vocabulary/fork#invisiblemodifiers[modifier trains]

_modifier trains_ generalize n-ary forks or hooks from producing verbs, to combinators (higher-order functions) which produce verbs, adverbs, or conjunctions. they are j's most general concept of inline combinator specification. they are essential j knowledge; for example, the common verb `every=:&>` is a modifier train following the CV form which produces an adverb.

NOTE: i consider appropriate that there are not two distinct words for monadic and dyadic verbs, but instead that general adjectives about arity are applied to the word _verb_; keeping symetrically with this sensibility i shall use the term _modifier_ only, never _adverb_ nor _conjunction_, which each/both refer(s) to the same concept though their parameters (namely arities) differ. however, i will still use the distinct terms when regarding their "quick search" codes as found in the modifier train nuvoc page.

NOTE: NVN is a combinator! dyadic verbs combine nouns! this demonstrates the symmetry that the class of higher-order functions entails first-order functions as a base case—the ultimate, terminal application of combinators.

===== coding mostly by combinators

motivation:

* brevity, elegance, maintainability
* efficiency
  ** link:https://code.jsoftware.com/wiki/Vocabulary/SpecialCombinations[special combinations]. all sc's are of modifiers only.
  ** link:https://code.jsoftware.com/wiki/Vocabulary/SpecialCombinations#EIP[execution in place (eip)], particularly for `}`. tacit eip is the _anonymous_ case (cf the _zombie_ case).

why not:

* link:https://code.jsoftware.com/wiki/Fifty_Shades_of_J/Chapter_17[readability] (sometimes). frankly, though, it's your fault if you don't write readable code. though one _can_ express their code by extremely obtuse modifier trains, one can express their code by a multitude of other obtuse forms, too. like all things, modifier trains can be useful, and should be used usefully, regardless of what obtuse possibilities their algebra technically supports. nobody thinks that <english is a bad language because "buffalo buffalo buffalo buffalo buffalo buffalo buffalo" or whatever is legal>. this being said, j, by using multiple characters per primitive, suffers ease of parsability as apl does not. consider `ocr=.;@(<@i.@#/.~)/:[:/:~.i.]`. we see dots around, and a symmetry of `[` & `]`. however, this geometric symmetry does not reflect the code, since `[:` & `]` are the actual primitives, and they have entirely different meanings! furthermore the dot nor colon communicates any idea by itself; it mearly means "variant 1" or "variant 2", generally though sometimes they're related e.g. as in `[{}][.:]` or `#[.:]`. to parse `ocr=.;@(<@i.@#/.~)/:[:/:~.i.]` we say "`]` then `i.`—so we're developing a train now—then `~.` then `/:` then `[:` which is a fork whose 5th tine is cap." that whole thing is right of `/:` which is left of an expression attached to `;@`; thus `/:` is the middle tine of a 3-fork. that's frankly horrible to parse, though not too bad compared to the amount of mental work needed to parse its equivalent code in non-apl languages. elegance is inherent in structure but is most useful to a programmer when reflected in code. in the FSoJ ch. 17 link, using `up` is appropriate only insofar as `up` is an arbitrarily symbol that re-expresses `ocb2` more elegantly: in terms of common code. notation is a tool of thought, and misleading notation leads to mislead thoughts. even `#i.@#` is hard to read. it's equivalent to hook `(# (i.@#))`.
  ** some of j's readability issues would be resolved by moving to graphical encodings instead of textual ones. for example, `zigzag=.($ /:@:;@:(|.&.>`]/.)@:(</.)@:i.)@:(2&#)` should be represented as a box of code with lines separated by `@:` and whose name should be placed above the rectangle as a header. forks and hooks should be displayed as graphs. j commonly follows rtl eval, which is fine as long as `x` is simple or is a function under simple composition (i.e. sequencing outputs, accumulating like a fold), namely `@` or `&`.
    *** arguably using colons so frequently is unadvisable because it can be unreadable e.g. in `zigzag`'s definition, `/:@:;@:)` we see `:;` which is nonsense by itself (being that `@:` & `;` are the actual tokens) but might be mistaken for `;:` which is meaningful. one may argue the contrary: that this generally as obvious a difference as "ab" & "ba". regardless, this is avoided if all primitives are single-character, or if `.` & `:` were replaced by ~`1`~ & ~`2`~ which are obviously parsable geometrically by the visual cortex and parseable easily by the frontal lobe as subscripts are immediately & clearly known to only follow, not preceed, the word with which they're associated. of course if one _thinks_ about it, then they'd know that `:` _always_ follows a single character, and the couple characters together are a primitive, but who wants to take the time to think? also one can't say the same for `.` which is alone its own operator and which, by this odd asymmetry, requires preceeding whitespace in order to be properly tokenized. syntax coloring should suffices, however i'm unsure what scheme to use.

the kind of tacit that haskellers wish they could write: `spread=:1:+>./-<./` i.e. 1+max(y)-min(y), literally haskell `\y -> const 1 y + foldl max y - foldl min y`, hopefully optimized into one traversal over `y`. haskell's type system (even with gadts & type families) would make j's general hook very difficult to implement, and cumbersome or limiting to use. replicating j's modifier train system in haskell is either impossible or impractical.

[TODO]
* when does combinators nesting sometimes correspond to nesting in structures e.g. nested `"`, `&>`

j supports the following combinators:

* trains
  ** juxtaposition of words
  ** `[:`
  ** `]:`, `[`, `]`: identity, left, right. `u]:` is the identity adverb: it is used in modifier trains analagously to how `]`, `[`, or `[:` is used in forks or hooks. `v]:n` is equivalent to `v n`. e.g. `+:]:4` = `+:4`.
* ~ (reflex & flip)
* @: (monadic or dyadic)
* &: (dyadic)
* &.: (monadic or dyadic)
* gerunds: ` `: @.

NOTE: `{{x v y}}` is equivalent to `[v]`.

when i think about it, though, all programming is combining things. in j we combine powerful primitives. combinators are just natural ways to do it; ordinary j "without combinators" is just using one or two combinators that have no names but are just how j runs verbs!

NOTE: use tacit expressions only when they're at least as clear as lambdas. e.g. `(,<@(+/)@:>)` is horrible; `{{x,<+/>y}}` is clearer and doesn't concern operator valence. `(,<@:+/@:>)` is `(,(<@:+)/@:>)`, which is applying an adverb to a derived verb—rarely what one wants to do!

n"_ NB. constant function: λ_. n. rank affects: 'c'"1 i. 2 3 6 breaks into (2 3)-frame and 6 cells, replacing each row of 6 by a 'c'. here a rank of _3 or 0 is 2 3 6 $ 'c'
[: NB. force valence of tacit verbs; error is raised if tacit verb is executed with improper valence. aside from egp, idk when to use.
]: [. ]. NB. used for the black magic known as _modifier trains_ aka _invisible modifiers_
m&v is v whose x is m. u&n is u whose y is n. dyadic is the same but applies z times where z is the 2nd arg.
[x] u@v y NB. fn comp. u always monadic, v's arity depends on x's presence. useful b/c it uses v's rank e.g. #@> vs #>

|====================================================================================
| open | close     | dyadic operation                   | comment
| u&v  | (u&:v)"v  | u(v(x),v(y)) i.e u∘v with dyadic v | dyadic u, monadic v
| u@v  | (u@:v)"v  | u(v(x,y)) i.e u∘v with monadic v   | dyadic v, monadic u
| u&.v | (u&.:v)"v | under via obverse                  | close uses v's monadic rank
|====================================================================================

the _close_ [adj] versions have u close to each application of v, hence "closer to v." the terms "near" & "far" should have been chosen.

in the unary case, @ and & are equivalent: standard unary function composition. convention has deprecated monadic & and &: in favor of @ and @: . this standardization was preferred because @: has some optimizations that &: lacks.

// TODO: confirm these fill rules

* open forms fill v(x) and v(y) before applying u; close forms apply u to each of v(x) and v(y) before combining then filling the array composite of v(x) and v(y).
* @ fills the composite of v(x) and v(y). & fills each of v(x) and v(y) then composes them.
* for *close @ only*, if v is a noun, then it's λ_. v.

.fork

neither @: nor &: can implement h(f([x],y),g([x],y)). for that you use hook, which is appropriately denoted [x] f h g y. example: `avg=:+/%#`. j interprets any 3 consecutive verbs as a fork, using the outer ones monadically and the middle one dyadically.

forks must be enclosed by parens where invoked inline.

NOTE: cap makes fork act like unary fn composition i.e. `g@:f` where f is forced to being unary.

TODO: how is cap used as a left arg in `!@<: : [:`? (example from https://code.jsoftware.com/wiki/Vocabulary/bang)

.hook

(g f) is, monadically, g(y,f(y)), or dyadically, g(x,f(y)); the monadic version can be thought of as the dyadic version with x=y implicitly; though `x (g f) y` is `x g f y` and so may seem useless, it's useful for tacit verbs. j interprets any 2 consecutive verbs as a hook.

examples:
----
   (; <:) 5
┌─┬─┐
│5│4│
└─┴─┘
   6 (; <:) 5
┌─┬─┐
│6│4│
└─┴─┘
----

the mnemonic for `(u v) y`=`y u v y` is that `u v` stays in the same place there; `v` is to the left of `u` so its value is passed as `u`'s right argument, but of course this can happen only after `v` has been applied, and naturally, since `v` is right of `u`, `v`'s argument is the right argument, `y`. `u`'s left argument must be filled, so it uses the left argument, `x`, if available; else `y`.

NOTE: monadic hook (g f) is equivalent to fork (] g f). hook & fork dyadically are not usefully related: g(x,f(y)) vs h(g(x,y),f(x,y)). however conceptually equivalent, the fork `([-.-.-)` is not equivalent to hook `(-.-.)` because `[` is dyadic: left, not identity.
NOTE: hook (u]) is equivalent to u~

since we aren't passing fns in j, instead running computations on data y then relating those results to y, hooks are apt, since that's exactly what a hook is: g(y,f(y))! in other words, using datum literals in lieu of λ's naturally gives rise to the hook pattern.

.summary

* `g @: f` is factor `f g`, including how `f` is agnostic over arity
* `(f1 g f2)` is factor `[ f1 ] [ f2 ] bi* g` or `[ f1 ] [ f2 ] 2bi* g` depending on whether x is provided i.e. haskell f1***f2>>>g applied to y or (x,y)
* `g &: f` (dyadic, as is the only form conventionally permitted) is factor `[ f ] bi@ g`
* unary (u v) is factor `dup v u`
* & is partially applied dyadic verb: x&v or v&y e.g. haskell `(>0)` is j (>&0) and haskell `(5+)` is j (5&+)

examples:

NB. let z=.(>x),(>y) in <z/:'RrAa'i.z
NB. in factor it'd be expressed:
[ > ] bi@ , dup "RrAa" [ i. ] curry call /: <
where i.'s argument order is assumed to not need swap 
cross=:<@:(/:'RrAa'&i.)@:,&:>

where we'd use `dup` in factor, we use a hook in j. both require us to see that y is used as the two args to a future fn. in both cases we must preserve its value before passing it to ('RrAa'$i.) i.e. we cannot apply that partial fn immediately b/c we'd overwrite [lose] information.

.(tacit) j vs factor

the compasison suggests itself because both j and factor is entirely pointfree; or rather the points are given at irregular positions in the program; a whole j or factor program can be a single argument followed by a series of unary fns (though ltr in factor and rtl in j.) in both factor and j extra arguments may be given as & where needed. both allow tacit expressions (fn combinators.) the primary difference between j & factor is that factor has a more general argument supplication model because it allows 3+-ary fns, which puts more [read: _excess & intolerable_] responsibility on the programmer to track state through programs; *factor source code does not clearly show the relationships between functions and their arguments.* it doesn't help that factor allows higher order functions, which is excessively powerful and precludes terse & simple encodings of programs.

factor:

* arities are fixed and must be known in advance
  ** higher order functions' arities depend on parameters' arities
* one must track the stack throughout computations
  ** as result values are derived, they're left somewhere in the stack, and *their position relative to other to-be-arguments must be known*. this is stack langs' critical defect.

j:

* arities are 1 or 2
* one must track transforms of data throughout computations
  ** one knows that this is the right argument; if ever a left argument is provided, it's obviously on the left side of the latest verb. *this guarantees positional independence of arguments.* furthermore, the position of arguments does not need to be tracked; the ast is represented clearly (though without visual levels; it's flat, all in one line) in source code, provided that one can recognize the part of speech of each word, which they should.

summary:

* were factor's verb/gerund syntax terser e.g. `f` instead of `[f]` or even worse, `[ f ]`—especially when one needs idioms like `n [ v ] curry apply`. yikes—then it may be terse enough to consider comparing to j. that in j spacing is optional is excellent.
  ** because factor is not so terse, it resorts to user-defined functions instead of primitives
* factor is not specialized (& optimized) around one structure like j is; this means that factor has an inelegantly large set of primitives, about too many iteration schemes, and too many data structures
* j's syntax could be improved a bit, tailored to tacit programs e.g. using juxtaposition instead of @: , like is done for hooks and forks.

nb:

* `([: u v)` and `u@:v` are equivalent
* `([: u v)"v` and `u@v` are equivalent, i.e. `u@v` `v`'s rank.

==== io

* j is file-based, not stream-based; there are no file pointers; all files are read entirely.
  ** j's optimizer probably doesn't literally read in whole files strictly.
* common verb: `1!:1 :: (13!:11@(''"_))`. `u::v` is "try u; if fail then v`. 13:!11 returns the last-raised error's number. recall that verb `x"_` is `const(x)`. we can't just say `13!:11 ''` b/c that'd be a noun, and we want to produce a verb. i suppose that this is the most common idiom for what in haskell would be `const 13!:11`.

.mapping [a file to a noun]

_mapping_ is to create a non-strict-eval noun that represents a file; when read, the file is read, and when set, the file is overwritten.

example: `JCHAR map_jmf_ 'var';'path'` maps `var` with (bilateral) `path`

WARNING: beware accidentally affecting text files by modification of (especially aliased i.e. pointers to) mapped variables!

TODO: see the lab _Mapped Files_ and _Aliasing of Variables_ in the chapter on dlls

== string formatting / pretty print

* remember `table`

`":` converts to a possibly-multidimensional array of displayable bytes (EXCEPT BOX DRAWING CHARCTERS) with optional specification, `x` which is an imaginary number whose real part is the width (num chars; used for padding/spacing) and imaginary part is the number of decimal digits to display. if either re or im is <0 then the numbers are displayed in engineer's notation.

----
   0 0j3 0j_3 ": 100 %~ i. 3 3
0 0.010  2.000e_2
0 0.040  5.000e_2
0 0.070  8.000e_2
----

monadic `":` has nice default formatting.

----
   ; ":&.> 'Today ';'is ';2002 1 24
Today is 2002 1 24
----

the `8!:n` verb family has amazing array formatting capabilities!

----
   '3.0,m<$(>p<$>n<)>q< >c14.2' 8!:0 (10 500.32 ,: 22 _123456)
+---+--------------+
| 10|      $500.32 |
+---+--------------+
| 22| $(123,456.00)|
+---+--------------+
----

x is a string. see jfc ch. 20 for deets.

=== printing boxed structure

the following function displays a boxed array as it displays in the repl except replaces all box-drawing characters (i.e. those with codepoints less than 32) with a space character. a better version would replace these lower-codepoint characters by their appropriate proper unicode box drawing analogues. this can be done in j or maybe by `tr(1)`.

`,(,&LF)"1((' '"_)^:{{(a.i.y)<32}})"0@":`. i'm sure it could be cleaned-up a bit. the following solution is better anyway, though:

[source,j]
----
ucs=:dfh '250c','252c','2510','251c','253c','2524','2514','2534','2518','2502',:'2500'
bdc=:a.{~16+i.11 NB. box-drawing characters
showboxes=:(8&u:) @: ((] (ucs{~])`(a.i.[)@.(11=]) bdc&i.)"0) @: ,@:((,&LF)"1)@:":
----

`showboxes` outputs a boxed display identical to what's seen in the j terminal, except that when writing the display to a file, it writes those actual box-drawing characters rather than non-displayable ASCII codes in the range [16,27]. it's defined of 3 parts from right to left:

. format input cells, append linefeed to each row, then ravel
. lookup character in `bdc`; if there then use that index into `ucs` to get the codepoint; if not there then use the ascii codepoint
. convert vector of codepoints to utf8

note that we applied `8&u:` at the end; applying it within the gerund (after `ucs{~]`) would cause the resultant array to have 3 columns since box drawing characters require three bytes but ascii characters do not.

other considerations:

. `9!:7` sets other ASCII-ONLY characters to replace the usual box drawing characters. the 11 *bytes* follow the same sequence as `,.(16+i.11){a.`. the simple one is `'+++++++++|-'`. i don't know of any other good ones.
. use `9!:37` to avoid printing ellipsis for long results.

NOTE: `format/sbox` does not produce output suitable for writing to files!

=== common designs

with all these primitives understood, this section considers how to systematically derive j programs tuned for speed, elegance, regularity, simplicity.

efficient codes:

* the i.-family:
  ** i.2
  ** i:2
  ** ~.1
  ** -.2
  ** ~:1
  ** u/.2
  ** e.2
  ** dyadic idioms:
    *** +/@:e.  NB. num in
    *** +./@:e. NB. any in?
    *** *./@:e. NB. all in?
    *** e.i.1:
    *** e.i.0:
    *** e.i:1:
    *** e.i:0:
    *** I.@:e.
    *** [-.-. NB. actually [-.!.0-. . tolerance specification syntax: x ([-.-.!.f) y
inner product: (x +/ . * y)
grade: [\/]:~ y and [\/]: y

* `i.`'s x is the search space and y is the array of query points (called a _probe_ in the j docs). y is an array of items of x. y is one less than the rank of x. this is b/c each item of y is mapped to a single index in x; this fact does not support e.g. `(i.2 3)i.4` returning `1 1` representing its multidimensional index in x. thus it returns `2` b/c that's `#x` and `4` is not an item of `i.2 3`.
* we get a funny thing if x is an atom and rank(y)>0: we get 1's (#x) for all items in y not equal to x, and a 0 for the ones that are equal.
* if y's rank is greater than x's then `i.` is applied to each of its items as per usual e.g.

[source,j]
----
   ]A=:6+i.10
6 7 8 9 10 11 12 13 14 15
   A i. 10 7 14 9
4 1 8 3
   A i. (2 2 $ 10 7 14 9) NB. same as (2 2 $ A i. 10 7 14 9) b/c (#$y)>:#$A
4 1
8 3
----

NOTE: use !.0 on numeric arrays with rank>1 or boxed arrays that contain numbers. use tolerant comparison on arrays that don't contain numbers (yes, it's faster.)

working with relations

i. & i: give 1st & last occurences. = or -: gives all. I. converts logical vectors into indices. when x is sorted, i. & i: return the least or greatest elements matching a predicate.

NOTE: when searching for strings in a boxed list, box the string! `('alpha';'bravo';'charlie')i.<'bravo'` is correct.

NOTE: `x e. y` is like x∈y whereas `x i. y` is like y∈x.

''''

i.2 e.g. (/: 'RrAa'&i.) 'AxryRz' => RrAxyz whereas /:~ 'RarA' => 'ARar'

* i.2 and {2 are association; one gets index from element; the other gets element from index.

=== loopless programming

* cf c, but also scheme, which is functional but over lists/trees instead of (multidimensional) arrays. compare with sql, too.
* discuss the nature of map (independent elts), fold (dependent elts), short-circuiting, multiple fns each with distinct return values e.g. the simultaneous existenece of `member?`, `list-ref`, `assoc`, ... and discuss why these are not present in j—namely because j uses masks, which is a single return value and is an array, whereas in other langs returning a whole array is expensive and thus each iteration tries to each consider & return as little information as possible; yet this has a inherent design flaws: 1. multiple traversals must be made in order to get multiple values; 2. each traversal is a separate function with a separate name. (1) can be avoided if we sacrifice elegance for efficiency by using manual recursion or complicated folds. also functions do not compose as easily as j primitives. furthermore, like c, j uses 0 & 1 for booleans and always uses numerically indexed arrays, cf. non-indexed linked lists whose mth elt has O(m) access and slightly worse modification complexity.

general theoretical consideration of loops:
all loops are traversals. they are symmetric operations of structures, expressing operations on substructures. structures are ultimately collections of atoms; the structure is the form, the atoms the matter. there may be a need to loop over atoms e.g. `while(x++<n){...}` (the structure here is natural numbers; remember that atoms are themselves structured, because the atoms are numbers, which permit equivalence classes, orders, and generally, algebraic structures). while & if are the same since they're both mere conditional jumps. structures may be (in)finite; regardless, we commonly want to relate substructures. there is commonly an index operator, which takes a literal index, for that purpose. loops are commonly used to identify that index. the index here refers to substructure, not just atoms like j's `{` or c's `[]`, but also substructures e.g. python's slice operator (`;.` in j). the question, then, is: what's the smallest & most elegant set of traversals that can identify all such indices?

* to select symmetric substructure, j deals with this by simply being an array language, i.e. every operation has map, and every verb has rank (which is always used with axis order, which is permutable by `|:`) i.e. subset (subaxis, specifically) selection.
* to identify arbitrary element subsets, apply (map) a function whose codomain is {0,1} or ℤ—a mask of whether each element belongs to the filtered set, or more generally, partition ids.
  ** often masks are applied via `#` to filter an array. otherwise `~.` filters an array in a particular way. `~.` is equivalent to hook `#~~:`
  ** there are special primitives for identifying singleton or empty sets: `i.`, `i:`, `e.`. these are not necessary; we can use set-theoretic operations instead. however, these primitives are efficient because they are short-circuting traversals and they also always return atoms, about which j can optimize.
* for traversals where elements are positionally related, j features `/`, `;.`
  ** traversals over sets (arrays whose order is irrelevant) are done by the same except that the argument verb must be commutative.
* for while/if, j uses `^:n` where n is 0, 1, (the choice of which determines whether to conditionally apply a function) or many times (as given by a constant or function that returns a boolean or integer) to apply a function multiple times.
* for conditionally executing code, j has the usual c-like control flow primitives e.g. `if.`, `while.`, &c

loopless verbs expressed as an s-expression: ((<classification fn app> `#` `~:`) ((`i.` `i:`) `e.`) (`"` `|:`) (`;.n` (`F.` ...) `/` `\`) (`i.~` `/.` `/..`) `^:` (`if.` ...)). that's 7 concepts, and the 2nd class is redundant of the first, included only for efficiency.

TODO: the "filter" classification may be inappropriate; consider #'s more general case, and put ~. & ~: with i.~ b/c they're for classification.

NOTE: key may be defined by `{{u&>y<@#~"_ 1 (~.=/])i.~x}}`. `i:~` would work just as well, since first/last are isomorphic and equal up to direction of traversal. note that `(~.=/])@:i.~` (as a hook: `(=/~~.)@:i.~`) is equivalent to monadic `=`. thus key may be simply defined as `(=x) u@# y`.

relating group ids by common indices is the single general way to relate data, which constitutes all programming except for traversals over the groups, and conditional execution. a specific case of group relation is relation of elements—each group is singleton. relating subsets of cartesian products is `join` [relalg].

this constitutes the total theoretical set of loops/traversals.

=== a basis

| lookup by index   | i.
| lookup by value   | {
| associate subsets | "
| fold whose dom has different cardinality from cod | TODO

=== systematically deriving j programs from relational schema

arrays are like views of relations. `|:` permutes the view. arrays relate data along axes, and relate relations of those relations, which implies that arrays relate axes. rearranging axes changes the substructure (cells) obtained by indexing into the arrays. cell substructure corresponds to string substructure, except that cells are definitely delimited whereas strings are not e.g. in ';cat bat hat;rat butt', the ';' marks the starts of cells, and each cell may be considered as a string or sequence of space-delimited strings or set of strings. each set of strings may be of choices, or may be a mandatory item followed by a variable sequence of augmenting data, or a mandatory datum followed by optional data,....

the relational model is the least constrained possible, so deriving programs from it starts with no assumptions. derivation is information-theoretic and maps from <exact program specifications expressed as relations> to structures that, per the program's needed subset selections, are most elegantly expressed by [j]'s primitives and hence must follow the structure that these primitives elegantly operate over.

TODO: when do we need `while` (corresponds to sql recursive cte)? how to choose [*select*] (if)?. cf sql notes.

== optimizing/efficiency

* <https://code.jsoftware.com/wiki/Vocabulary/SpecialCombinations#Execution_In_Place_.28EIP.29>
* SC's

== real-world j examples explained

=== a simplified example from the nuvoc for link:https://code.jsoftware.com/wiki/Vocabulary/barco#dyadic[rearrange axes]:

[source,j]
----
schools=:'s1';'s2';'s3'
grades=:9;10;11;12
sex=:'m';'f'
subject=:'cs';'sci';'lang'
props=:'p1';'p2'
]comp=:schools;grades;sex;subject;<props NB. `<props` instead of `props` b/c of `;`'s asymmetry: it doesn't box its right argument
┌──────────┬────────────┬─────┬─────────────┬────────────────────────┐
│┌──┬──┬──┐│┌─┬──┬──┬──┐│┌─┬─┐│┌──┬───┬────┐│┌────┬─────┬─────┬─────┐│
││s1│s2│s3│││9│10│11│12│││m│f│││cs│sci│lang│││#stu│prop2│prop3│prop4││
│└──┴──┴──┘│└─┴──┴──┴──┘│└─┴─┘│└──┴───┴────┘│└────┴─────┴─────┴─────┘│
└──────────┴────────────┴─────┴─────────────┴────────────────────────┘
NB. data =: ((}:@;@:((,&'_')) each)) each ({ (((({.@;:@":) every) each) comp)) NB. explicit ast form. the middle `each` is the root of this sentence's ast.
]data=:}:@;@:((,&'_') each) each { {.@;:@": every each comp
┌───────────────┬───────────────┐
│s1_9_m_cs_p1   │s1_9_m_cs_p2   │
├───────────────┼───────────────┤
│s1_9_m_sci_p1  │s1_9_m_sci_p2  │
├───────────────┼───────────────┤
│s1_9_m_lang_p1 │s1_9_m_lang_p2 │
└───────────────┴───────────────┘

<same as the prior 3 2 array but with f instead of m>


<same as the prior 2 3 2 array but with 10, 11, or 12 instead of 9>

<same as the prior 2 3 2 array but with s2 or s3 instead of s1>
----

i'll discuss the last sentence from its right to its left:

. `every each` in the repl evaluates to adverb `(&>)(&.>)`. we know that it's an adverb b/c (every each)0 error says `(adv noun)`.
  .. recall that `&.` is a conjunction. thus `&.>` matches the CV modifier train pattern which is equivalent to the conjunction whose right argument is bound. a conjunction whose left parameter only is free is an adverb.
  .. `&` is a conjunction, as specified in the error msg resulting from evaluating `0&0`. `&>` follows CV pattern and is thus an adverb.
. then `every each` matches the AA train pattern and is therefore an adverb whose parameter is applied to `every`.
. if we weren't to link `grades` into `comp` then `comp -: ]&.> comp` and `comp -: <&>&.> comp`. `{.@;:@":` basically does nothing; what it technically & actually does is converts numbers (namely `grades`) into strings. that's it. `":` converts to string, then `;:` boxes and adds an extra dimension, then we remove said extra dimension by using `{.`. all of this is ridiculous nonsense and i don't know why the example features it. we could easily have equivalently yet more clearly used `<@":` instead of `{.@;:@":`. in fact, *`data` is equivalently defined by `}:@;@:(,&'_'@": each) each { comp`. i've no idea why anyone wouldn't use that form.*
. unary `{` produces the cartesian product. you may be surprised that it's unary, rather than `... each` being its left argument. however, remember that `each` is an adverb; its left argument is applied, resulting in a verb; a verb cannot be the left argument of another verb; namely here `u&.>` cannot be the left argument of `{`. this exemplifies potential confusion entailed in parsing j's context-sensitive grammar. however, if you're familiar with parts of speech, as you must be to use j anyway, then parsing won't be tricky. this being said, spacing, parens, comments, and keeping sentences short help readability, and should be used appropriately.
. discussion of `}:@;@:((,&'_') each)`:
. `(,&'_') each` appends an underscore to each field
. `;` converts the boxed array to an unboxed array. a bit confusing how the unary `;` dual of dyadic `;`.
. `}:` drops the trailing underscore (the last character in the string i.e. last element in the character array)

TODO: this looks like a bug:

[source,j]
----
   ${.{.": every each comp

   {.{.": every each comp
┌──┐
│s1│
│s2│
│s3│
└──┘
   {.{.{.": every each comp
┌──┐
│s1│
│s2│
│s3│
└──┘
----

same behavior with `0{` instead of `{.`.

=== a tacit example of common complexity

taken from <https://code.jsoftware.com/wiki/Phrases/Indices_as_Base>.

`($ #: (i. <./)@,) A` where `A` is a noun. you may at first wish for help parsing this, but you won't after a little practice.

. fork (VVV train pattern) where the right V is `(<./)@,`. remember that `@` has highest precedence.
. unary fork b/c applied only to `A`; it's h(f(A),g(A)) where h is `#:`, f is `$`, and g is `(<./)@,`
. h & f are obvious. start considering g from the right (after you've parsed it from the left^*^): first it's unary `,` b/c g is unary b/c it's a part of a fork applied to one argument (namely `A`). `,` linearizes.
. then `(i. <./@,)` is a hook. it's unary b/c it's part of a conjunction (namely `@`) which is unary (being that `@` is the root node of g's ast and g is unary here). the hook expands to `(,A) i. <./,A`, which gives the index of A's least element.
. `dimensions #: linearindex` is the multidimensional index of a given linearindex. if you understand `#:` then you'll know why. see its documentation in this document.

^*^ you can parse trains from the left and/or right, for whatever's easiest. j parses from the right. i find that once i've identified a 3-tine fork i like to parse the left tine from the left and the right from the right. there's no reason for this; it just follows how my mind has learned to parse, based on geometric symmetry.

=== only in apl/j

TODO: discuss designs like finding last index at which x occurs in y: `>./@:I.@:=`

==== combinatorial coding

languages that generally use higher-order functions, such as haskell or factor, don't elegantly code combinators, because that model is too general to be elegant: it requires excessive quoting and currying of functions, by allowing any number of inputs to any function, impractically cumbersome tracking of arguments and nesting of functions (for functional languages), or tracking order that items are added to the stack (for stack langs).

by contrast, j limits its arities to 2. obviously functions must support at least 1 arity^*^ to encode a program (or more generally, a logical system). the limitation to 2 inputs and one output is wise because there's only one value to track as it moves through a computation, as opposed to multiple values of a stack. applicative languages, rather than having a "running computation" model, use a "composed computation" model where the total computation is expressed as a large tree of other sub-computations; except that that does not quite support all computations, so some horribly ugly local binding syntax is also introduced. haskell can be used as a combinatorial language, i.e. 100% point-free, but it's ugly, namely because it both 1. supports multiple function inputs and 2. generally considers two function types different, the two of which altogether imply that one must define multiple of versions of each combinator to support multiple arities—or conversely that one should use code only by unary, binary, or some few ternary combinators, which i support, and which is exactly what j's trains are!

^*^precisely: computations must allow specification of their inputs; an example here is x86 opcode inc which implicitly operates on eax; to specify that input one must execute a program that writes to eax. there are many ways to do that, the simplest being `mov eax immediatevalue`.

j's lack of generality (namely higher-order functions) is what _allows_ j to be powerfully elegant! it does not _make_ j elegant alone; the potential is realized by exploiting the fact that all things are binary or unary, and *words are always juxtaposed*, though parens may be needed to guard against greedy leftward application of words into adverbs.

tl;dr: j (or apls generally) is uniquely elegant for combinatorial coding because it:

. does not support higher-order functions symetrically (but uses special ad-hoc modifier train relation rules)
. limits arities to 1 or 2
. juxtaposes words to relate them—no extra syntax

usually symmetry is preferable, but j has used a brilliant mix of a/symmetry: the symmetry of unary & binary definition & application, yet the symmetry of them being the same for all parts of speech e.g. both verbs & conjunctions being monadic or dyadic. j isn't perfect, namely that adverbs don't accept their arguments on the right like monadic verbs do—yet despite that j is still exceptional. there's probably a reason for it, anyway: probably something about symmetry of how forks accept arguments or avoiding a glut of parenthesis on the right of an expression.

=== combining adjacent boxes

link:https://www.jsoftware.com/help/jforc/loopless_code_v_partitions.htm#_Toc191734451[from chapter 23 of j for c].

. verb `<@:~.@:;` exploits idempotence to effectively encode the conditional branches `c1:x->x;c2:x->f(x)`, namely where c1 is whether y is singleton and c2 is whether y is multiple. it thus avoids conditional devices `^:` or `@.`.

== coding with, vs without, boxing

=== example 1

boxed version from <https://code.jsoftware.com/wiki/Fifty_Shades_of_J/Chapter_07>. i easily translated into a flat version.

boxed:   `a.{~,|:65 97+&><i.26`
unboxed: `a.{~,(+&65 97)"0 i.26`

i think that the unboxed version is more obvious. the boxed version still produces a matrix but transposes before linearizing; my version uses `"0` instead of `every` then linearizes. `+` is already rank 0, so doing that to every boxed item is nothing special; there the boxes are an—i'd argue inappropriate—alternative to rank. my version explicitly maps the addition of two numbers, 65 & 97, to each in `i.26`.

to avoid framing fill of `a:`, box results then, at the end, raze them (`;`) e.g.

[source,j]
----
   A
┌─┬───────┐
│Q│3 5 6  │
├─┼───────┤
│B│1 2 8 9│
├─┼───────┤
│M│0 4 7  │
└─┴───────┘
   ]B=.({. ,./ <"0@>@{:)"1 A
┌─┬─┐
│Q│3│
├─┼─┤
│Q│5│
├─┼─┤
│Q│6│
├─┼─┤
│ │ │
└─┴─┘

┌─┬─┐
│B│1│
├─┼─┤
│B│2│
├─┼─┤
│B│8│
├─┼─┤
│B│9│
└─┴─┘

┌─┬─┐
│M│0│
├─┼─┤
│M│4│
├─┼─┤
│M│7│
├─┼─┤
│ │ │
└─┴─┘

   ]sol1=.(#~ ((a:,a:)-.@-:])"1),/B NB. works, but ugly compared to the next solution.
┌─┬─┐
│Q│3│
├─┼─┤
│Q│5│
├─┼─┤
│Q│6│
├─┼─┤
│B│1│
├─┼─┤
│B│2│
├─┼─┤
│B│8│
├─┼─┤
│B│9│
├─┼─┤
│M│0│
├─┼─┤
│M│4│
├─┼─┤
│M│7│
└─┴─┘

   ]C=.({. <@(,./) <"0@>@{:)"1 A
┌─────┬─────┬─────┐
│┌─┬─┐│┌─┬─┐│┌─┬─┐│
││Q│3│││B│1│││M│0││
│├─┼─┤│├─┼─┤│├─┼─┤│
││Q│5│││B│2│││M│4││
│├─┼─┤│├─┼─┤│├─┼─┤│
││Q│6│││B│8│││M│7││
│└─┴─┘│├─┼─┤│└─┴─┘│
│     ││B│9││     │
│     │└─┴─┘│     │
└─────┴─────┴─────┘
   sol1-:;C
1

NB. contrast with >C. unbox is raze except with framing fill:
   B-:>C
1
----

== particular addons/packages/libraries

as tested in j9.0.4

=== `web/httpget`

NOTE: `HTTP_Get` is, despite being in the j wiki, not available; it's deprecated in favor of link:https://code.jsoftware.com/wiki/Addons/web/gethttp[web/gethttp].

* running gentoo, uses cURL, HTTP/1.1 (connecting to a local server that uses haskell's warp)
* x=`'help'` just runs `curl --help category`. unfortunately specifying a category e.g. x=`'help http'` just fails to parse correctly; it tries to retrieve from a host called `http` rather than executing `curl --help http`.
* x=`'file'` writes to a file whose name is the last segment of the uri's path. no directories are created. curl fails with error 23 if no path is provided. (so yes, the `gethttp'http://www.jsoftware.com'` example is incorrect!)

=== link:https://code.jsoftware.com/wiki/Addons/tables/dsv[csv/dsv]

. `load 'tables/dsv'
. `(<recsep>;<string delim>) readdsv <path>`

== boxes

boxing avoids/defers framing fill.

| `;`      | like `,` except w/o framing fill
| `u&.>`   | apply u to each box's contents
| `u&>`    | apply u to each box then unbox, leaving framing fill to occur
| L. L: S: | TODO
| e.       | compare boxed elements against their raze. e.y is (;y)&e.@>y

TODO: consider:
[source,j]
----
   'hi' ,&:> 'there'
hithere
   'hi' ,&> 'there'
|length error, executing dyad ,&>
|shapes 2 and 5 do not conform
|   'hi'    ,&>'there'
   'hi' ,&> <'there'
hthere
ithere
   (<'hi') ,&> <'there'
hithere
   (<'hi') ,&> 'there'
hit
hih
hie
hir
hie
----

== is `i.` essential?

firstly, `i.` is advantageous over `#` only for sequences. it has no utility for unordered data. `i.` & `i:` are filter but rather than identifying all elements on an interval, they give the interval itself. as `i.` & `i:` expressly concern themselves with indices, they are only useful for traversing arrays in particular & arbitrary ways. `i.` (when equivalent to `i:`) is also good for, when used as an SC, efficiently implementing join [relalg].

. any vector `v` of natural numbers is implicitly interperable as a map from indices to indices
. if, given an array `a`, then if `v` is a rearrangement of `#a` then `v` is a permutation vector of `a`
  .. if `v` is the same but may contain non-unique elements then it's like a permutation vector of a but in a different way.
. relations are where the actual information is, not in functions that traverse those relations. `i.` gives the index of the first element matching the predicate `=&y`. it does short-circuit, but is useful only if a more general predicate has already been computed. `i.` relates values to indices in an array, seeing the array as a relation of indices and values, `a(i,v)`. `i.` looks-up index by value, whereas `{` looks-up value by index. these are the same form in sql: `select i where v=V`vs `select v where i=I`. seeing as a(i,v) is equivalent to `i join v using (row_id)`,...rather we commonly do, given `a(i,a)` and `b(i,b)`, `a join b using (i)` to combine a & b, which is just `,.` in j, but only because indices are special in j but not in sql! again, sql joins are more powerful because they aren't as constrained by indices' uniqueness.
. in scalar langs you'd use predicates and structure indexing inside a loop, whereas in array langs you express these as intersections and filters.
. `&.:~.` is an interesting idea~

actually, when, if ever, is `i.` even more efficient? consider `({~{.@:I.@:(>&7))` which applies the predicate to the whole array first and is theoretically O(n) anyway, so `i.` getting the 1st element is dumb anyway; the the first 1 index (`{.@:I.`) is what we want anyway! i'd be just as well doing `({.@:#~(>&7))` would be just as well. AH! i was going to use `i.&1` to get the first `1`.

cool use of `i.` as map:

[source,j]
----
NB. buy, sell, and exit are functions of an input order
NB. a single character, to buy, sell, or exit a stock trade, is stored at index 4 of an order array.
   {{(('bse'i.>1{y){+:`%:`*:)`:0 >{.y}}          NB. explicit
   ({. ([ {{y`:0 x}} +:`%:`*: {~ 'bse'i.])&> {:) NB. tacit! actually works! just another fork.
2
----

== common shell stuff

| list directory | `1 dir <glob>`
| operate on file line-by-line | `<f>;._2]1!:1<<path>`

== conditional function application patterns

| description | code | note
| slice [0:e] where e is an array element | `(i.&e{.])` | uses e as an index rather than an integer index; if e not present, then takes to the end.
| for each | (;@:(I.@:E.&.>) {."0 _ >@])

== avoiding antipatterns

i.e. noticing to use more elegant primitives before writing code that snowballs into a mess that you only realize after it's written that it could have been written much more elegantly by using different primitives.

here's an impressive yet terrible example of splitting a string; it's terrible b/c i should've used `;.1` instead of `,:/@:2&]\` with `;.0`:

[source,j,]
----
   ('my';'friend';'you') (,:/"1@:(2&(]\))@:;@:(I.@:E.&.>) <;.0"_1 _ >@]) <'hello there my friend how are you today? are you well?'
┌───────────────┬──────────────────────────────┬────────────────────────┐
│my friend how a│friend how are you today? are │you today? are you well?│
└───────────────┴──────────────────────────────┴────────────────────────┘
----

naturally this happened because i did not use a systematic method for identifying elegant solution codes. i yet see 2 solutions to this:

. optimized multi-parameter codes e.g. sql's select form. there's no choice here; if you want information, you're using `select`. it's the only thing that does any remotely related to data selection/access or just returning any expression at all! when there's no choice, there's no possibility for bad choices. under-the-hood optimization takes care of that concern, and optimization is much more affordable when the thing to optimize is so constrained, so unvaried.
. 

choice is the elegance-killer. elegance is, in its greatest form, most elegant, i.e. optimized. the only way to consistently get that grade of quality is by systematic reasoning, which means that the reasoning is encoded in the algorithm that the coder uses—not in the coder's mind. there's a reason that people used paper and then computers: people are volatile yet want consistent reasoning and the correct results that follow. taking this to its ultimate conclusion, we see that people's perogative is to provide facts in the form of data and queries, and for computers to answer. sounds like prolog, huh?

.aside: "why not just use prolog, then," again?

try to use the most capable primitives first, which i bet are typically less finely specifiable, but only when they fail should we try less powerful (and assumedly more finely specifiable) ones.

recall array primitives:
* rearrange axes:: |:
* reshape: $ ,. n&]\ ,: NB. $ is the true primitive
* flatten/append:: , ; NB. flatten is just append with fold
* subarrays: ;.n{. }. {: }: NB. ;.0 is the true primitive
  ** NEXT: consider the relation, if any, between subarrays (x;.3y) and subarray (x;.0y). also note that ;.[_][12] is subarrays but 1. no loss of information except optionally delimiters; 2. no overlap among subarrays.
* reorder: ;.0y |. |.!.f { NB. reorders are relations of indices, not of elements(' values)
* apply aggregate fn: / \ \. /. /.. F:.
  ** TODO: this needs exposition e.g. how \ generates a triangular array and the consequences of that for combinatronics
* un/box: > <

accessors (queries, or more generally as in prolog, binding parts of a relation then calculating the total set of statements which satisfy the partially-bound (and thus also partially-free) relation):
* {
* I. NB. for RANGES. cf. sequences or sets of computationally unrelated elements. I. is an interesting primitive because it entails both structure (sequence, namely an arithmetically ordered one) and elements' computable values. uses binary search!
* i. i: unary, indirectly useful for generating indices, e.g. 100+i.20 to mean the slice [100,120]. not sure if this is actually ever done in j. TODO: which primitives accept indices, and how does each of them accept indices?

mask/index generators:
* <predicate application> or, more generally, <group generator application>
* i.~ i. i: ~: NB. ~: is ordered whereas i.~ is unordered, the grouping accomplished by an injection: that equal elts have the same output for `y&i.`. TODO: cf i. vs i.~
* I. NB. not a true primitive; equivalent to (# i.@:#)~ i.e. it uses y as an inclusion mask on i.y
* E.
* /: \: NB. grade should be used have been only a unary primitive.

TODO: organize primitives [complete classification] into a db then export that to an [html] with color-coding. subclasses: coding primitive, ordered? (seq|set), arithmetic|relational, join|split|rotate; boxed?

"truvoc:" the true structural primitives, remembering that j is an array lang (so e.g. \. is a primitive even though we could accomplish the same by using a loop or ^: because it acts on the whole array rather than on one element at a time):

[options="header"]
|============================================================================
| fn    | description         | class                         | implementation
| $     | shape               | shape                         | -
| \|:   | rearrange axes      | shape                         | -
| >     | unbox               | shape                         | -
| /:y   | grade               | elements                      | -
| /.y   | group               | elements                      | -
| x{    | query (_,value)     | query                         | -
| x i.  | query (value,_)     | query                         | -
| ~:    | nub                 | mask                          | none, right?
| x;.0  | subarray            | subarray                      | <see note below>
| ,     | append              | <see note below>              | -
| F:.   | relate elements     | subarray                      | -
| E.    | subarray index      | subarray, mask                | -
| x I.  | binary search       | optimized by exploiting order | -
| #y    | get count of list   | ?                             | {.@$
| x#    | set count of elts   | ?                             | `;@:(([ ,. $"_1@:]) <@$"_1 ])` or `;@(([ <@$"0 i.@:#@:[) {&.> <@])`
| i.y   | [0..y)              | mask                          | (<:@:(+/\)@:$&1)
| \|. y | reverse list        | ?                             | smth with i. & {
| ;.0 y | reverse axes' items | ?                             | smth with i. & {
|============================================================================

class descriptions:

* _reshaping_ changes shape not elements
* _changing_ elements changes elements but not shape
* _query_ subsets without delimitations
  ** _subarray_ is a subset defined by an interval; one only must specify the bounds rather than all the elements. however, one is limited to only accessing the bounds. a more powerful version (though perhaps slower) for bounds `(a,:b)u;.0 y` is `(a+i.b){y`, whose control argument may be modified e.g. `(#~-.@:(2&|))(a+i.b){y`; *masks are more versatile than anything else because they can be arbitrary arrays; they're permitted as full generality as possible [sensible for the primitive to which they're a control argument].* *subarray ops are for efficiency or convenience only*.
    *** thus subarrays are in the _interval_ class, too!
  ** _masks_ are delimitations and are always used as inputs to queries

[NOTE]
* `>` & `;` are alternatives; `>` fills whereas `;` does not
* `;` & `<` are dual; `>` has no dual.
* `;` & `,` are similar only insofar as they both remove structure: `;` removes box structure and `,` removes shape structure

subarray note: though subarrays express intervals, they do not accept intervals as arguments! they accept a multidimensional index and multidimensional length!
good subarray example: `(1 2,.1 2,.0 3) ];.0 i. 4 3 4`. `1 1 0` is the index; `2 2 3` is the shape of the subarry to take (and thus the shape of the result here, since we're using `]` which does not alter shape). it's equivalent to something like `0 1 2 { 1 2 { 1 2 { i. 4 3 4`. apparently it's not so simple. the convenience is non-trivial.

NOTE: truvoc is good for reasoning and program derivation. however! one must translate resultant code back into efficient primitives by noticing which invariants may be exploited e.g. using `;.0` instead of `i.` & `{`!

TODO: is the _elements_ class appropriate? elements are rank-0 arrays, which suggests that they have trivial axes, but axes nonetheless. well, though, it still connotes that, given an axis, it permutes the axes' elements, as opposed to changing the shape of the array! i.e. `$&.u` is constant for all u of the _elements_ class!

`,` may be of the subarray class even though it's dual to subarray; morphism direction does not affect my classification, as i see all morphisms as relations, and relations' attributes are unordered. in prolog, appropriately, append & split are the same relation. duality is always implicitly available simply by changing which of the relation's attribute is free vs bound. `,` may instead be of the rearrange class since it doesn't add any new information but changes the shape of its inputs. it's an odd primitive.

verb application, namely regarding how their ranks specify over which subarrays they're applied, is its own primitive. the rank conjunction is thus implicitly a true primitive. `|:` exists solely to work with `"`.

* `F:.` (isomorphic with recursion, which is isomorphic to iteration with a call stack or many general data stacks) is the de facto way to relate elements of a common subset, subsequence, axis, &c
  ** if you want to act on arbitrary subsets rather than elements, then you just identify the subsets first then fold over them: `vF:.w@:u;.n`` vF:.w@:u/.` or w/e.

special notes:
* forms which accept dyadic verbs are the only primitives capable of relating elements along an axis (as opposed to dyadic verbs obviously relating their two inputs); namely they relate elements by their argument relation(s) `u` and possibly `v`. forms which do not accept verb arguments can only change selection or modify elements individually.
* foldr is recursion. foldl is iteration. if you can reverse order of computation then you've just made a recursive design iterative. the defining property of recursion is accumulating an ast/call tree then evaluating it from its leaves first
* `x` can encode the traversal for `^:u^:v` over `y`. recursion schemes encode the same information as data structures: the traversal. still any graph or isomorphic table/relation can be traversed by any function that takes the current set of points/rows and returns a set of nodes to traverse next, with the empty set being the end of the traversal.
  ** by this design there's no need for "short circuiting" as a particular consideration; just have the loop body include a choice one of which is `0$0`. _choice_ generalizes `if` from its usual restricted form to one of querying a relation `c(cond,val)`.

NEXT: the most obvious (i.e. "the first thing to") consider is the number of items in a relation (namely the number inputs of since all j fns have one output), which should be a direct representation of their information content b/c anything else would imply either redundancy or bringing-in new information from <somewhere>. for functions that take in the same inputs give different outputs? what does that say about the structures that they operate on? for example, if the control arg `x`'s order is irrelevant then the operation is a set operation, not a sequence one. if `x`'s order matters then each `x` corresponds to an item in y, but if `x` is computed from a commutative relation e.g. `=` then the inputs to generate `x` do not need to be ordered. my point is that, like rank [conj], there are asymmetries across symmetries (and maybe vice versa if that makes sense to suppose) which is another way of saying that all sets of data have, under a given consideration, some factorability of information or not i.e. things which must be preserved or not but *that's really just applying the consideration's essential invariants to its data inputs.* all non-invariants are variants i.e. dof.

_partitions_ are maps from a set to a collection of subsets, which may or may not overlap depending on how you choose to define "partition." i prefer to say "subsetting" which everyone agrees maps S to any set of sets none of whose elements are not in S. consider that definition precisely & carefully. i also consider all elements of sets to be arrays, though j does not e.g. `$'a'` is empty whereas `$'ab'` is 2; obeying symmetry, `$'a'` should be 1. anyway, then `u;.0` and `u/.` subset by indices and group id equality respectively. given that equality is commutative but subarray indexing is not (i.e. a=b <=> b=a yet x[a:b] is not generally equal to x[b:a], if the latter is even defined). note that `u;.0`'s x does not take start & end indices; it takes start & length; if the length is negative then it's run as though it were positive except that that result is reversed. regardless, *both `x u;.n y` and `x u/. y` apply a function `u` to each subset given by selection mask `x`*.

NOTE: for `y[a:b]` (cf what ;.0 does: `y[a:a+len]`) use `({&y)@:([+[:i.-~)`

i assume /: as the canonical isomorphism of /: & \:, and likewise for F:. of its family union {\. \}, and , as the canonical representation of ; and i. of it and i: .

grade:

[source,j]
----
NB. a relation of items with the indices at which they should appear. relation of a factored form.
   ]A=:(<"0'QBM'),.3 5 6 12;1 2 8 9;0 7
┌─┬────────┐
│Q│3 5 6 12│
├─┼────────┤
│B│1 2 8 9 │
├─┼────────┤
│M│0 7     │
└─┴────────┘

NB. note that some indices are missing, but none appears more than once
   /:~;{:"1 A 
0 1 2 3 5 6 7 8 9 12

NB. distributed form of relation, as we'd expect to see it in sql.
   ]B=.;({. <@(,./) <"0@>@{:)"1 A
┌─┬──┐
│Q│3 │
├─┼──┤
│Q│5 │
├─┼──┤
│Q│6 │
├─┼──┤
│Q│12│
├─┼──┤
│B│1 │
├─┼──┤
│B│2 │
├─┼──┤
│B│8 │
├─┼──┤
│B│9 │
├─┼──┤
│M│0 │
├─┼──┤
│M│7 │
└─┴──┘

   B/: {:"1 B NB. this almost gets us what we want, but still has indices 4, 10, & 11 missing, so ;{."1 B would be incorrect.
┌─┬──┐
│M│0 │
├─┼──┤
│B│1 │
├─┼──┤
│B│2 │
├─┼──┤
│Q│3 │
├─┼──┤
│Q│5 │
├─┼──┤
│Q│6 │
├─┼──┤
│M│7 │
├─┼──┤
│B│8 │
├─┼──┤
│B│9 │
├─┼──┤
│Q│12│
└─┴──┘

NB. solution, analagous to left/right join in sql: add missing indices with associated default value to original array, then do the above computation:
   ((]-.~[:i.[:>:>./)@:;@:({:"1)) A
4 10 11

NB. the whole computation which uses that computation to get indices:
   ]Ap=.(,('*';(]-.~[:i.[:>:>./)@:;@:({:"1))) A
┌─┬────────┐
│Q│3 5 6 12│
├─┼────────┤
│B│1 2 8 9 │
├─┼────────┤
│M│0 7     │
├─┼────────┤
│*│4 10 11 │
└─┴────────┘

NB. using Ap instead of A to get the correct result:
   (>@:{."1@:(/:{:"1)@:;@:(({. <@(,./) <"0@>@{:)"1)) Ap
MBBQ*QQMBB**Q
----

this demonstrates that, for ordinal `x`, `y/:x` means "x specifies y's positions in output." this is a bit interesting when you consider that `y/:x` is equivalent to `y{~/:x`. furthermore, consider how `/:` is akin to join in sql:

[source,sql]
----
create table t(char string, idx integer);
insert into t values('Q',3),('Q',5),('Q',6),('Q',12),('B',1),('B',2),('B',8),('B',9),('M',0),('M',7);
select * from t;
┌──────┬─────┐
│ char │ idx │
├──────┼─────┤
│ Q    │ 3   │
│ Q    │ 5   │
│ Q    │ 6   │
│ Q    │ 12  │
│ B    │ 1   │
│ B    │ 2   │
│ B    │ 8   │
│ B    │ 9   │
│ M    │ 0   │
│ M    │ 7   │
└──────┴─────┘

-- right join is join but where there's a value without corresponding idx, then
-- the selected attributes of the left table (namely char & idx here) assume null values
-- and the rows are still included in the joined output.
select * from t right join (generate_series(0,12) join (values('*'))) on value=idx order by value;
┌──────┬─────┬───────┬─────────┐
│ char │ idx │ value │ column1 │
├──────┼─────┼───────┼─────────┤
│ M    │ 0   │ 0     │ *       │
│ B    │ 1   │ 1     │ *       │
│ B    │ 2   │ 2     │ *       │
│ Q    │ 3   │ 3     │ *       │
│      │     │ 4     │ *       │
│ Q    │ 5   │ 5     │ *       │
│ Q    │ 6   │ 6     │ *       │
│ M    │ 7   │ 7     │ *       │
│ B    │ 8   │ 8     │ *       │
│ B    │ 9   │ 9     │ *       │
│      │     │ 10    │ *       │
│      │     │ 11    │ *       │
│ Q    │ 12  │ 12    │ *       │
└──────┴─────┴───────┴─────────┘

-- basically the solution
select coalesce(char,column1) as v -- `coalesce(x,y)` means `if x then x else y`
from t right join (generate_series(0,12) join (values('*')))
       on value=idx order by value;
┌───┐
│ v │
├───┤
│ M │
│ B │
│ B │
│ Q │
│ * │
│ Q │
│ Q │
│ M │
│ B │
│ B │
│ * │
│ * │
│ Q │
└───┘

-- make output display just the string without the column name
.mode csv

-- the actual solution
select group_concat(v,'') -- this outer group_concat selection is like ,/ in j
  -- this parenthesized query is the basic solution from above
from (select coalesce(char,column1) as v
      from t right join (generate_series(0,12) join (values('*')))
             on value=idx
      order by value);
MBBQ*QQMBB**Q
----

you'll notice that `12` was a constant that i supplied to `generate_series`. i could get its value by selecting `count(*)` in a `with` clause, but i'm not going to bother with that; the point of the example is to demonstrate the relation between `[left/right] join` and `/:` as `y{~/:x`.

NEXT: refactor to avoid boxing, and to exploit common indices. the simple C solution is to use a loop (or fold) with `or`: `i∈ >:i.>./;idx , out[x]=(indices i.i){letters,'*'`
NEXT: confirm & make exactly correct: `y/:x` is just `(i.#y);.y [left] join (i.#x;.x) using (idx) order by x.val;`.

NEXT: also, elsewhere, i need to cover:
* ^: wrt <something of a recent example i think>
* how prolog doesn't much nest horn clauses but instead sequences them, and each body is a sequence of co/prod'd predicates. in j wouldn't this just be local binds e.g. `(A ,./&.> B)[B=.|:@[A=.i.@:>:@]`? b/c each horn clause has variables local to it just like each sentence in j has variables local to it, and each horn clause is built on the others, whereas in j each leftward subexpr has the vars introduced earlier in the sentence's evaluation, and evalutation in j is just reduction rather than unification. really, tacit, or any code generally for that matter, should not be nested any more that 2 (or 1?) levels deep.
* binary and & or can be <. & >. instead of +. & *. .

consider ergonomics of nested vs non-nested structures e.g. prolog's quicksort:

[source,prolog]
--------------------------------------------------------------------------------------------
qsort( [], [] ).
qsort( [H|U], S ) :- splitBy(H, U, L, R), qsort(L, SL), qsort(R, SR), append(SL, [H|SR], S).

% splitBy( H, U, LS, RS )
% True if LS = { L in U | L <= H }; RS = { R in U | R > H }
splitBy( _, [], [], []).
splitBy( H, [U|T], [U|LS], RS ) :- U =< H, splitBy(H, T, LS, RS).
splitBy( H, [U|T], LS, [U|RS] ) :- U  > H, splitBy(H, T, LS, RS).
--------------------------------------------------------------------------------------------

vs the equivalent in j or other common langs.

== the systematic technique for coding logical systems (including programs) in terms of logical relations

. what information do you want?
. which it a subset of: a datum (e.g. json object) or abstract set (e.g. the set of primes)?
  .. this tells which primitve to use: one that strictly subsets, or one that adds new information
. which _information_ do you want? do you want it with delimitations or not? e.g. selecting a subarray would not see the subarray with delimitations, but selecting multiple subarrays (by e.g. `u;.1`) delimited by a delimiter (e.g. `';'`) would see the result as multiple, separate data, and `u` may either preserve their distinctness or not.
  .. restructuring does not change the information present in an object and is thus a separate concern!

unary primitives are not relations and hence don't relate/accumulate information. you could phrase it as `y` always being the accumulator and considering whether a primitive adds information from `x` into the accumulation. even `$` relates `x` & `y` and thus returns a datum that contains information of both `x` & `y`. the only primitive that adds information to a program is roll! in fact, generally the only routines that can add information to a program, which the user does not specify, is the random function. it is _the_ function for attaining information neither specified statically, dynamically, nor by relation to any other computed data.

each array has distinct classes of information: shape and elements. reshaping does not change information. remember that relation itself is (abstractly) what has the information. in practice, numerical values have information, though they are conceptually relations of units. the only reason, then, that we restructure is as a form of reencoding so that the primitive that we pass the array to can decode it properly. thus we have encoders/reshapers, . for each primitive we must consider whether it acts on shape vs elements, and if on elements, then if it relates elements (thus mandating that it be an adverb which takes a binary operation) and if so, by which axes it does; does it relate elements along one axis, or does it relate all elements along all axes? this is closely related to, but not identical to, rank, i think; maybe they are equal. for example, F:. relates elements of a list; if we do F:."r then we may select the elements to be k-cells. this is similar to how many operations can be described as folds over a list; all we must do is reshape the data into a list.

so the question is simple: where's your data located? how do you extract it wrt axes of symmetry and preserving distinctness or not? e.g. ;.1 sees all returned items distinct but related by adjacency; and /. preserves distinctness along axis of equality i.e. all items in each subset are equal to each other and thus not equal to any items of any of the other subsets; and `{` may take `x` to be a multiset; and .

now that we know the true primitives, let's consider 

I. and ;.1 and / entail the concepts of relations of binary relations e.g. that (a,b) may be extended to (a,b,c) such as if a & b were start & end delimiters, then what remains after b may be so split again. this is common in functional programming: that we take a subsequence, perform a computation on it, then cons it to the result of this whole recursive function on the remaining sequence. recursion is the _traversal form_ of self-similar _data_ structures. recall that all "static" data structures come to exist by some constructor function; thus the function and resultant structure have the same information.

NEXT: consider primitives as prolog-style relations (appropriate generalizations of relalg schema/relations). these forms are most general, computable, and perfect; they are literal, unadultrated essential truth, by no introduced structure despite the common prolog notation. only by relations can we perfectly reason about arranging primitve relations in order to ultimately compose a logical system. relational-logical model enables simultaneously the set-theoretic and first-order-propositional perspectives, freely allowing one to intersect sets and predicates (both generally the _product_ operation [category theory]). we see defining properties, freedoms vs constraints, a/symmetries, easily. these naturally easily permit classifying & sequencing relations [operations] by factoring their common constraints, including common axes of symmetry. we then map the simplified composite relation to primitives of the system that we're using. summary:

. encode primitive relations (e.g. j primitives) into prolog-style relations
. arrange into 
. simplify by:
  .. canonicalizing expressions (e.g. ordering or reshaping all expressions into common order/form)
  .. applying simplification rewrite rules (e.g. eschewing redundancies, or reducing redundant compositions of relations)
  .. factoring a/symmetries / common constraints
. decode composite relation to relations of system primitives

* `#` is the de facto inclusion mask applicator
* `/.` is the de facto classification mask applicator
* `}` is the de facto choice mask applicator, though it accepts the mask as an adverb argument

usually we consider either sets or sequences, but quite less often do we consider multisets.

accessors parameterized by indices are binary relations between arrays & subarrays. this statement summarizes j aside from its arithmetic, foreign, reflective, and io functions, and its trains.

== an unsophisticated method for writing terse, efficient code

this is basically a list of primitives, grouped by utility, ordered with most specific (most convenient & efficient yet least flexible) primitives first. simply look at the most powerful & fastest primitives; if you can use them then do; else look to the next-most powerful & fast primitive that serves the same need. basically go down the list and select the first primitive that you can use!

=== god's kludge

[quote,j's page on special combinations]
----
Note: Partitions `(x u/. y)` are processed through the same code as `(x u;.1 y)` and inherit its special code as well. 
----

use these few efficient, powerful primitives; they make writing elegant, terse, efficient code brainless, which means rapid software development. these primitives form a basis for logical/programmatic systems:

| `x { y`            | subsequences by index mask. the most general, powerful selector. x may be unboxed, but that can select only items of y; for multidimensional indexing, x must be boxed. the boxed form generalizes the unboxed form: `(a,b,c){y` is equivalent to `(a;b;c){y`. because it's more powerful, i'll consider only the boxed form. each item of each box is an axis' index e.g. `(<0 2){y` is equivalent to `2{0{y`. if multiple axes are boxed together, e.g. `<a b;c d e`, then each item of the box is still an axis; thus a & b are indices of axis 0; then c, d, & e are indices of axis 1. suppose that `y` is a matrix. then this specification returns a 2 3 array whose first row is items of the ath row, columns at the cth, dth, and eth indices; and whose 2nd row is the cth, dth, and eth items of the bth row. see example below.
| `x u/.. y`         | subsequences by equivalence mask. preserves element adjacency only per class. works on sequences with non-adjacent subsequences. not just subset! partitions are evaluated in order given by `~.x`, and each partition's elements' order matches that of `y`
| `x u;.[12] y`      | irregularly-sized sublists by boolean split mask. preserves element adjacency.
| `x u;.[03] y`      | [regular] subarray(s) by hyperrectangle [and movement vector]
| `x u F:. v y`      | relate elements of a common axis
| `$` `"` `|:` `, y` | specify axes/subarrays/symmetries or k-cells
| `/:`               | order

.`{` generalizes `;.[03]`
[source,j]
----
   ]A=:5 5 $ a.{~65+i.26
ABCDE
FGHIJ
KLMNO
PQRST
UVWXY
   (<(2+i.3); >:i.4){A
LMNO
QRST
VWXY
   (2 1,:4 4) ];.0 A NB. equivalent to (2 4,.1 4)];.0 A
LMNO
QRST
VWXY
----

.advanced `{`
[source,j]
----
   (<2;3){A NB. same as (<2 3){A ; i don't understand how. however, (2;3){A is same as (2 3){A , which makes sense.
N
   (<2 3;0 1){A NB. items at indices 2 & 3, then for each of those, items at 0 & 1.
KL
PQ
   (2 3;0 1){A NB. x is 2 items: (<2 3) and (<0 1); each item specifies 2 axes
NB
   (2 3;0){A NB. same but some (1, namely the 2nd) of the selector's axes is omitted, which makes it select all along those axes [that axis]
N    
ABCDE
   (<(<2 3);0){A NB. x has one element of form A;B where A is boxed; thus A is a blacklist rather than whitelist. B is not boxed, so it's still a whitelist. A selects from the 0th axis, B from the 1st.
AFU
   (<(<2 3);<<0){A NB. i.e. (<(<<2 3),<<0){A
BCDE
GHIJ
VWXY
   (<a:;<<0 4){A NB. mnemonic: a: for "all". all of the 1st axis, all but 0th & 4th of the 2nd.
BCD
GHI
LMN
QRS
VWX
----

you'll probably want to use fetch (`{::`) as a more ergonomic multidimensional select, especially if you're unboxing! this being said, if there is no unboxing to do, then it's still more ergonomic!

note that the same selection works for amend (`}`) also:
[source,j]
----
   i.3 4
0 1  2  3
4 5  6  7
8 9 10 11
   (<a:;2){ i.3 4 NB. all of 1st axis, only 3rd index of 2nd axis
2 6 10
   100 (<a:;2)} i.3 4 NB. set those to 100
0 1 100  3
4 5 100  7
8 9 100 11

NB. apply *: to 3rd column, because the x arg to amend is 2. x f`g`h}y is (x f y) (x g y) } (x h y).
   2 (*:@{"1)`([:<a:;[)`]} i.3 4
0 1   4  3
4 5  36  7
8 9 100 11
----

for tables, selecting columns is best done by `x&{"1`. for deeper structures, boxed select can be better. of course if you need blacklist selection then boxed select is best.

NOTE: ;.[12] accepts x with multiple rows as a convenience; the split is done independently per row then assembled together.

classes: masks | binary relation application | modified binary or unary relation application | shape (which merely encodes the information's symmetries)

rank conveniences: `.` `/` `

subarrays: //q's: overlapping? one or many?

. `u;.0` single subarray, independent axes. use control argument `(a1 b1,.a2 b2,.)`
. `u\` subarrays, overlapping if x>0, non-overlapping if x<0. *use only in SC's; generally prefer `u;.3`. it's faster and more capable.*
. `u;.3` *regular* subarrays, the amount of overlap is given by size minus movement; negative overlap means skipping elements.
. `u;.[12]` *irregular* subarrays
. `{`

equivalents at least where y is a vector:
* `(1,:x) u;._3 y` `x u;._3 y` `x u\y`
* `n u;.3 y` where n<0 `u@:|.\. y`
* `{.@:(u;._3)` `u;.0`
* `(u;.2~ (0=n|[:>:[:i.#)) y` `n u\y`
* `(-n)\y` `(<.(i.#y)%n)]/.y`
`u;.3` permitting generalization. `u;.3` `u;.0`

we see that the less particular a form, whether it be as a structure or operation, then the more interpretations it permits. the more particular/complex the form, the fewer interpretations it permits, which makes choosing primitives over it quite easy. we should choose primitives that are extremely elegant & efficient over arbitrarily-dimensioned data whose elements have particular relations; this allows us to store particular relations across an arbitrary number of axes of symmetry, while making the encoding (assembly) & decoding (applying a primitive) thoughtless [easy]! this is what makes sql so easy to use.

=== my solution to the k-combinations problem

k=3. to choose k from n, have a k-column partially-filled-matrix:

a b c    a c d    a d e
    d ->     e -> 
    e

we remove the 2nd item until there is only one row. to get actual values, fill downward...:

a b c    a c d    a d e
a b d -> a c e -> 
a b e

then concatenate:

a b c
a b d
a b e
a c d
a c e
a d e

those are all the combinations of size 3, from `'abcde'`, containing `'a'`. to get all nCk, this verb that as an argument to suffix (`\.`) i.e. get the 3-combos of `'bcde`' containing `'b'`, then when we consider input `'cde`', we return it because its tally equals k.

having removed the head, `'a'`:

b c d -> b d e
    e

then fill & concatenate:

b c d
b c e
b d e

having removed the head, `'b'`:

c d e NB. base case: input is output

full result: the append of all suffixes:

a b c
a b d
a b e
a c d
a c e
a d e
b c d
b c e
b d e
c d e

there you have all `3!5` (10) combinations.

note that

-----
a b c
    d
    e
-----

is `'a',.((<:k) nCk y)'. this basically defines the general case of k-combinations in terms of (k-1)-combinations. you can say that it's `((<:k){.y),"1,.(<:k)}.y`. probably only one of these is correct but w/e i don't care yet.

=== some funny power (`^:`) examples

NOTE: `^:_1` works for some considerable class of tacit expressions! it will derive the inverse! tacit expressions involving `/:`, `/` can't be inverted.

[source,j]
----
NB. scan version of 3 (9&,) 1
   3 ([: 9 , m f ])^:(<@[) 1
1 0 0
9 1 0
9 9 1

NB. variation on dyadic bond (&) conjunction
NB. on each iteration, <applies u> x times
   3 (9&,)^:(<@[) 1
1 0 0 0 0 0 0
9 9 9 1 0 0 0
9 9 9 9 9 9 1

   +:^:<: 6
192
   +:^:< 6
6 12 24 48 96 192

   +:^:< 5
5 10 20 40 80
   5 +:^:< 5
5
   6 +:^:< 5
5
   4 +:^:< 5 NB. 4<5 but can't execute +: b/c it's dyadic form accepts only booleans, not integers
|domain error, executing dyad +:^:<
|   4    +:^:<5
   4 +^:< 5
9
   5 +^:< 5
5
   6 +^:< 5
5

NB. accumulate random numbers until 10 is enlisted
NB. omitting the @] will cause out of memory error
   20 (?@[,])^:(10~:{.@])^:_ (0$0) NB. better version (,?@20"_)^:...
10 16 7 3 7 16 7

NB. erroneous use of power as do-while: it stops either on encountering 10, which is what we want,
NB. but also stops if it happens to encounter the same random number consecutively—the convergence behavior!
   (?@20"_[echo)^:(10&~:)^:_] __
__
15
7
12
9
9

NB. running again, and this time happens to exit on the condition that we desired
   (?@20"_[echo)^:(10&~:)^:_] __
__
2
8
10
   (?@20"_[echo)^:(10&~:)^:_] __

NB. solution: attach dummy incrementer to avoid convergence.
NB. echo used to output the random number for that iteration and the iteration number.
   ((?@20"_)`>:"0 [ echo)^:(10~:{.)^:_] 0 0
0 0
18 1
4 2
8 3
8 4
4 5
19 6
18 7
14 8
5 9
19 10
2 11
19 12
9 13
9 14
9 15
10 16

NB. almost surely returns 10 and the number of rolls needed to roll a 10 from a 20-sided die
   ((?@20"_)`>:"0)^:(10~:{.)^:_] 0 0
10 31

NB. this verb is an SC. each item in x gives the next position to look-up. this map is:
NB. 0 3
NB. 1 1
NB. 2 4
NB. 3 5
NB. 4 1
NB. 5 2
NB. loop terminates at the index equal to its value, which here is 1 at index 1.
   3 1 4 5 1 2 {~^:a: 0
0 3 5 2 4 1

NB. i'm curious how this would be used, why there's an SC for it.
NB. "Produces list of starting positions, the first being y. Each x-value is the place the next record would start, if a record starts at that x. (If the first value in each record is the length, x would be (list + i.#list)"
----

the version that accumulates a list never exits due to convergence, because it necessarily enlists a new element, and no array is ever equal to itself with another item enlisted.

.insert (`/`)

i like to call this the "relate" primitve because it applies a binary relation to elements.

insert has a fucky-wucky asymmetry. it's depicted plainly in the following example:

[source,j]
------------------------------------------
   {{x,{.&.>y}}/cut'hello there my friend'
┌─────┬─┬─┬─┐
│hello│t│m│f│
└─────┴─┴─┴─┘
------------------------------------------

iter | x        | y
     | ┌──┐     | ┌──────┐
0    | │my│     | │friend│
     | └──┘     | └──────┘
     | ┌─────┐  | ┌──┬─┐
1    | │there│  | │my│f│
     | └─────┘  | └──┴─┘
     | ┌─────┐  | ┌─────┬─┬─┐
2    | │hello│  | │there│m│f│
     | └─────┘  | └─────┴─┴─┘

* insert inserts a fn between each pair of elements starting from the right.
* x is the left element, and y is the right.
* x is the current element and y is the accumulator.
* on the 0th iteration, y is given as is; the insertion function is not run!
* it's only on the successive iteration that we see the new y. thus y is lagging whereas x is immediate.

[source,j]
----
   {{(toupper&.> x),{.&.>y}}/\.cut'hello there my friend'
┌─────┬─┬─┬─┐
│HELLO│T│M│f│
└─────┴─┴─┴─┘
----

iter | x        | y
     | ┌──┐     | ┌──────┐
0    | │my│     | │friend│
     | └──┘     | └──────┘
     | ┌─────┐  | ┌──┬─┐
1    | │there│  | │MY│f│ NB. iter 0 passed to iter 1.
     | └─────┘  | └──┴─┘
     | ┌─────┐  | ┌─────┬─┬─┐
2    | │hello│  | │THERE│M│f│
     | └─────┘  | └─────┴─┴─┘

the ugly asymmetry is that `f` is not upper case but all others are; the last element is treated differently. this is why general lambdas are not appropriate for folds unless the last element is treated specially i.e. is an initial value, the `z` that we'd see in haskell `foldr f z xs` which is expressed in j as `f/xs,z`, akin to `foldr1 f (xs++z)`.

if i'd wanted all to be capital then i should properly code it as a fact of all elements, instead of a relation between elements, which it is not! factually, uppercase is a unary function, not a binary one; thus it cannot relate elements! the key design insight here is that your fold fn should consist exclusively of binary functions.

[source,j]
----
   ,/(toupper@:{.)&.> cut'hello there my friend'
┌─┬─┬─┬─┐
│H│T│M│F│
└─┴─┴─┴─┘
----

*this properly separates the symmetry over all elements, from the asymmetry of adjacent elements.* granted, the adjacency is expressed as a symmetry, but be aware that adjacent elements are isomorphic to a table of ad-hoc relations, such as may encode a conditional block:

.pairs
[source,j]
----
   2]\cut'hello there my friend'
┌─────┬──────┐
│hello│there │
├─────┼──────┤
│there│my    │
├─────┼──────┤
│my   │friend│
└─────┴──────┘
   _2(,&.>/)\cut'hello there my friend'
┌──────────┬────────┐
│hellothere│myfriend│
└──────────┴────────┘
----

.concat strs with spaces between them
[source,j]
----
   {{x,' ',y}}&.>/;:'things are cool'
┌───────────────┐
│things are cool│
└───────────────┘
----

these pairs are similar to the fold, but instead of relating an accumulator to the current item, it relates the next item to the current one.

=== json

NOTE: dictionaries are itemized e.g. `$1{::dec_json'{"y":10}'` --> 1 instead of (0$0)

[source,j]
----
load'convert/json'

NB. keys are seen as column headers
dec_json'{"x":3,"y":[1,20,6],"z":{"A":[[10,20,30],[45,55,65],[80,95,99]]}}'
┌─┬────────┬────────────────────────────────────┐
│x│y       │z                                   │
├─┼────────┼────────────────────────────────────┤
│3│┌─┬──┬─┐│┌──────────────────────────────────┐│
│ ││1│20│6│││A                                 ││
│ │└─┴──┴─┘│├──────────────────────────────────┤│
│ │        ││┌──────────┬──────────┬──────────┐││
│ │        │││┌──┬──┬──┐│┌──┬──┬──┐│┌──┬──┬──┐│││
│ │        ││││10│20│30│││45│55│65│││80│95│99││││
│ │        │││└──┴──┴──┘│└──┴──┴──┘│└──┴──┴──┘│││
│ │        ││└──────────┴──────────┴──────────┘││
│ │        │└──────────────────────────────────┘│
└─┴────────┴────────────────────────────────────┘
----

a dict is an alist: a list of labeled data, whereas a sequence [list] is a sequence of unlabeled data. just as lists (type `[a]`) can describe trees (as done in lisp and haskell), described as type `Tree a`, then we can use alists to get a type `Tree (label,a)`. when each datum is considered as either a list with or without a header/label, this means that we can use nested tables rather than trees to represent trees; this fact implies describes the graph theoretic nature of trees: connected & acyclic. furthermore, we see that a more constrained variant of that—the _rooted tree_, a directed graph—is isomorphic with [the concept of] nesting! _nesting_ is actually just another term for recursion. arrays are recursive: elements may be arrays. thus they support nesting and are alternatives to trees proper.

the asymmetry of directed edges cripples. it means that traversal is scoped. as always, the ideal code is one of a/symmetries. suppose that i want to flatten each of z's A's. the description should be "`o` but with `z`'s `A`'s flattened." we expect a model that supports identifying A's, then checking if they're of z, then optionally applying `,`. this is natural given the commutative intersection of predicates, here namely prolog `parent(z,A),parent(xs,A):-flatten(xs)`. this is inaccessible in a reductionist model or a scoped model because we must test three levels simultaneously! fortunately we can assign indices to any model and convert it to a flat relation. converting back to the original structure might be a pain or inefficient, but the original model (encoding) probably shouldn't've been used in the first place.

granted, if the current index were in scope for each node considered, then at least all information needed to update nested structure would be preserved. such indices would be like `x` for 3, `y 1` for 1, `y 2` for 20, and `z A`.

and again, we see that all structure & data is best understood as indexed relations!

tl;dr: we should always be able to consider a thing wrt its context, since context means "relations of which it's a member" and all information is relations! the directed (and thus asymmetric) nature of functions makes them unsuitable for encoding relations, because functions necessarily always represent directed edges, which limits considerability of context. loops [graph theory] are represented by recursion, and cycles by mutual recursion.

[source,j]
----
NB. accessing is easy; replacing is not, simply b/c { does not automatically unbox things of shape 1
   ;>>1{>(<1;2){ o
10 20 30 45 55 65 80 95 99

NB. ????????????
   (<0;2){o
┌─┐
│z│
└─┘
   (<'z')=(<0;2){o
0
   (<'z')=&>(<0;2){o
1

   ]p=:('x';'y';'z'),:(3;(<1;20;6),<((<'A'),:<(<10;20;30),(<45;55;65),(<80;95;99)))
┌─┬────────┬────────────────────────────────────┐
│x│y       │z                                   │
├─┼────────┼────────────────────────────────────┤
│3│┌─┬──┬─┐│┌──────────────────────────────────┐│
│ ││1│20│6│││A                                 ││
│ │└─┴──┴─┘│├──────────────────────────────────┤│
│ │        ││┌──────────┬──────────┬──────────┐││
│ │        │││┌──┬──┬──┐│┌──┬──┬──┐│┌──┬──┬──┐│││
│ │        ││││10│20│30│││45│55│65│││80│95│99││││
│ │        │││└──┴──┴──┘│└──┴──┴──┘│└──┴──┴──┘│││
│ │        ││└──────────┴──────────┴──────────┘││
│ │        │└──────────────────────────────────┘│
└─┴────────┴────────────────────────────────────┘
   o-:p
0
NB. what's a boy to do?
----

...i can't even use `^:` to index into this because i need both `x` & `y` to change on each loop update. so i need full-blown recursion.

actually, there's good news: link:https://code.jsoftware.com/wiki/Vocabulary/AmendingBoxedStructures[`applyintree`] solves the problem.

TODO: check whether we can, as with usual j operations, compute the path(s) by applying a predicate to the input boxed structure. note that unlike array operations, `applyintree` accepts a function argument rather than data; usually in j we do `g(f(y),y)` rather than `g(f,y)`. is the choice of which to do a reflection of nesting vs flatness? in a sense, yes: j's primitives and its array model work on arrays—flat hyperrectangles. boxes don't follow that; they can be seen as multidimensional ragged arrays or flat arrays where atoms have 0+ depth. thus boxes have the essential/relevant property of depth/raggedness which arrays do not have, and which makes few of j's primitives useful for. this being said, the paths (called _boxing paths_) used by `{::` & `{` are the same (including `a:` being meaningful; it always means `i.@#`) regardless of whether the structure is boxed or not; such paths work on any multidimensional structure regardless of raggedness.

NOTE: sql has not this problem; arrays, boxed structures, and all other structures are mere relations and said relations may have any index structure, generally a unique & total ordering of its elements. in sql all structures are dealt with by the same code, and all structures are necessarily expressed flatly. this expresses another important point: *flatness is a property of expression, not structure.* there are no "flat structures"; there are just structures, expressed flatly or not.

TODO: write a document on flatness & scope alone.

btw, displaying a tree as a table:

A
├─B
│ ├─C
│ └─D
├─E
└─F

[source,j]
----------------------------
   p=:,:&<
   'A'p('B'p'C';'D');'E';'F'
┌─────────────┐
│A            │
├─────────────┤
│┌───────┬─┬─┐│
││┌─────┐│E│F││
│││B    ││ │ ││
││├─────┤│ │ ││
│││┌─┬─┐││ │ ││
││││C│D│││ │ ││
│││└─┴─┘││ │ ││
││└─────┘│ │ ││
│└───────┴─┴─┘│
└─────────────┘
----------------------------

in uiua it displays even more like a tree:

[source,uiua]
-------------------------
p ← ↯2_1⊟∷□
p@A{p@B{@C@D}@E@F}
╭─                       
╷           □A           
  ╓─                     
    ╓─                   
    ║    □B              
      ⟦□C □D⟧   □E □F    
              ╜          
                      ╜  
                        ╯
-------------------------

so the next time you're thinking about pretty printing a tree, consider whether it'd be easier to display hierarchies by tables.

== link:https://code.jsoftware.com/wiki/Vocabulary/Locales[namespaces (locales)] and identifier & pathname resolution

.terms
. simple name: identifier as given by syntax alone, w/o.r.t. namespaces. each simple name corresponds to a _private namespace_—the namespace that exists during the execution of a verb, referred to in the definition of the verb, and modified by `=.`.
  .. of course, simple names are defined in the _current locale_
. locale: public namespace. locale's names may not feature underscores.
  .. numbered locale aka instance locale: "holds an instance of a class." is given a system-assigned numeric name when the instance is created.
    ... *numbered locales must be explicitly created before being used.*
. locative: a simple name coupled with a locale name of one of the two following forms:
  .. explicit aka direct: denoted by a locale name between single underscores. thus an explicit locative looks like `simp_explloc_`
    ... if the locale name is omitted (i.e. simple name followed by `__`) then it's assumed to be `base`
  .. object aka indirect: denoted by a chain of 1+ _object names_, each of which is a simple name preceeded by `__`. the whole chain is called an _object locative_. object locatives are nested/referenced (different interpretations of the same thing) namespaces such as one would find in an oop lang e.g. link:https://docs.oracle.com/javase/8/docs/api/java/util/Calendar.Builder.html#setDate-int-int-int-[`java.util.Calendar.Builder.setDate`] in java would be `setDate__Builder__Calendar__util__java` in j. in j the rightmost locale is resolved, then from within that locale the next most rightward locale is resolved, and so on.
. class: synonym for object locale
. starting locale: the locale specified in a locative, or if multiple, then the rightmost one.
. implied locale: synonym for _current locale_. perhaps _implicit_ would be a better term than _implied_. in multi-locative object locatives, the current locale is implied by the resolution of the prior locale. _imply_ is the same as _implicit_ and _implication_ such as logical implication, which in prolog is definition.
. search path: of a locale, the locales searched when a lookup in the current locale fails. defined as a vector of boxed locale names.
  .. the search path of a locale created implicitly by reference—e.g. `anoun_myloc_=:'noun here!'` creates `myloc` if it did not already exist—then its path is only `z`. an instance (numbered) locale created by `conew` is given the search path of its class.
. "name in locale": executing a locative, which executes under that locale
. "name from locale": executing a definition that's not present in the current locale nor in a locale specifide by a locative, but instead is of a locale in the current or starting locale's *path*. such execution never changes the current locale.

the distinction between _name in/from locale_ is important and as follows: execution in a locale uses that locale's names, whereas execution of a name from a locale uses the current locale's names. e.g.:

[source,j]
----
   k    =: 'k of base'
   k_z_ =: 'k of z'
   p_z_ =: {{k}}
   p 0    nb. p from z uses base's k
k of base
   p_z_ 0 nb. p in z uses z's k
k of z
----

NOTE: there are two kinds of locatives, but there is only one kind of locale. numbered locales created by `conew` effectively behave as any others, but are optimized.

locales are hash tables. you can use them as such.

=== link:https://code.jsoftware.com/wiki/Standard_Library/jade[loading files]

* `load` runs a file. arg is a space-delimited string of file descriptors, which are "names", full or relative pathnames, or "script shortnames". TODO: learn what these quoted things mean.
  ** the `scripts` verb lists scripts that can be loaded via `load`. `scripts''` lists shortnames. `scripts'v'` is just, imo, a worse display of `Public_j_`—the map from shortnames to filepaths
  ** calls `getscripts_j_` to resolve names. `getscripts_j_` maps a shortname to path; it just looks-up in `Public_j_`.
* `require` is idempotent `load`

=== particular locales

* the `base` locale is the current one unless explicitly changed "by executing a [any?] verb in a different locale"
* the `z` locale's words are available in every locale

=== viewing locales

* `show` takes three varieties of `y`:
  ** the empty string translates to `0 1 2 3`
  ** a string of names separated by whitespace. prints those definitions.
  ** a vector of numbers: 0 for nouns, 1 for adverbs, 2 for conjunctions, and 3 for verbs.
    *** `4!:0` specifies the map from integer to part of speech
* `names` lists parts of speech of type `y` (integer code for part of speech; see `4!:0`) whose names begin with `x`
  ** `names_<loc>_` lists the names defined in locale <loc>
  ** `names 6` lists locales

=== working with / using locales

* verbs execute in their locale. for example, `f_q_=.{{a=:y}}` defines `a` in locale `q` regardless of what the current locale is when `f_q_` is invoked
* evaluating a locative creates that locale. e.g. `cat_mandu_` in a fresh j repl gives a value error but afterward `names 6` shows `mandu` among the other locales

somewhy the prefix "co" refers to locales. i'd've expected _loc_ but w/e.

link:https://code.jsoftware.com/wiki/Standard_Library/colib[colib]:

[options="header"]
| colib verb                  | its definition, basically
| `conames`, `conl`           | `18!:1`
| `copath`,`coinsert`^[1]^    | `18!:2`
| `cocreate`, `conew`^[2]^    | `18!:3`
| `coclass` aka `cocurrent`   | `18!:4`
| `coname`                    | `18!:5`
| `cofullname`^[3]^           | `18!:5`
| `coerase`, `codestroy`^[4]^ | `18!:55`
| `coreset`^[5]^              | `18!:55` & `18!:1`

. `coinsert` is monadic only. whereas `copath` sets locale `y`'s path to `x`, `coinsert` adds locale `y` to the current locale's path. however, you should be able to do `coinsert_loc_ newloc` to effectively do what `newloc coinsert loc` would do.
. idk what `conew` does, but it seems distinct from, yet defined in terms of, `cocreate`. `conew` is used to effectively instantiate a class; it returns the locale name of the instance, boxed.
. if given a simple name, appends `'_',(>18!:5''),'_' to it. if `y` is a locative then `cofullname` is `]`. it does no lookup; it's purely a string manipulation function.
. `codestroy` is `coerase@coname`.
. idk which locale(s) `coreset` destroys. apparenly "instance locales" afetr they've finished executing

link:https://code.jsoftware.com/wiki/Standard_Library/coutil[coutil]:

* `load'coutil'`

[options="header"]
| verb         | function
| `cofind[v]`  | tell in which locale a word was defined [and its current value]
| `conouns[x]` | "nouns referencing objects [with locales]". no idea how to use.
| `copathnl`   | no idea
| `costate`    | no idea. in fact, `$conl 1` was `0` yet `costate''` gave `r` (see `costate`'s definition).
| `coinfo`     | dunno.

note that `names 6` is the same as `conames''` which is `18!:1]0 1`.

other (definition location unknown):

[options="header"]
| verb        | description
| `erase`     | remove the definition corresponding to a locative
| `clear`     | clear all names in the current locale
| `copathnlx` | path locales, not including `z`

demonstration of `copathnlx`:

[source,j]
----
   foo_loc_=:4
   baz_loc_=:50
   smol_duck_=:'smol! <:o'
   beeg_duck_=:'beeg! >:3'
   cocurrent'duck'
   coinsert'loc'
   names 0
beeg smol 
   copathnlx''
┌────┬────┬───┐
│beeg│duck│   │
├────┼────┼───┤
│smol│duck│   │
├────┼────┼───┤
│baz │    │loc│
├────┼────┼───┤
│foo │    │loc│
└────┴────┴───┘
----

the earlier columns are tried for resolution before the latter columns. here, with current locale being `duck`, `beeg` & `smol` are, when referenced, tried for resolution in `duck`, and only failing that, are tried in `loc`.

tacit verbs' namespace: "The details get tricky when an explicit verb executes a tacit verb and you wonder just what names the tacit verb has access to. In that case you need the full rule, which is: If the original name was not a locative, and a private namespace exists (in otherwords, if an explicit entity is running), the youngest private namespace is searched to see if the simple name is defined there."

NOTE: there's a link:https://code.jsoftware.com/wiki/Vocabulary/Locales#Verbs_Relating_To_Locales[tabular reference] of the above two tables altogether.

==== object locales

we can only reference values of an object locale either:

. when that locale is the current locale; or
. by using a locative but only when the starting locale is not directly referenced, but instead indirectly referenced by the name of a word whose value is the starting locale's name, boxed. as link:https://code.jsoftware.com/wiki/Vocabulary/Locales#Explicit_locative_and_object_locative[the documentation puts it]: "the double-underscore is followed by one or more names of nouns whose values give the starting locale. Each value must be a boxed string."
. as an explicit locative, but only if the starting locale is a number

[source,j]
----
   cocreate<'myobjloc'
┌────────┐
│myobjloc│
└────────┘
   a__myobjloc=:4
|value error: ll
   L=:<'myobjloc'
   a__L=:4 NB. sets a__ll to 4
   cocurrent'myobjloc'
   names 0
a
   cofindv 'a'
┌────────┬─┐
│myobjloc│4│
└────────┴─┘
   cocurrent'base'

NB. cocurrent is confined to an explicit definition
   {{0 0$HOLA=:4565[cocurrent'myobjloc'}}''
   coname''
┌────┐
│base│
└────┘
   names 0
L
cocurrent'myobjloc'
names 0
HOLA a
----

TODO: link:https://code.jsoftware.com/wiki/Vocabulary/Locales#Changing_the_implied_locale[the documentation says]: "Returning from an anonymous verb, even an explicit one, does not restore the implied locale." as demonstrated above, this is incorrect, at least in the j repl.

TODO: use `coname''` all over the place to check the behavior/rules of "restoring the implied locale." there is the obvious rule that invoking a verb by its locative e.g. `myverb_myloc_ 0` will execute `myverb` under `myloc` which is the same as switching the current to `myloc` then executing `myverb` then switching back to the prior locale. this being said, there's no use of `cocurrent` here, so idk why link:https://code.jsoftware.com/wiki/Vocabulary/Locales#Changing_the_implied_locale[the documentation] mentions it w.r.t. `cocurrent` & `18!:4`.

TODO: identify the justification for the indirectness of the object locative design. it seems to be that for oop, commonly the starting locale is a dynamic value. the silliness here is that we must name the starting locale to a word then reference that word rather than e.g. `a__(<'myobjloc')`. j's design is against metaprogramming.

==== link:https://code.jsoftware.com/wiki/Vocabulary/Locales#Bypassing_the_Search_Path:_Nameref_Caching[nameref caching]

* put `9!:5]1` near the top of a script to enable nameref caching. this just makes locale name resolution faster, but works only if the set of public non-nouns is not modified during execution, including their definitions, if i understand correctly.
* if a nameref is cached, then it effectively cannot be deleted, since there's no way to remove the cached version, and the cached version is always tried first

=== link:https://code.jsoftware.com/wiki/Guides/Folders_and_Projects[resolving pathnames]

* `SystemFolders_j_` & `UserFolders_j_` are maps from <some> identifiers to paths. they abstract paths across users' machines.
  ** `UserFolders_j_` (and additional entries to `SystemFolders_j_`) is specified by `jpath'~system/config/folders.cfg'`.
  ** `jpath` resolves these system & user identifiers to their specified pathnames when they're preceeded by a tilde. for example say that i put an entry `anime ~/anime` into `folders.cfg`; then *afterward* when i run `jconsole`, `jpath'~anime'` outputs `'/home/nic/anime'`.
    *** `~.f` instead of `~f` is equivalent to the resolved version of `~f/..`. `jpath` does not further resolve `..` or `.` in its path argument.

==== project folders

* a project directory `<dir>` is denoted by featuring a file `<dir>.jproj` and "should be" a subdirectory of "folders" [`UserFolders_j_`?].
  ** `<dir>.jproj` can be empty or a list of pathnames of the project's source files

commonly:
* `build.ijs` "assembles code for the project" (no idea what this could mean.)
* `run.ijs` runs the project "e.g. for testing" (for testing? what about ordinary _running_?)

=== z locale

* you can link:https://code.jsoftware.com/wiki/Vocabulary/ZeeLocale[view definitons of words of standard libraries]

=== practical use

defining a module looks like this:

.somemodule.j
[source,j]
----
NB. set the namespace
cocurrent'mymodule'
NB. then define functions
sum=:+/
NB. then export some to the z locale
sum_z_=:sum_mymodule_
----

thus when the user loads `somemodule` then executes `sum 0`, `sum` is evaluated to `sum_mymodule_` which is then invoked inside the context of `mymodule`, then after the verb finishes executing, the current locale returns to whatever it was before invoking `sum_mymodule_`.

TODO: how is this technique effectively different from just defining the word directly in `z`? the only difference that this method could have is if the user defined some other entity by the same name (here, `sum`) s.t. that definition is to be tried first before searching for `sum_mymodule_`; so how to do that?

==== link:https://code.jsoftware.com/wiki/Vocabulary/Locales#Working_with_classes_and_instances[oop]

* `conew` has `x` as initial data and `y` as the unboxed locale name corresponding to a class.
* the only thing that makes a locale an instance of a given class is its search path; changing its search path implicitly effectively makes it an instance of a different class, now. by this description, a class ordains only the minimum set—not the total set—of class attributes that any instance must have.

NEXT: finish this whole section on locales & oop by reading the following: <https://code.jsoftware.com/wiki/Vocabulary/ObjectOrientedProgramming> <https://code.jsoftware.com/wiki/Vocabulary/Assignment>.

=== the execution stack

like the stack in assembly language, or more similarly, continuations in scheme, which tracks all scope & evaluation context.

* the execution stack is the record of the names, locales, and local variables in execution.
* names bound by `=.` are part of the execution record and are not stored in a locale.
* the execution stack is not a part of any locale. 

i'm putting this section here because it was mentioned in <https://code.jsoftware.com/wiki/Studio/Locales>, though idk why.

== link:https://code.jsoftware.com/wiki/JAL/User_Guide[the j application library (jal)]

* link:https://code.jsoftware.com/wiki/Vocabulary/Libraries[install libraries]

=== bugs (or what should be bugs)

* u"id where id is an undefined symbol will do `u` w/o.r.t rank! u"(id+0) is a fix.

in j9.0.4:

[source,j]
-----------------------------------------------------------------------------
   (,&'(')`]`(,&')')"1|:(<"0'fgh'),.(<'5'),.<"0'abc'
JE has crashed, likely due to an internal bug.  Please report the code which caused the crash, as well as the following printout, to the J programming forum.
0000000000403132: ?:0:	sigsegv
00007fa02407f60f: ?:0:	?
00007fa01f8cd2d7: ?:0:	jtincorp
00007fa01f8d72ca: ?:0:	jtaro
00007fa01f8d7242: ?:0:	jtaro
00007fa01f8d7898: ?:0:	jtarep
00007fa01f8a7de6: ?:0:	jteformat
00007fa01f88ac9d: ?:0:	jtrank1ex
00007fa01f893363: ?:0:	cycr1
00007fa01f8d18c2: ?:0:	jtparsea
00007fa01f8d112c: ?:0:	jtparse
00007fa01f8d64e9: ?:0:	jtimmex
00007fa01f8c16bf: ?:0:	jdo
00007fa01f8c14b1: ?:0:	JDo
000000000040306f: ?:0:	main
00007fa02406a909: ?:0:	?
00007fa02406a9c4: ?:0:	__libc_start_main
00000000004024ed: ?:0:	_start
ffffffffffffffff: ?:0:	?
-----------------------------------------------------------------------------
