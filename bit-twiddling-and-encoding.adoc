== bit twiddling, and encoding

.hash maps vs tree maps for natural & speedy lookup

* a hash whose result is a memory address would be fastest.
* digitstrings are ordered,...
  ** so if they encode all data, then they can always be stored in a treemap.
    *** like in sql, they may use values that are keys in other maps, rather than using pointers, though pointers _can_ be used also; the encoding would simply decide by a prefix or other predicate whether a value represents a pointer or something else.
  ** and permit multiple orders. we can start using multiple orders by using the sql index mechanism.

.treemap parsers

if we're going to generally use parsers for everything everywhere, then it should be efficient by one design so that we can use that one thing unthinkingly, freely. let's not use linear search through parsers. most parsers are defined as functions, and so cannot be computed over, and so lookup keys cannot be derived from them, though each can be paired with a lookup key by some relation like using a composite parser as `[(key,parser)]` rather than just `[parser]`. however, then, by most definitions of _parser_, a composite parser would not be a parser. the mere fact that parsers are functions means that we can't get metadata from them; functions only morphisms are from given inputs to outputs, not supporting morphisms independent of the function's inputs or outputs.

consider an i18n parser. it reads the 1st 2 characters of a string which represent a country code, then looks-up that code in a dictionary. a linear search would be foolish; a binary search is fastest and obvious. the parser must know that the country codes are ordered. again, with everything as dstrs, this is obviously guaranteed, but still. the fact that any parser may fail, causing "backtracking" to the next parser to try remains the same.

.parsers, maps, and relations

screw maps; prefer relations, though even a relation is merely an unordered set of data at common indices. so really screw maps and relations! sequences suffice. the sequences must support fast lookup, namely binary search, though i've yet to compare with hash tables or other structures. however the sequence is stored, it must support fast find/replace, which can get subsequences, delete by replacing with an empty value, or insert a substring; replacing /^/ or /$/ by a string are prepend and append respectively,

"lookup" is just sql's `select`. indeed, since we aren't using data structures _per se_, _select_ is a more appropriate term. even _subset_ is not quiet appropriate because we're dealing with information, which is plurality-agnostic and does not recognize the dichotomy of elements vs sets. information is more general than sets.

.conclusion

certainly our language must not use functions, instead only being parsers, defined solely of find/replace. rather than hash tables or any structure containing actual _values_, they contain pointers to values; hash tables are thus merely an indexing mechanism, not a storage mechanism; data are stored in ram, which is O(1) access. we only need to know which data to access. tables are relations, which are relations of indices. this being said, we still need efficient find/replace.

TODO: study hash and string search algorithms e.g. rabin-karp, and succinct structures.

''''

6 groups, a, b, c, d, e, & f, are related as subsets: f={a,e,b={c,d}}. if we give groups integer unique ids, then we can represent a=1,b=,c=,d=,e=,f=0. f's elements are given by: {x|x>f} or {x|x!=uid(f)} (though this implies that c & d are in f, which may or may not be what you want). TODO: finish this example by identifying uids in ℤ for which predicates exist satisfying the subset relations.

TODO: explore cellular (individual agents whose action (including death) depends on their surrounding context, namely their relation among other agents) string programming.
TODO: manipulating bitstrings by bitwise ops is currently inelegantly expressed in most langs. how is it in various assembly langs, though? e.g. toggling bits i~j by shifting an i-length string to the right j bits then xoring. it isn't bad, but it's verbose, error-prone (`&` & `|` are easily confused, and offsets may be incorrectly specified), and detailed beyond the actual code; it concerns the implementation, not just the idea. besides, bitstrings should be treated uniformly as all other strings (i.e. numbers, digit/elt sequences), right? if so, then i should identify a good notation for it all; if not, then why the asymmetry?
TODO: put the following section where it belongs.

recall that all programs simply identify information then pass them to arithmetic functions. generally subset identification is done by predicates, though commonly the predicate is `x==y`, though more generally `x ∈ Y`, or most generally `p(x)`. the subsets may be of form `a` (find), `[a]` (filter), `[[a]]` (group by), &c, subset selection is `group by` aka `partition`; partition is done by equivalence classes, and is of form `a -> [[a]]`; if one wants one subset, then they use a predicate that partitions into the desired group and others which are not concerned in the current computation.

one may suggest that partition is division, and that we should consider union/append (+), intersection (×), difference (-), and relating subsets e.g. join, inner or outer products, cartesian product, `rotate` which can be interpreted as remapping indices i.e. mutating relation of indices with values, and is a specific variety of *permutation*. however:

. a+b is just saying that a & b belong to a common group. union can be represented as appending strings, but can be encoded by other means also. for example 'abc' + 'def' = 'abcdef' works, as does 'abc' -> '1abc', 'def' -> '1def' where equality on the leading number determines group. the information added by `a+b` is grouping `a` & `b` together.
. a×b & a-b both just identify subsets of `a`
. relating elements is just saying that they belong to a common group
  .. `join` in sql is its own concept within the relational algebra; it has no single, natural generalization beyond relalg

`group by` still applies to substrings—even overlapping ones. consider a string with multiple groupings:

----
abcdecgba -- string
123453621 -- group 1; groups are determined by equal group number
1234abcdA -- group 2: substrings' order is done by codepoint order. grouping is done by x∈[0-9] or x∈[a-z] or x∈[A-Z]
----

generally we can encode more information per string element by sharing indices with other strings or by appending e.g. to store two characters per element, for elements 'ab', 'cd', & 'ef':

----
'abcdef' -- one string; with len=2, substring(s,len×n+1,len×n+n) when indexing from 1
-- two strings; to get nth element, get nth element from each of the two strings
'acd'
'bdf'
----

a program's output is always just an action or subset or aggregate thereof in a pretty encoding. computation of aggregates may be delayed until the aggregate value needs to be related to some other value. element in/dependence has a lot to do with optimization! it determines when whole sets must be stored (e.g. sorting a set requires the whole set but `[ 1 + ] map` may consider only one element at a time) and which operations may be done in parallel.

so, given an infoblob, you want to identify relations among elements. with those relations you can compute things. two common failures of programming are 1. needlessly discarding information, and 2. combining (operations over sets) rather than combining operations then applying them over sets. subset is a variety of this; often subsets are not just identified, but copied; that is a _huge_ inefficiency! ironically both copying & deleting are done far more frequently than appropriate; practically never does either need to be done! rather than delete from a set, just blacklist it from a traversal. without deleting, there's no need to copy; copying just preserves information that would otherwise be lost. so just don't lose it! this is a case of two needless competing opposites. not only can aggregates (folds) be commonly delayed, but also maps or any operations. perhaps there may or may not be a reason to delay any computation, but the fact of _whether it can_ be delayed crucially determines how we can optimize our program by restructuring!

TODO: identify which relations force computation. `max` does not require sorting, though it's equal to `sort 1 last`. but what about `sort n last`? by symmetry, shouldn't that not require sorting? what essential quality of the information needed by `n last` requires sorted data? perhaps only operations that require looping more than once over forcing computation i.e. that the operation is element-wise, but that the elements aren't computed yet; in `sort 1 last`, the one element to take already exists. in `sort n last`, regardless of whether we sort first then take `n` vs if we sort until we have the 5 max elements, both cases require looping more than once. this being said, the latter version is more efficient! it seems that the cardinality of the subset to be identified (i.e. the amount of information content) determines how much of any computation must be done. in this case, the minimal information that we must know in order to get the top 5 is the max of a set, then the max of that set minus its max, ...; thus we compute the aggregate `max` 5 times. given that `max` is O(n), we do not need to sort the set in order to get the top _n_ elements; yet this version of top _m_ elts has O(mn). compare this with quicksort's average O(nlog(n)). our version is clearly better for m<<n. however, quicksort lends itself to parallelization, which can be a very large speedup, and leaves the whole set sorted, which, if used later in the program, may as well be computed now. suppose m=10 and n=10,000. ours runs in 100,000 operations whereas quicksort would be 92,000 on average. clearly the 100k version considers information redundantly whereas quicksort does not. comparing of sorting algorithms by considering how their structuring of data exploits implication of facts or computations without needing to subset or rearrange; what info do they preserve, and how do they exploit statistics to get a most-likely good performance? remember that probabilistic programming is closely related to information theory!

''''

_devise encoding schemes, write parsers._ this document discusses programming by using only strings related implicitly by indices. arbitrary relations are expressed by strings implicitly related by indices, too: the map `[(a,b),(c,d)]` is represented by strings `'ac'` & `'bd'`. strings support subset (substr), union (++), and find/filter, and so can act as sets. they are sequences; they order elements, relatiing elements to their neighbors or to other elements by patterns on indices. for example, we can store two strings `'abc'` & `'def'` as a single string ``adbecf'`; the two contained strings are not extracted as substrings, but subsequences: `subseq(s,i|2)`. `|2` partitions the string, and generalizes to `f:substr→ℤ` where each unique z∈ℤ uniquely identifies a group. i choose `f` to act on a substring(i,j) instead of just an element `i` because a single item in a string may not contain enough information, and the generalization is easy. generally we need substrings & efficient random access in order to decode strings with practical efficiency.

using an enum/number enforces mutual exclusivity. consider `(or a b)`; the first non-falsy is chosen; however, `a ∧ b` may be true. if you want to help ensure that `a xor b` is true, then have a single number called. why integers? most types work; we need for all elements of the type to be unique. integers are a good choice because they obey that property, and are machine words, and support bit twiddling. the point of this pattern is doing `case x v1: ...; v2 ...; ...` instead of `cond`, since `x` must have exactly one value, whereas `cond` statements, while more general (i.e. supporting general predicates instead of mere equality), must be carefully ordered, and may be not mutually exclusive.

.conventions, terms, and other notes

* 2's complement is assumed unless otherwise noted
* _word_ always means machine word, not natural language word
* for bits, 1 may be called _set_, and 0 _unset_
* _bits_ is short for _bitstring_ i.e. a bit vector. because any bits can be split into many, _bits_ means a bitstring or a string of bitstrings, recursively.
  ** _bits_ is plurality-agnostic

=== numbers, sets, and sequences (they're all the same!)

numbers are no different from sets (and thus no different from sequences, since sequences are merely a specific variety of set). both may be considered as amorphous blobs, or any number of structures may simultaneously be considered of them. for example, the number `6` has several interpretations i.e. is an encoding of several informations, some of which are:

. not zero (truthy)
. {2 3} (prime factors)
. 0b110 (a sequence of 3 booleans, or one boolean and a number on [0,3])
. a number less than 10
. the rational 12/2 (thus a compression scheme that reduces two numbers into one)
. 4×1+2 i.e. 4r2 (one unit of 4 with a remainder of 2 i.e. a single period of measure 4 plus one half that period i.e. 1.5×4.)

generalization of numbers: 𝔹 ⊂ ℤ ⊂ ℚ ⊂ ℝ ⊂ ℂ ⊂ ℍ .... it's incorrect to say that any integer is a single datum but that a complex number a 2-sequence of data, because an integer is an n-ary sequence of bits. now truly the bit _is_ the smallest unit of information. anyway, clearly if integers can encode such a variety of information, then rationals, complexes, &c can encode very much more!

these are no different from sets. both have product, coproduct, subset. breaking a number into other smaller numbers then selecting one of those numbers is an example of subset selection. numbers support many unions; bitwise `or` is a union that applies to integers (and even to IEEE754 floats, if you're a real stud like the developers of  quake [game] were (viz fast inverse square root)), just as `+` is coproduct. they're coproducts of different rings, but a number can be interpreted by many rings, simultaneously or not.

all numbers permit orders. so do all sets, at least regarding programming, since the sets are, as all things are, comprised ultimately of bitstrings, which are numbers. the pertinent question, regardless of set vs number, is whether any natural ordering is useful, or whether we instead need to introduce our own ordering scheme, independently encoded from the natual one (i.e. variance of values across the the natural one's axis does not vary values along the introduced one. this brings to mind partial derivative invariance.)

with common thought, _set_ or _sequence_ refers to a _data structure_—an encoding where each datum is stored in its own cell. these structures are far too limited and their excessive & artificial partitioning often fails to encode any natural relationships among the data. they all have their own construction & traversal, places where they're suited or not, regarding elegance or efficiency. the foolishness of them is that they're all artificial; rather than use numbers, which can naturally encode so much information, people decided to treat numbers as mere values (as though numbers or other natural values are as unrelated as pie and books) and design their own encodings of structure. spoiler alert: humans did a worse job at structuring than nature. as usual, it's better to study natural structure than try to make our own. _succinct data structures_ are a nice example of storing information without needless partitioning. i can't say how natural they are, but they're at least a step in a good direction.

==== vote strings for the _de facto_ sequence type

basically numbers are bitstrings, and strings as usually considered are strings of characters, and each character corresponds to a number, so all strings are bitstrings. since numbers are all that are used by a processor, they're the only data type, but they're bitstrings, so bit is actually the only data type, and it's not even just a data type; it's the unit of information. therefore bitstrings are the only data ever, and they're sequences of bits. therefore numbers and strings are the same, both bitstrings. as for sets, they're merely structures that have efficient lookup by value, contrasting with sequences, which have efficient lookup by index. therefore sequences, `[(i,v)]`, are isomorphic to the implementation of sets `{v}`; firstly, everything must be ordered when represented anywhere, even if the order is irrelevant, so `{v}` is really literally `[v]`. the index is missing but contains the same information as the relations that structure the set in such the way that it efficiently implements set operations; the _structure_ part of _data structures_ can be expressed by strings, because they are implicitly indexed, and arbitrary relations can be encoded by index permutations e.g. `[(a,e),(c,e),(b,f),(a,d)]` is given by strings `'abc'` & `'def'` and index/association permutation string `'12,32,23,11'`. other relations may be specified on 'abc' & 'def' without affecting them nor requiring restructuring.

every language should have a _de facto_ sequence type. in lua, it's the string or table. in sql, it's the string or relation. in lisp, it's the list [stack], but that's a bad choice because lists cannot be easily & efficiently manipulated. consider that elements of a list can be expressed as a space-delimited sequence of uids. if we can efficiently manipulate strings but not linked lists, then a string representation is better; the string representation is converted to literal data when the literal data are needed; this may be a conversion of any subset of the sequence. lisp lists support nesting, but strings, like relations, do not. again, instead of nesting, we use `join` or reference by index e.g. in sql or lua `'1 2 3'` represents a permutation of table with keys/attributes having values 1 2, & 3. many languages feature pattern matching on structures but not on strings; if ever done for strings, it's usually in some quite different parser framework. why the asymmetry? aren't strings powerful enough? they may represent numbers of any radix, and generally generalize bitstrings, being able to encode an exceptional amount of value per character. a string of characters belonging to an alphabet of cardinality _n_ contains information equivalent to a number of radix _n_. though strings of arbitrary encoding are always representable by bitstrings, the partitioning (character size i.e. number of bits per character, e.g. 64 in UTF8, 128 in UTF16. remember that the utf number is bytes, not bits) can be quite useful, just as hexadecimal (4 bits per character) is a useful interpretation of bitstrings. any hexadecimal string is guaranteed to have n×4 bits. this helps with string alignment for bitwise manipulations. for example, we may consider hex and octal together; each hex character is 4 bits and each octal is 3. they align at 12 bits, or 4 octal / 3 hex. i can't now see how that'd be useful; in fact, quite the opposite, since that's such poor alignment compared to e.g. 2 base-4 & 1 hex.

* c is one language where strings are represented as static arrays of characters, and characters are equivalent to integers. good symmetry! unfortunately it's a poor structure for manipulation. lua stores strings as ropes, so they support all sequence operations easily & efficiently. it also stores all strings as bytestrings. it's a very elegant bytestr/charstr model.
* one can use strings or bits to express regrouping i.e. that a counter has passed a threshold, e.g. representing that a program has reached a certain point in execution or that some condition is thus implicitly met. indeed, one can have a large bitstring that represents the current control flow point (or multiple), and mutating this is easier than updating a stack to track state.
* regex is extremely powerful for strings. there is no reason to limit their use to text! use them for bytes (if your regex engine supports it, e.g. lua's), and sequences of _anything_, even if manipulating that sequence is done by manipulating a virtual string representation of the sequnece!
* using strings as an encoding for sequences, we see that `gsub` (replace substrings matching a regex) is `filter-map`, assuming that `gsub` accepts a unary string endomorphism λ (such as in lua).
* remember that sequences can be used as [multi]sets. this is easiest if `insert` & `update` are unified into `put`

in summary: all encodings are sequenced; just ask whether we can leverage that or if we must introduce new independent information. all things support subset and adjoin. even a single bit supports subset: 1→{1}, 0→∅. obviously the bit supports adjoin: 0+1→1, 1+1→1. in the case of the bit, `+` & `&` are identical, or rather `+` is truncated/filtered from ℤ to the set {0,1}. in this case, `min` & `max` are the filters. is this use of _filter_ different from filtering a set by a predicate? you decide, but i suggest "no." indeed, to write `min` or `max` in c, you'd use a ternary expression—a convenient encoding of `if`. the predicates' information is inside the definition of `min` & `max`, namely `<`. btw, though they've the same predicate, each chooses a different input, together corresponding to the two branches of `if`.

obviously bitstrings, being sequences, support:

. adjoin = interleave (at arbitrary indices, not necessarily every other index) (append is a specific version)
. subset = subsequence (substring is a specific version)
. mutation by bitwise ops

consider this iteration over the string `'hello'`, which expresses a sliding window of size 3: `local s = 'hello' for i=1,#s do print(string.sub(s,math.max(i-1,0),math.min(#s,i+1))) end`. neither `map` nor `fold` handles windows well; substring does, though. zippers do, but only for simple situations. `substring` is plainly implemented as jumping to the index (pointer offset) `i` then using `n` elements subsequent of and including the one at `i`. thus `substring` exactly represents sql's `between` or `limit/offset` constructs, and adding iteration (here a `for` loop) transforms that into a window function. the only difference between `between` & `limit/offset` is that one controls input and the other controls output.

suppose the string `'apple\36banana\2cherry garcia\50'`. this encodes an alist of type `[(string,integer)]`: each string is `/[[:alpha:]]+/` associated with a value in [0,50]. we can search this string for a number or text by the regex `[a-z]+` or `[\0-\50]`, both by lua function `string.find`. in fact, we can combine and specify these regexes to find any pair, sequence of pairs, or even the pair following an integer value in a given range (regex `'[a-b][a-z]+[\0-\50]'` where `a` & `b` are numbers.) you can use `string.gsub` instead of `string.find` to filter the list for all such values. to print each of the 1st column on its own line: `print(string.gsub(s,'[\0-\50]','\x0a'))`. by this scheme, the 2nd column of the alist values can store any number in [0,96], since 97 is the codepoint for 'a'. that's not limiting, though; to store more data, just allow delimiters to be `[\0-96\]+`; now they can store an arbitrary amount of information as a base-96 number. no recursive traversal. no recursive data structure. no nesting. no separation of data, `map`, `filter`, `fst` nor `snd`. just `find` & `gsub`—functions supported by all languages, even easily written in assembly for any architecture. this scheme does not support getting the 1st col val from a 2nd col val unless the strings are bound to some maximum length.

we can associate such an alist with another of (actually, any number of) the same scheme by implicit index.

strings like this can encode programs; in such cases, they're practically custom bytecode schemes, and you'll need to write (simple) interpreters in whatever language is to execute them. it's far easier to use bytecode than to write your own human-readable (e)dsl.

=== in/dependence [of information]

so why do people prefer data structures? perhaps it's that bit twiddling / information theory / the art of encoding was never popular, or fell out of popularity, and seems less obvious than data structures. certainly anyone, without knowledge of encodings, number theory, or even intermediate mathematics, can understand a list, graph, tree, &c. i think that people like to consider data separately, too. it's easier. the price paid, however, is less elegant and more verbose code—more steps needed to relate data & keep them in scope. furthermore, independence is clean; we can consider one thing at a time. that's appreciable. indeed, dependence is terser and _can_ be more elegant, but things like factor use dependence (adding or removing an item on the stack affects other items' stack position) in a way that trades readability and ease of reasoning & writing programs for terseness, and it's not a worthwhile trade! this is not a fault of dependence, but of poor dependence. *good programming carefully relates data or not.* as prolog and relational algebra represent, programs are only relations & values, matter & form. *dependence of information is just as important as independence. code elegance is the balance of the two.*

the ideal program uses relations that either "constructively" interfere or do not interfere. for example, if i want to simultaneously consider a number as both a non-zero number and a boolean value, then i'm in luck: i can perform any operation (endomorphism) on the number without affecting whether it's a boolean or not. however, if i want to simultaneously encode a boolean value and a number which may be zero, then i need to make these data independent; otherwise an operation may take a number from non-zero to zero, but that's a truthy zero, not a falsy value. the obvious solution in the data structurist mindset is to use a cons pair where `car` is a boolean value and `cdr` a numerical one. that satisfies the need for independence, but are there other encodings that also do that, but are more elegant? for example, in haskell we may use a duple; duples have categorical type class instances, so the ordering of boolean and number can change our code's elegance!

bitstrings are usually not helpful for describing recursive structures. consider a linked list. its length is unknown and partitioning into cells is its very use. the only possible gain by concatenating bitstrings is that it _might_ make window functions easier to write, but even that is an imprementation-specific benefit; they're the same at the level of theoretical abstraction. however, bitstrings are only useful for describing _particular_ structures. this is really true of any strings whose certain intervals connote certain values, though. anyway, loops over alists can elegantly set variables. suppose that data x, y, and z are encoded in a bitstring at substring ranges [1,4],[5,7],[8,12]. then i can get the constituent parts of 0b10111,001,1010 (2970):

[source,sql]
----
with n(n) as (values(2970)), s(var,i,l) as (values('x',1,4),('y',5,3),('z',8,5)) select var,(n>>(i-1)) & ((2<<(l-1))-1) as val from s,n;
----

┌─────┬─────┐
│ var │ val │
├─────┼─────┤
│ x   │ 10  │
│ y   │ 1   │
│ z   │ 23  │
└─────┴─────┘

the `-1`'s show the difference between my preferred representation of bit substrings and the actual arithmetic. also, and i'm not a fan of tracking order of operations, but we can remove most of the parens: `n >> i-1 & (2 << l-1) - 1`. turns-out that subtraction has higher precedence than bitshit. given this example, can't say i'm disappointed with that!

NOTE: bitstrings are not used by sql! they must be converted to relations before being usable with the relational algebra! since sqlite is already efficient, just use relations directly. still, bitstrings are useful in other languages. the above sql statement easily converts to a loop that populates a hash map in any language.

=== domains & transforms

the domain of your values determines its maximum information content. the number of bits needed to encode _n_ values is ⌈log₂n⌉. your encoding should support your program's preimage & image, and transforms on the encoding should appropriately preserve information or not.

=== exploitation of relations

remembering that functions generalize to relations, we see that, in the immediately-prior duple/ordering example, the categorical type class methods, being functions, are thus relations. they relate data to an im/proper subset of the duple. the question, as always, is which information is retained in the output, and whether it's enough for us to calculate the original inputs, if need be. *we want each particular relation/mutation to implicitly affect other information while preserving other information [invariants].* handling this manually is tedious, error-prone, and uncessary (soon). coding a constraint system to identify most efficient encodings given a set of invariants and domains should be at least as easy as coding μKaren, which is only 39 lines of scheme, though it might require a bit of knowledge of number or information theory.

=== list of common encodings

per relation, here listed are transforms and their domains and which information they preserve or not. though most encodings are tailored, they're commonly composed of some common patterns.

* adding an extra bit doubles the number of values supported. this corresponds to (<<1)=(*2). the common example is where an extra bit accounts for sign
* ordering represents layers e.g. [2,4],[5,7] represents 2 layers. being in the upper layer implies that you're above the max value of the lower layer. layers are given by orders and can thus simply be expressed by strings.
* cheap approximation e.g. linearization or using a simple (measure of information content) relation then (e.g. binary search or quicksort, which start with 2 large, imprecise sets then increases precision)
* convenient relative values e.g. to represent numbers 1036 and 940 you may say that the max is 1036 which needs 11 bits, so use 11 bits for both. however, if we express them in terms of their minimum, then you need 7 bits for 1036 and 0 bits for 940. a very terse expression for numbers of large ranges is an assumed base and a small number for exponent e.g. with b=10 (0 bits because it isn't variable) and n=∈[0,7] (3 bits), 1036 is expressed as (3,36), encoding 10^3+36. that's 9 bits total.

=== particular encoding examples

==== stock

this example demonstrates: 1. reducing domain to practical preimage; 2. efficient utilization of extra values by modular arithmetic. by _extra values_ i mean those describable by a bitstring of a given length but not in the set of ordinarily valid values encoded by the bitstring; to encode n values i need ⌈log₂n⌉ bits, implying 2^n^-(1+n) extra values.

say i'll invest some percent of my cash into a given stock. that's a real [number] value. however, though i may invest 50% in it, or 33%, or 25%, or maybe even 10%, i don't think that i care about investments less than 10%, and nor do i care about my investment amount being in increments any finer than 10%. thus my investment amount is an integer n ∈ [-10,10]. that's 10 values plus a bit for sign i.e. 19 values (since 0 & -0 are equal); i need 5 bits to encode it. 5 bits gives 32 values. since i'm using only 19, i can assign special meaning to some 32-19=13 values. can i combine m & n into o such that i can break o into m & n i.e. can i losslessly compress m & n into a single value o? yes, but i need an interesting transform. `with t(a) as (select * from generate_series(0,32)) select a/19,a%19 from t` produces:

┌──────┬──────┐
│ a/19 │ a%19 │
├──────┼──────┤
│ 0    │ 0    │
│ 0    │ 1    │
│ 0    │ 2    │
│ ⋮    │ ⋮    │
│ 0    │ 18   │
│ 1    │ 0    │
│ 1    │ 1    │
│ 1    │ 2    │
│ ⋮    │ ⋮    │
│ 1    │ 13   │
└──────┴──────┘

one column has two unique values, and the other has 19 unique ones. the combination of these two data describes all 32 values. however, i must keep these data separate in order to do that. this means using a bit for the first column, and ⌈log₂18⌉=5 bits for the second. that means a total of 6 bits to encode two values n∈[0,10] and m∈[0,13]. add an extra sign bit for n, and our total is 7 bits. not bad; that's 2 bits a better compression than storing the numbers separately, which would be ⌈log₂19⌉+⌈log₂13⌉=5+4=9 bits. through the magic of modular arithmetic, we made two bits disappear!

there's probably at least off-by-one error in this example, but whatever. the idea is valid regardless.

notes:

* this example would have been much easier and more boring if we'd rounded down 10 values to 7, which is neatly described by a 3-bit substring. all of the bytes' possible values would be reserved for that one variable, so we'd need to use other, independent bits for other variables. in other words, we wouldn't be overloading bits.
* when using a sign bit, you can decide whether -0=0 or not; you may choose for 0 to be 0, but interpret -0 as a flag e.g. if 0 corresponds to closing a position at market price, then -0 may connote closing by a market-on-close order.

=== bit twiddler's mindset

often bit twiddling, like assembly, is considered difficult to manage; this simply means that a good notation hasn't been chosen. bitstrings or hexstrings are not amenable to humans! (solution: blinkenlights. see below.) it may be difficult or arduous to identify compression schemes then apply them. sure, but doing either by hand is silly; automate it. the only part to do manually is the part that actually requires the programmer! namely, that task is identifying relevant information; given any naïve idea/concept/datum, just identify the considerable attributes and the relevant sets of which they're members; mapping any domain to {0,1}ⁿ (isomorphic with the more general form, dⁿ where d is a digit of a given radix) is easy. after that, allow the computer to use algebraic rules (see below) to auto-compress and arrange your data conformant to the program-defining predicates (the program _spec_) that you provide.

the bit twiddle model forces programmers or designers to consider their data's properties, such as any datum's properties' e.g. mutual information or any of a datum's attribute's mathematical properties e.g. symmetry, closure, or associativity. this is very good; one must consider why they're using some assumedly useful data, or interpretations thereof, and the nature of the data [type]: how it behaves / can be manipulated, and how it can be interpreted, and, surprisingly importantly, the amount of redundant information of any interpretation.

.bits & decimals

tl;dr: floating point considered harmful unless you're using division an arbitrary number of times on values on (0,1) or need ±∞.

floating point is hardly necessary; use fixed point instead. arbitrary precision is best handled by perfect precision e.g. rationals instead of floats; rationals are perfect precision whereas floats are arbitrary but often incapable of exact representation. furthermore one must consider 1. what degree of precision is useful and 2. what degree of precision is meaningful viz sigfigs.

consider the polynomial 3.452069245x³ - 6.25678x²: how many digits are useful? would 3.452x³ - 6.257x² produce significantly different values? if not, then we need to encode (3.452,3,6.257,2). the exponents are naturally expressed by indices (see polynomial representation of numbers in §_bits algebra_) which leaves the decimals. if we assume that 3 decimals is sufficient, then we can have 1000 decimal values expressible by 10 bits; on a 64-bit system, that leavs 54 bits to express the non-decimal, so the max value is ≈18 quadrillion. 4 decimal digits requires 14 bits, so the max then is ≈1 quadrillion. finally, the larger the whole part, the less significant the decimal; i can't imagine a context in which 10,645,245,627.2345 is significantly different from 10,645,245,627.2346. therefore you should consider bits to represent the number of sigfigs! indeed, the meaning of the decimal operator directly corresponds to the fact that there's an infinite number of values on [0,1] and [1,∞)! this implies that, without division, a single unit cannot express all values on [0,∞). for places where that property does not apply, e.g. `$120.67`, we can simply change the unit from dollars to cents, or tenths of a cent, etc; this trades the decimal place for leading zeroes, e.g. `$120.67` = `1206700` when the unit is one-hundredth of a cent. use of integers acknowledes that the choice of unit is arbitrary rather than inherently meaningful. all this said, even 32 bits should more than suffice for a polynomial; who needs a polynomial of degree greater than 5? nobody, that's who. rather than using floats for all purposes, the programmer specifying the number of decimal bits explicitly tells the expected order of magnitude for the value, which can suggest the meaning/nature of the program where that value is used.

anyway, back to the polynomial: the most needed to express an 8^th^-degree (3 bits) polynomial with maximum coefficient of 32,768 (15 bits) at 4-digit (10 bits) precision, we need 8×(3+15+10) = 8×28 bits. rather than consider that as 204 bits, it's useful to say that 28 is less than but approximately 32 bits—a halfword on common modern systems, so we need 2 words or 1 dword to express an *eigth degree* polynomial—only 25% the size of `float[8]`, and doesn't use the heap!

for `floor`, `and` with a mask that has 1 for non-decimal indices and 0 for decimal indices. we can express this mask simply as "not decimal." no iteration nor type conversion. one cycle.

by this expression, polynomials naturally support addition and subtraction. for multiplication or division, replace the polynomial representation by its numeric output value. that requires a couple more cycles, but still is far more efficient than anything not done with bit twiddling. you'd need to define separate addition & subtraction operations for `float[8]`—not so, here!

what about marshalling between languages? no need to convert array types or throw-around pointers to allocated memory! just pass some few ints—trivially easy in any marshalling system.

lastly, decimals occur only when dealing with continuous things. most non-scientific computing is discrete. besides, for scientific computing you'll probably use a gpu which handles floats extremely well.

decimals are also a useful grouping mechanism: we can select unique elements from a group of uids {1, 2, 3.1, 3.2, 4.1, 4.2} by using equality, or we can select groups whose elements have a common floor: {1, 2, {3.1, 3.2}, {4.1, 4.2}}. this is achieved by using a mix of integers and floats, or could be done using all-floats. remember, though: floats' precision can be relied on only when values are static! it's fine to use uids as long as they are never mutated; floating point mutation can break equality. for example, 1.1 + 1.0 may equal 2.1 or it may not; never assume that it will! you may keep it simple by encoding as fixed-point decimals or some other scheme partitionable into two discrete integers. generally this scheme is a tree structure: {3.1.0, 3.1.1, 3.2, 4} corresponds to sexp ((3 (1 (0) (1)) (2)) (4)). the sexp encoding is more compressed.

==== relation between efficiency and simplicity

the real polynomial example shows us that we get total elegance: efficiency *and* simplicity, naturally together. this is common, though it often requires a bit of tact to identify elegant encoding schemes.

bits are a data structure that lives entirely on 1+ register(s). they can be traversed and mutated incrementally, and thus support some common or uncommon algorithms.

=== intuitive programming with an improvement on blinkenlights

it'd be good to have, rather than programs as text, programs as graphics. the limitation of text is that the bits of the codepoint corresponding to each glyph is not represented in the glyph itself, excepting ascii majiscule/miniscule case, denoted by the 6th bit. contrastingly, an arbitrary graphical display of code can use any properties that it wants: geometric (2d or 3d) orientation (rotation, position, reflection, skew, size, or any other affine properties that i missed), color (each of h,s,v), size, shape (e.g. polyhedra), line thickness, &c. this is basically a symmetric version of reading blinkenlights, where every independent bit of information is displayed independently e.g. changing color does not change number of degree of a regular polygon, which contrasts with toggling _any_ bit of a codepoint resulting in a completely unrelated glyph! with a small & regular set of primitives (namely arithmetic and set & seq ops), this should make subconscious/intuition-based debugging quite easy. btw, this kind of programming should be done because it leverages the particular power of the human brain, much more efficient, liberating, and creative than trying to reason by constraint. let the computer deal with constraint and the human with play & investigation, to each their particular strengths.

i'm inspired by encrypted "garbage" like `ehJH~=SxY}^!昹9},u@?յaO}?>~#`, which looks like j for all i know, and i think about how powerful that terseness is. but by using codepoint-glyphs (ad-hoc assignment of bits to glyphs) instead of glyphs composed of in/dependent, a/symmetric information relations (symmetric relation of information to glyphs), we can encode _far_ more information in each glyph, and use "custom" glyphs which are actually just natural consequences of their latent information.

the basic idea here is that graphics are superior to text because they have more dimensions and fewer constraints. they naturally support graphics that freely represent arbitrary information, rather than unidirectional sequences and limited-size alphabets whose characters don't compose systematically.

this technique is good generally for displaying any information. for programming, this includes both reading & writing code, and debugging "dead" or "living" programs—those that execute a sequence then halt, or those that stay alive until killed, and which you can inspect & modify as it runs. for debugging, think of that a light dimming to blackness is easier to spot in a mess of graphics changing over time than a number going to zero among a mess of numbers changing over time. for encoding programs, we can display any glyph reflected over the vertical axis rather than making a specific codepoint & glyph, and modifying a font file, and installing the font file, &c, just to connote the idea of an operator with flipped arguments. we can add a dot above and/or it or something if it supports both negative & positive values—or not, or something else; it's the coder's decision; implementing that display is just a couple graphics api calls away! your glyphs can directly represent properties about them, and glyphs be computed dynamically of their properties!

personally i want to manipulate code with my hands, with the code being abstract geometric objects, or sounds, or whatever; i want something more natural and free than keeping my hands affixed to a keyboard, using a modal text editor! sequences of key presses, sequenecs of bytes. sequences are for turing machines. sequencing text is like programming by a turing or stack machine. though better than applicative style, using sets (sql, prolog) is even better, and our interface & representation should reflect that! in fact, screw looking at a screen. rather project a world of objects around me like a planetarium to walk about in and manipulate! trade keyboards & monitors for projectors and cameras. 10 years ago such designs were a bit expensive, but they're quite affordable now, what with our vr headsets, tracking gear, inexpensive projectors, computer vision, and cameras that can caputure most of 4π steradians. i want to use my two hands & arms simultaneously to manipulate data. rather than map keys to functions, map actions to functions, and let those functions be better than manipulating text; let them manipulate data. manipulating data requires fewer primitives than manipulating text, because text a more verbose represention of information than geometries & sounds. currently we're mapping 10 fingers to 104 keys. why not include more parts of the body? why have 104 keys? let's not pretend that having all latin characters is anything special. it doesn't help chinese, japanese, etc. it doesn't help entering math symbols. and there's no need for each letter to have its own key. in fact, if we're using glyphs naturally given by the information that they represent, then the idea of one key per glyph is obviously stupid. the ios kana japanese input _method already_ demonstrates more efficient and beautiful input methods. function keys? come on, we all use accelerators/modifiers instead anyway. we hardly need any keys. i can rotate my arms, hands, move them around and such, assume many body configurations. those mean more options for representing information, such as data manipulations. cameras are better than hardware because, to add/modify functionality, only new graphical patterns need to be programmed, rather than creating or modding hardware. finally, the argument that we can enter keys quickly is no good, because a sensibly efficient encoding of information would need fewer manipulations. mashing keys all the time is like using feet to drive a car rather than having gas and brake pedals. faster feet or longer legs are not what we need. it's time to break away not just from the old terminal/typewriter designs, but from text altogether, seeing text input as a special case of general input. obviously software character input can be very good, and indeed far superior to hardware text input.

perhaps ironically, these designs' importantce is proportional to the amount of time spent coding. i'm dissatisfied with my desire for coding to compete with my needs & desires of being an animal. coding is too wonderful an exploration of art & truth than to be sullied by being aggressive toward creatures that need to move and play.

of course, i haven't identified the proposed mappings from body configurations to data manipulations, but i have faith that the body supports far more configurations, and can manipulate parts of the body independently, corresponding to many values for independent data; this allows things like e.g. using the left arm to set the case of a character and the right arm to choose the character. this is a silly example because the arms support far more configurations than any that has the information content of a single bit, but the example generalizes nicely.

=== you may as well use bits

an example compound encoding scheme that does not use bits is {pairity,sign,abs(x)>=1000,v^*^}. actually, pairity is a predicate on the lsb; `x&1` discards all but x's lsb, which is 0 for even, 1 for odd. the same is true of sign (in 2's complement) too, except thet sign is determined by the msb. ^*^_v_ is x's value not including 1000; if x>1000 then we subtract 1000 from it, since the 1000 isn't really x's value, but instead connotes other information. this implies that x's value is in [0,1000). the `if(x<1000,x,x-1000)`. rather than 1000 (10^3), though, we could use x>=2^n, which is easily toggled by toggling the nth bit. this is not a general encoding for subsets, though; toggling only applies to bits e.g. you can't _toggle_ the nth digit of a base-5 digit string; you can choose one of 5 values for each digit. anyway, choosing a given digit of any any-radix number is overconstrained; we want to easily express subsets by arbitrary numbers—again, like x>1 & x>4. btw, the use is that when `1` & `4` are arbitrarily chosen to represent given properties and one property implies the other, then that corresponds to that x>4 implies x>1.

==== branching by filters

TODO: incorporate about how e.g. abs is a piecewise fn `if x < 0 then -x else x`, also interperable as a filter (filters-out the sign). min & max are low- & high-pass filters, too. filters/piecewise fns are alternative(s) to control flow; they're both asymmetry primitives. also the type trinity is numbers, strings, and sets because they represent {mass, countable: {ordered, unordered}}. numbers are mass in that e.g. 1 + 2 yields 3, but given 3 we cannot know which addends produced it. the big point when designing an encoding scheme is which functions use which information; for example, a function defined of positive numbers is equal to a function of the absolute value of positive numbers; this allows us to adjoin the sign information without affecting the value of the function. we generally want our scheme to meaningfully affect some operations but not affect others. another example is that we may let character case encode e.g. genders per names, without affecting a case-insensitive sort. we may use bitwise operations as filters (corresponding to their electronic gate counterparts) to implement logic or control flow. another example of predicate satisfaction is whether a datum is within a given range; you can use basic comparison operators for subsets; x>4 is a subset of x>1.

min, max, & abs are all piecewise: abs(x)=if(x<0,-x,x); min(x,y)=if(x<y,x,y); max(x,y)=if(y<x,x,y). min0:=min(x,0)=if(x<0,x,0). max0:=max(x,0)=if(x>0,x,0). -x=0-x. min0/max0 is a coproduct of the identity and constant functions; it passes-through or discards its value. we don't need both min & max, nor > & <. in fact, we need only (min,max,-,+,0), notably lacking ×; × is useful with `+` when predicates return 0 or 1, but i want to code more like lisp, using values if truthy, alternatives if falsy, and short-circuiting if falsy and no alternatives. `abs` is not a primitive: abs(x)=max(x,-x). -abs(x)=min(x,-x). `/` is the unit-change operator, and `%` is expressed by `/` & `-`: x%y = x-x/y, or in factor, `dupd / -`. anyway, `min`, containing the information of `id`, `const`, and `<` or `<=`, seems a good canditate, alongside `+` to choose alternatives.

using this algebra, let's re-express `if(x<n,x,x-n)` by (min,max,-,+,0). if x<n then min(n,x)=x=v and max(0,x-n)=0. else min(n,x)=n and max(0,x-n)=v. x=min(n,x)+max(0,x-n).

[source,sql]
----
with t(x) as (values(1200),(40)) select min(1000,x),max(0,x-1000) from t;
┌─────────────┬───────────────┐
│ min(1000,x) │ max(0,x-1000) │
├─────────────┼───────────────┤
│ 1000        │ 200           │
│ 40          │ 0             │
└─────────────┴───────────────┘
----

...ok, so somewhat of the way there. i know that i didn't want to use predicates as logical values, but i can get to that by cheating here by using integer division: x>n = min(x/n,1) and 1-p for ¬p, though i could have used xor with 1 instead (i think):

[source,sql]
----
with t(x) as (values(1200),(40)) select (1-min(x/1000,1))*min(1000,x) + min(x/1000,1)*max(0,x-1000) from t;
┌─────────────────────────────────────────────────────────────┐
│ (1-min(x/1000,1))*min(1000,x) + min(x/1000,1)*max(0,x-1000) │
├─────────────────────────────────────────────────────────────┤
│ 200                                                         │
│ 40                                                          │
└─────────────────────────────────────────────────────────────┘
----

quite frankly, i don't know what i'm doing, but i feel that these things should be researched, and ultimately an algebra system that refines predicates to numeric properties and gates on them should be designed.

we can use min & max to make something a predicate, too: `x>y` is expressed as `min(1,max(x-y,0))`, derived from the observation: x<y <=> x-y<0 <=> max0(x-y)=0. we can then use that with the standard branchless form: `if(x>y,a,b)`=`(x>y)*a+(1-(x>y))*b`=`(min(1,max(x-y,0)))*a+(1-(min(1,max(x-y,0))))*b`.

with min & max, we can toggle whether a value will be discarded, by negating it. e.g. assuming x>0, max0(x)=x and max0(-x)=0. then max0(x)+max0(y) will give either x, y, or x+y. similarly min0(x) will choose 0 or -x depending on whether x<0. we can negate the output of min0 or max0, or negate their inputs.

if(x>y,a,b)=min(1,max(x-y,0))*b+a.

[TODO]
* consider min & max wrt lattices, and how prolog's predicate unification uses a lattice. obviously using min & max on reals with 0 & 1 is stupidly limited compared to using them against other reals. how can we usefully generalize the boolean ring?
* consider `sign` gives 3-valued boolean logic.

''''

=== entropy & encoding

TODO: read about encodings, e.g. huffman, hugh-tucker, and wavelet trees; and hilbert curves.

==== _succinct_ data structures

∃ papers about them, but not how to use them (according to link:https://www.youtube.com/watch?v=sdHXaYCX3RE[kmett in 2015].)

* you need H = log(n choose k) + 1 bits to encode n bits where k are set.
* rank(α s i) is #{1 | α == s[k], k ≤ i}. rank(0) shares all info with rank(1). rank can be computed in O(1) by chunking s into chunks each of size log(n).
* select gives the position of the ith α in s. it can be done in O(1) by recursing upward through a huffman tree.
* rank & select share information.
  ** rank(α,select(α,i)) = i (rank is a left-inverse of select)
  ** select(α,rank(α,i)) ≤ i (select & rank form a galois connection)

the rank of a huffman tree (which is isomorphic with a bits) can be found by recursing on rank.

rank & select work on alphabets of any size, and on all prefix-free codes, especially order-preserving compression schemes.

an important principle that this technique demonstrates: we only need to encode data. we do not need to have separate "cells" for each "separate datum." such conceptualization is naïve and inefficient. do not constrain yourself to keeping data separate; only care that you can _effectively_ manipulate the data as desired (namely CRUD), which may mean compressing, mixing, &c the data together, then extracting or reconstructing the actual logical data. this sees data as-manipulated and as-stored.

the _order_ of an encoding is the number of bits that each datum encodes, assuming that enough data is available. a positive order means autoregression.

==== miscellaneous little tips

* search by fewest possibilities first, e.g. lookup dates as month day year, because there are at most 12 months, 31 days, and an unbounded number of years. looking-up by 12 then 31 then n enforces a lookup complexity upper bound. 

=== bits algebra

* bitstrings can be split. e.g. a 32-bitstring can be 4 8-bitstrings i.e. a 4-vector of octal values.
* index is exponent. radix is always 2
* a length n bit vector can encode 2ⁿ values
* numbers are expressed as polynomials: Σdᵢrⁱ where d is a digit and r is a radix
* like how the smirnov transform in statistics transforms into U[0,1], a set of values can be compressed into a set of bitstrings and a back-transform.
* for booleans/bits, complement = opposite; both are represented uniformly by `not`.
* an unordered set of bits is expressible entirely by its count of set bits.

==== symmetries

efficiency is obtained by exploiting symmetry and/or coincidence.

===== lattices

TODO: unify < & min, or explain why that's impossible.
TODO: consider how x can be split into information |x| & sgn(x)
TODO: consider complex numbers.

NB. sgn(x-y)min(z,|x-y|) (or something like it) is a terse form of iff(x>y,min(z,x-y),max(-z,x-y)).

a common problem is choosing of `(<,max,high)` or `(>,min,low)`. this is simpler encoded as `(<,max,high)` under negation or not; min(a,b) = -(max(-a,-b)). thus the `<` & `>` lattices are opposites. one's min is the other's max.

.retained info & arity
[options="header"]
|===================================
| fn      | abs | sgn | arity | #cod
| abs     | yes | no  | 1     | ∞
| cmp     | no  | yes | 2     | 3
| sgn     | no  | yes | 1     | 3
| <,>,=   | no  | no  | 2     | 2
| min/max | yes | yes | 2     | ∞
|===================================

* `sgn` is unary `cmp`
* `min`/`max` retain(s) the most information

to exploit symmetry, use only `<`, but not in its literal sense; its meaning must be relative to the usual lattice or its opposite. in program semantics this means that the reïfication of `<` is context dependent i.e. it'd be in a type class rather than selected from an `if` clause. if `if p then a < b else a > b` (or anything dealing with `min` or `max`) appears multiple places, then `opposite {a < b}`, where `opposite` specifies `<` & `min` to use the opposite lattice and is scoped, is easier to refactor and is less prone to code entering mistakes. as for selecting `low` or `high` (assuming that we need to track both), use only a single context-dependent identifier called `extreme`. such a context can be specified by using dynamically bound variables, e.g., in racket:

[source,scm]
----
#lang racket/base

(require (rename-in racket/base [< LT] [min MIN] [> GT] [max MAX]))

;; these zeroes are dummy initial values. low & high will be set
;; throughout the program.
(define low  (make-parameter 0))
(define high (make-parameter 0))

(define pos (vector LT MIN low))
(define neg (vector GT MAX high))

(define (set-lat x) (if (> x 0) pos neg))

(define lat (make-parameter pos))

;; unfortunately in racket i can't define things in terms
;; of memory addresses; i would instead define them as macros,
;; but they're defined in terms of `lat`, and sharing identifiers
;; between macros and non-macros is a pain. thus i define them as
;; functions so that they'll be evaluated upon each use [invocation].
(define (<)   (vector-ref (lat) 0))
(define (min) (vector-ref (lat) 1))
(define (ext) (vector-ref (lat) 2))

(low 5)
(high 20)

(printf "~a < ~a: ~a~n" 40 ((ext)) ((<) 40 ((ext))))
(set-lat #f)
(printf "~a < ~a: ~a~n" 30 ((ext)) ((<) 30 ((ext))))
----

outputs

----
40 < 5: #f
30 < 20: #t
----

this method branches often, which is inefficient. ideally we'd multiply everything by a given variable whose value is either -1 or 1. in most languages, though, this would look absolutely horrible, since that multiplication would need to be explicitly specified in syntax in many places. ideally we'd store `pos := (<,min,ext)` and `neg := (>,max,ext)` in arrays with constant memory offsets so that we can simply set a variable `lat` to either `pos` or `neg`, and use macros `<`, `max`, & `ext` to refer to `lat[0]`, `lat[1]`, & `lat[2]`.

to define this code well, we need a mechanism to select whether eval is done at definition vs use. see _best paradigms_ section on evaluation for further discussion. ideally we'd use clever bit twiddling to avoid all this.

consider whether `high` & `low` are positive fixed-point or not, and which encodings they support. recall that -x = ~x+1.

.identities

* abs(a) = max(a,-a) = -min(-a,a).
* a <= b = a < b or not -a < -b
* min(a,b) = a < b ? a : b. min is the result of folding <.

everything is defined in terms of `<`, booleans, and `-`. we know that everything can be defined by `nand`, but can we use that simplicity to enable elegant code?

=== encodings

* a binary coproduct of positive integers can be represented by a single signed integer whose sign determines the interpretation of the absolute value i.e. n is shorthand for +n which contrasts -n which is interpreted as the cons pair (sign,n) where sign∈{+,-}
* if two numbers are always sufficiently small and have fixed point precision, then we can fit them into a common integer, one taking the high bits, the other taking the low bits.

=== integer algebra

TODO

==== symmetries

TODO

=== exploiting bits' multiple interpretation

note the _in bitstrings_; we can encode bitstrs such that certain substrs have useful boolean/integer interpretations. 

shift for expt/log, _ for multiply/divide

TODO: explore modular arithmetic, number theory, combinatronics

the operation (when (p x) (inc x)) can be expressed x=x+p x when p returns 0 or 1.

in double dash, there's a counter for which checkpoints you've hit. just because you hit checkpoints #1 & #3 does not imply that you've hit #2. thus whether you've hit each checkpoint is an independent boolean; thus a 32-bit word can be used to store this value (assuming that a course be broken into 32 pieces, which is pretty damn reasonable.) thus to check whether someone actually _has_ played the course properly (w/o cheating), just test the word against an n-bits full of 1's.

=== what bits can't/don't accomodate

* a type that requires more than a word to encode a single datum of that type, e.g. arbitrary ad-hoc sequences e.g. arbitrary strings
* branching; branchless programming does not concern bit twiddling, though relatedly bit twiddling can often well encode combinations of conditions

one may assume that categorical values must be represented by _arbitrary_ numbers/bitstrings, but this is not true: mnemonic strings can be expressed by words: a word on a 64-bit system can represent a string of 12 ci latin characters, and 6 chars by 32 bits, since ⌈log₂26⌉ = 5, and ⌊64/5⌋ = 12 & ⌊32/5⌋ = 6. thus `int[n]` is a more efficient version of `char[12][n]`.

=== examples

==== most frequent item in a set

say that we've a string of alphabet ACGT. that's 4 characters. if we want to know the most frequent item, then the order is irrelevant (because `max` is commutative); we treat the string as a set. of course the solution is to count the number of occurences then return the max:

.table version
[source,lua]
----
local t = {A=0,C=0,G=0,T=0}
for i=1,#s do local c = string.sub(s,i,i) t[c]=t[c]+1 end
local m = 0 local mc;
for c,n in pairs(t) do if n>m then m=n mc=c end end
return mc
----

this works, but is written in terms of concepts rather than in terms of information content. it's also done with tables instead of strings. it does not exploit any symmetries nor natural implications. it has a traversal of length `#s` and one of length of the alphabet (4), and that latter loop branches.

of course, our good version should use only basic arithmetic and relation. we see that we're converting subsets to counts.

* counting uses incrementing (+1)
* we shouldn't sort since we aren't concerned with order.
* we must preserve the relation between letter and count; this suggests that we store characters in a string, and counts in a string; however, we really need only to store counts in a string; the counts will be ordered in alphabetical order.
* the counts can be known only after traversing `s`

.bit/string version
[source,lua]
----
-- rather than return max element, return index of max element; this implicitly tells the letter. indices should _always_ be used rather than values!
----

the point of this method is that it's simple, efficient, and forces the programmer to relate the facts of their data to their conceptions of it.

one very important aspect of using only information in its plainest representation (string) is how solutions generalize to other..._structures_? well, not _data structures_, but abstract structures defined only by facts of the data, of which there are only 4 varieties:

. relation of elements within one string or among many strings
. domains
. implications
. invariants

=== recepies

set nth bit to 1, 0, or complement:

. (1 << n) | x
. ~(1 << n) & x
. (1 << n) ^ x

* trailing 0's to 1's: (x - 1) | x
* -x: ~x + 1
* lowest set bit: x & -x ; (number->string (let ([p 52]) (bitwise-and p (- p))) 2) prints "100". 52 is 110100b.
* masked copy: given bitsets A, B and a mask M, copy bits from B into A where M is set (where M is unset A we have A's value at that bit): (B & M) | (A & ~M)
* swap bits an indices i & j of x: y = ((x >> i) ^ (x >> j)) & 1; x ^= y << a; x ^= y << b
* # of set bits (POPCNT on x86): because x & (x - 1) unsets the lowest set bit, our solution is: [TODO: this solution is obviously wrong] for (c = 0; x != 0; c++) x = x & (x - 1)
* # of set substrings: (+ (& x 1) (/ (popcnt (^ x (>> x 1))) 2))
* next highest number with the same number of set bits: let t = x | (x - 1); nt = ~t in (t + 1) | (((nt & -nt) - 1) >> (bsf(x) + 1)), i.e. let t = trailing(x); nt = ~t in (t + 1) | (lsb(t) - 1)
* toggle case of ascii character (or set case by anding with 1 or 0): c^32
* not bit twiddling, but x∈[a,b] is well expressed by a stack grammar: `x { [ >=a ] [ <=b ] } bi and`, or even better syntax in apl: `(≥a∧≤b)x`.

==== square-and-multiply

TODO
