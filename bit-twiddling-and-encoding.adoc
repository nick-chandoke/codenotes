== bit twiddling, and encoding

using an enum/number enforces mutual exclusivity. consider `(or a b)`; the first non-falsy is chosen; however, `a ∧ b` may be true. if you want to help ensure that `a xor b` is true, then have a single number called. why integers? most types work; we need for all elements of the type to be unique. integers are a good choice because they obey that property, and are machine words, and support bit twiddling. the point of this pattern is doing `case x v1: ...; v2 ...; ...` instead of `cond`, since `x` must have exactly one value, whereas `cond` statements, while more general (i.e. supporting general predicates instead of mere equality), must be carefully ordered, and may be not mutually exclusive.

why?

. fun like number theory, which it practically _is_, but in binary
. keeps programmers familiar with information theory, which all programmers should know intimately
. efficient:
  .. bitwise ops are single-cycle
  .. elementary arithmetic uses few cycles
  .. word is the physical unit of memory
  .. bitwise (and simd) ops parallel: `a&b` = `(map and a b)`
  .. opcodes are inline; no jumping
. flexible: boolean/integer duality
. all systems support this variety of data, including direct support by ISAs

.conventions, terms, and other notes

* 2's complement is assumed
* _word_ always means machine word, not natural language word
* for bits, 1 may be called _set_, and 0 _unset_
* _bits_ is short for _bitstring_ i.e. a bit vector. because any bits can be split into many, _bits_ means a bitstring or a string of bitstrings, recursively.
  ** _bits_ is plurality-agnostic

=== bit twiddler's mindset

often bit twiddling, like assembly, is considered difficult to manage; this simply means that a good notation hasn't been chosen. it may be difficult or arduous to identify compression schemes then apply them. sure, but doing either by hand is silly; automate it. the only part to do manually is the part that actually requires the programmer! namely, that task is identifying relevant information; given any naïve idea/concept/datum, just identify the considerable attributes and the relevant sets of which they're members; mapping any domain to {0,1}ⁿ (isomorphic with the more general form, dⁿ where d is a digit of a given radix) is easy. after that, allow the computer to use algebraic rules (see below) to auto-compress and arrange your data conformant to the program-defining predicates (the program _spec_) that you provide.

the bit twiddle model forces programmers or designers to consider their data's properties, such as any datum's properties' e.g. mutual information or any of a datum's attribute's mathematical properties e.g. symmetry, closure, or associativity. this is very good; one must consider why they're using some assumedly useful data, or interpretations thereof, and the nature of the data [type]: how it behaves / can be manipulated, and how it can be interpreted, and, surprisingly importantly, the amount of redundant information of any interpretation.

.bits & decimals

tl;dr: floating point considered harmful unless you're using division an arbitrary number of times on values on (0,1) or need ±∞.

floating point is hardly necessary; use fixed point instead. arbitrary precision is best handled by perfect precision e.g. rationals instead of floats; rationals are perfect precision whereas floats are arbitrary but often incapable of exact representation. furthermore one must consider 1. what degree of precision is useful and 2. what degree of precision is meaningful viz sigfigs.

consider the polynomial 3.452069245x³ - 6.25678x²: how many digits are useful? would 3.452x³ - 6.257x² produce significantly different values? if not, then we need to encode (3.452,3,6.257,2). the exponents are naturally expressed by indices (see polynomial representation of numbers in §_bits algebra_) which leaves the decimals. if we assume that 3 decimals is sufficient, then we can have 1000 decimal values expressible by 10 bits; on a 64-bit system, that leavs 54 bits to express the non-decimal, so the max value is ≈18 quadrillion. 4 decimal digits requires 14 bits, so the max then is ≈1 quadrillion. finally, the larger the whole part, the less significant the decimal; i can't imagine a context in which 10,645,245,627.2345 is significantly different from 10,645,245,627.2346. therefore you should consider bits to represent the number of sigfigs! indeed, the meaning of the decimal operator directly corresponds to the fact that there's an infinite number of values on [0,1] and [1,∞)! this implies that, without division, a single unit cannot express all values on [0,∞). for places where that property does not apply, e.g. `$120.67`, we can simply change the unit from dollars to cents, or tenths of a cent, etc; this trades the decimal place for leading zeroes, e.g. `$120.67` = `1206700` when the unit is one-hundredth of a cent. use of integers acknowledes that the choice of unit is arbitrary rather than inherently meaningful. all this said, even 32 bits should more than suffice for a polynomial; who needs a polynomial of degree greater than 5? nobody, that's who. rather than using floats for all purposes, the programmer specifying the number of decimal bits explicitly tells the expected order of magnitude for the value, which can suggest the meaning/nature of the program where that value is used.

anyway, back to the polynomial: the most needed to express an 8^th^-degree (3 bits) polynomial with maximum coefficient of 32,768 (15 bits) at 4-digit (10 bits) precision, we need 8×(3+15+10) = 8×28 bits. rather than consider that as 204 bits, it's useful to say that 28 is less than but approximately 32 bits—a halfword on common modern systems, so we need 2 words or 1 dword to express an *eigth degree* polynomial—only 25% the size of `float[8]`, and doesn't use the heap!

for `floor`, `and` with a mask that has 1 for non-decimal indices and 0 for decimal indices. we can express this mask simply as "not decimal." no iteration nor type conversion. one cycle.

by this expression, polynomials naturally support addition and subtraction. for multiplication or division, replace the polynomial representation by its numeric output value. that requires a couple more cycles, but still is far more efficient than anything not done with bit twiddling. you'd need to define separate addition & subtraction operations for `float[8]`—not so, here!

what about marshalling between languages? no need to convert array types or throw-around pointers to allocated memory! just pass some few ints—trivially easy in any marshalling system.

lastly, decimals occur only when dealing with continuous things. most non-scientific computing is discrete. besides, for scientific computing you'll probably use a gpu which handles floats extremely well.

decimals are also a useful grouping mechanism: we can select unique elements from a group of uids {1, 2, 3.1, 3.2, 4.1, 4.2} by using equality, or we can select groups whose elements have a common floor: {1, 2, {3.1, 3.2}, {4.1, 4.2}}. this is achieved by using a mix of integers and floats, or could be done using all-floats. remember, though: floats' precision can be relied on only when values are static! it's fine to use uids as long as they are never mutated; floating point mutation can break equality. for example, 1.1 + 1.0 may equal 2.1 or it may not; never assume that it will! you may keep it simple by encoding as fixed-point decimals or some other scheme partitionable into two discrete integers. generally this scheme is a tree structure: {3.1.0, 3.1.1, 3.2, 4} corresponds to sexp ((3 (1 (0) (1)) (2)) (4)). the sexp encoding is more compressed.

==== relation between efficiency and simplicity

the real polynomial example shows us that we get total elegance: efficiency *and* simplicity, naturally together. this is common, though it often requires a bit of tact to identify elegant encoding schemes.

bits are a data structure that lives entirely on 1+ register(s). they can be traversed and mutated incrementally, and thus support some common or uncommon algorithms.

=== intuitive programming with an improvement on blinkenlights

it'd be good to have, rather than programs as text, programs as graphics. the limitation of text is that the bits of the codepoint corresponding to each glyph is not represented in the glyph itself, excepting ascii majiscule/miniscule case, denoted by the 6th bit. contrastingly, an arbitrary graphical display of code can use any properties that it wants: geometric (2d or 3d) orientation (rotation, position, reflection, skew, size, or any other affine properties that i missed), color (each of h,s,v), size, shape (e.g. polyhedra), line thickness, &c. this is basically a symmetric version of reading blinkenlights, where every independent bit of information is displayed independently e.g. changing color does not change number of degree of a regular polygon, which contrasts with toggling _any_ bit of a codepoint resulting in a completely unrelated glyph! with a small & regular set of primitives (namely arithmetic and set & seq ops), this should make subconscious/intuition-based debugging quite easy. btw, this kind of programming should be done because it leverages the particular power of the human brain, much more efficient, liberating, and creative than trying to reason by constraint. let the computer deal with constraint and the human with play & investigation, to each their particular strengths.

i'm inspired by encrypted "garbage" like `ehJH~=SxY}^!昹9},u@?յaO}?>~#`, which looks like j for all i know, and i think about how powerful that terseness is. but by using codepoint-glyphs (ad-hoc assignment of bits to glyphs) instead of glyphs composed of in/dependent, a/symmetric information relations (symmetric relation of information to glyphs), we can encode _far_ more information in each glyph, and use "custom" glyphs which are actually just natural consequences of their latent information.

=== you may as well use bits

an example compound encoding scheme that does not use bits is {pairity,sign,abs(x)>=1000,v^*^}. actually, pairity is a predicate on the lsb; `x&1` discards all but x's lsb, which is 0 for even, 1 for odd. the same is true of sign (in 2's complement) too, except thet sign is determined by the msb. ^*^_v_ is x's value not including 1000; if x>1000 then we subtract 1000 from it, since the 1000 isn't really x's value, but instead connotes other information. this implies that x's value is in [0,1000). the `if(x<1000,x,x-1000)`. rather than 1000 (10^3), though, we could use x>=2^n, which is easily toggled by toggling the nth bit. this is not a general encoding for subsets, though; toggling only applies to bits e.g. you can't _toggle_ the nth digit of a base-5 digit string; you can choose one of 5 values for each digit. anyway, choosing a given digit of any any-radix number is overconstrained; we want to easily express subsets by arbitrary numbers—again, like x>1 & x>4. btw, the use is that when `1` & `4` are arbitrarily chosen to represent given properties and one property implies the other, then that corresponds to that x>4 implies x>1.

==== branching by filters

TODO: incorporate about how e.g. abs is a piecewise fn `if x < 0 then -x else x, also interperable as a filter (filters-out the sign). min & max are low- & high-pass filters, too. filters/piecewise fns are alternative(s) to control flow; they're both asymmetry primitives. also the type trinity is numbers, strings, and sets because they represent {mass, countable: {ordered, unordered}}. numbers are mass in that e.g. 1 + 2 yields 3, but given 3 we cannot know which addends produced it. the big point when designing an encoding scheme is which functions use which information; for example, a function defined of positive numbers is equal to a function of the absolute value of positive numbers; this allows us to adjoin the sign information without affecting the value of the function. we generally want our scheme to meaningfully affect some operations but not affect others. another example is that we may let character case encode e.g. genders per names, without affecting a case-insensitive sort. we may use bitwise operations as filters (corresponding to their electronic gate counterparts) to implement logic or control flow. another example of predicate satisfaction is whether a datum is within a given range; you can use basic comparison operators for subsets; x>4 is a subset of x>1.

min, max, & abs are all piecewise: abs(x)=if(x<0,-x,x); min(x,y)=if(x<y,x,y); max(x,y)=if(y<x,x,y). min0:=min(x,0)=if(x<0,x,0). max0:=max(x,0)=if(x>0,x,0). -x=0-x. min0/max0 is a coproduct of the identity and constant functions; it passes-through or discards its value. we don't need both min & max, nor > & <. in fact, we need only (min,max,-,+,0), notably lacking ×; × is useful with `+` when predicates return 0 or 1, but i want to code more like lisp, using values if truthy, alternatives if falsy, and short-circuiting if falsy and no alternatives. `abs` is not a primitive: abs(x)=max(x,-x). -abs(x)=min(x,-x). `/` is the unit-change operator, and `%` is expressed by `/` & `-`: x%y = x-x/y, or in factor, `dupd / -`. anyway, `min`, containing the information of `id`, `const`, and `<` or `<=`, seems a good canditate, alongside `+` to choose alternatives.

using this algebra, let's re-express `if(x<n,x,x-n)` by (min,max,-,+,0). if x<n then min(n,x)=x=v and max(0,x-n)=0. else min(n,x)=n and max(0,x-n)=v. x=min(n,x)+max(0,x-n).

[source,sql]
----
with t(x) as (values(1200),(40)) select min(1000,x),max(0,x-1000) from t;
┌─────────────┬───────────────┐
│ min(1000,x) │ max(0,x-1000) │
├─────────────┼───────────────┤
│ 1000        │ 200           │
│ 40          │ 0             │
└─────────────┴───────────────┘
----

...ok, so somewhat of the way there. i know that i didn't want to use predicates as logical values, but i can get to that by cheating here by using integer division: x>n = min(x/n,1) and 1-p for ¬p, though i could have used xor with 1 instead (i think):

[source,sql]
----
with t(x) as (values(1200),(40)) select (1-min(x/1000,1))*min(1000,x) + min(x/1000,1)*max(0,x-1000) from t;
┌─────────────────────────────────────────────────────────────┐
│ (1-min(x/1000,1))*min(1000,x) + min(x/1000,1)*max(0,x-1000) │
├─────────────────────────────────────────────────────────────┤
│ 200                                                         │
│ 40                                                          │
└─────────────────────────────────────────────────────────────┘
----

quite frankly, i don't know what i'm doing, but i feel that these things should be researched, and ultimately an algebra system that refines predicates to numeric properties and gates on them should be designed.

we can use min & max to make something a predicate, too: `x>y` is expressed as `min(1,max(x-y,0))`, derived from the observation: x<y <=> x-y<0 <=> max0(x-y)=0. we can then use that with the standard branchless form: `if(x>y,a,b)`=`(x>y)*a+(1-(x>y))*b`=`(min(1,max(x-y,0)))*a+(1-(min(1,max(x-y,0))))*b`.

with min & max, we can toggle whether a value will be discarded, by negating it. e.g. assuming x>0, max0(x)=x and max0(-x)=0. then max0(x)+max0(y) will give either x, y, or x+y. similarly min0(x) will choose 0 or -x depending on whether x<0. we can negate the output of min0 or max0, or negate their inputs.

if(x>y,a,b)=min(1,max(x-y,0))*b+a.

[TODO]
* consider min & max wrt lattices, and how prolog's predicate unification uses a lattice. obviously using min & max on reals with 0 & 1 is stupidly limited compared to using them against other reals. how can we usefully generalize the boolean ring?
* consider `sign` gives 3-valued boolean logic.

''''

=== entropy & encoding

TODO: read about encodings, e.g. huffman, hugh-tucker, and wavelet trees; and hilbert curves.

==== _succinct_ data structures

∃ papers about them, but not how to use them (according to link:https://www.youtube.com/watch?v=sdHXaYCX3RE[kmett in 2015].)

* you need H = log(n choose k) + 1 bits to encode n bits where k are set.
* rank(α s i) is #{1 | α == s[k], k ≤ i}. rank(0) shares all info with rank(1). rank can be computed in O(1) by chunking s into chunks each of size log(n).
* select gives the position of the ith α in s. it can be done in O(1) by recursing upward through a huffman tree.
* rank & select share information.
  ** rank(α,select(α,i)) = i (rank is a left-inverse of select)
  ** select(α,rank(α,i)) ≤ i (select & rank form a galois connection)

the rank of a huffman tree (which is isomorphic with a bits) can be found by recursing on rank.

rank & select work on alphabets of any size, and on all prefix-free codes, especially order-preserving compression schemes.

an important principle that this technique demonstrates: we only need to encode data. we do not need to have separate "cells" for each "separate datum." such conceptualization is naïve and inefficient. do not constrain yourself to keeping data separate; only care that you can _effectively_ manipulate the data as desired (namely CRUD), which may mean compressing, mixing, &c the data together, then extracting or reconstructing the actual logical data. this sees data as-manipulated and as-stored.

the _order_ of an encoding is the number of bits that each datum encodes, assuming that enough data is available. a positive order means autoregression.

==== miscellaneous little tips

* search by fewest possibilities first, e.g. lookup dates as month day year, because there are at most 12 months, 31 days, and an unbounded number of years. looking-up by 12 then 31 then n enforces a lookup complexity upper bound. 

=== bits algebra

* bitstrings can be split. e.g. a 32-bitstring can be 4 8-bitstrings i.e. a 4-vector of octal values.
* index is exponent. radix is always 2
* a length n bit vector can encode 2ⁿ values
* numbers are expressed as polynomials: Σdᵢrⁱ where d is a digit and r is a radix
* like how the smirnov transform in statistics transforms into U[0,1], a set of values can be compressed into a set of bitstrings and a back-transform.
* for booleans/bits, complement = opposite; both are represented uniformly by `not`.
* an unordered set of bits is expressible entirely by its count of set bits.

==== symmetries

efficiency is obtained by exploiting symmetry and/or coincidence.

===== lattices

TODO: unify < & min, or explain why that's impossible.
TODO: consider how x can be split into information |x| & sgn(x)
TODO: consider complex numbers.

NB. sgn(x-y)min(z,|x-y|) (or something like it) is a terse form of iff(x>y,min(z,x-y),max(-z,x-y)).

a common problem is choosing of `(<,max,high)` or `(>,min,low)`. this is simpler encoded as `(<,max,high)` under negation or not; min(a,b) = -(max(-a,-b)). thus the `<` & `>` lattices are opposites. one's min is the other's max.

.retained info & arity
[options="header"]
|===================================
| fn      | abs | sgn | arity | #cod
| abs     | yes | no  | 1     | ∞
| cmp     | no  | yes | 2     | 3
| sgn     | no  | yes | 1     | 3
| <,>,=   | no  | no  | 2     | 2
| min/max | yes | yes | 2     | ∞
|===================================

* `sgn` is unary `cmp`
* `min`/`max` retain(s) the most information

to exploit symmetry, use only `<`, but not in its literal sense; its meaning must be relative to the usual lattice or its opposite. in program semantics this means that the reïfication of `<` is context dependent i.e. it'd be in a type class rather than selected from an `if` clause. if `if p then a < b else a > b` (or anything dealing with `min` or `max`) appears multiple places, then `opposite {a < b}`, where `opposite` specifies `<` & `min` to use the opposite lattice and is scoped, is easier to refactor and is less prone to code entering mistakes. as for selecting `low` or `high` (assuming that we need to track both), use only a single context-dependent identifier called `extreme`. such a context can be specified by using dynamically bound variables, e.g., in racket:

[source,scm]
----
#lang racket/base

(require (rename-in racket/base [< LT] [min MIN] [> GT] [max MAX]))

;; these zeroes are dummy initial values. low & high will be set
;; throughout the program.
(define low  (make-parameter 0))
(define high (make-parameter 0))

(define pos (vector LT MIN low))
(define neg (vector GT MAX high))

(define (set-lat x) (if (> x 0) pos neg))

(define lat (make-parameter pos))

;; unfortunately in racket i can't define things in terms
;; of memory addresses; i would instead define them as macros,
;; but they're defined in terms of `lat`, and sharing identifiers
;; between macros and non-macros is a pain. thus i define them as
;; functions so that they'll be evaluated upon each use [invocation].
(define (<)   (vector-ref (lat) 0))
(define (min) (vector-ref (lat) 1))
(define (ext) (vector-ref (lat) 2))

(low 5)
(high 20)

(printf "~a < ~a: ~a~n" 40 ((ext)) ((<) 40 ((ext))))
(set-lat #f)
(printf "~a < ~a: ~a~n" 30 ((ext)) ((<) 30 ((ext))))
----

outputs

----
40 < 5: #f
30 < 20: #t
----

this method branches often, which is inefficient. ideally we'd multiply everything by a given variable whose value is either -1 or 1. in most languages, though, this would look absolutely horrible, since that multiplication would need to be explicitly specified in syntax in many places. ideally we'd store `pos := (<,min,ext)` and `neg := (>,max,ext)` in arrays with constant memory offsets so that we can simply set a variable `lat` to either `pos` or `neg`, and use macros `<`, `max`, & `ext` to refer to `lat[0]`, `lat[1]`, & `lat[2]`.

to define this code well, we need a mechanism to select whether eval is done at definition vs use. see _best paradigms_ section on evaluation for further discussion. ideally we'd use clever bit twiddling to avoid all this.

consider whether `high` & `low` are positive fixed-point or not, and which encodings they support. recall that -x = ~x+1.

.identities

* abs(a) = max(a,-a) = -min(-a,a).
* a <= b = a < b or not -a < -b
* min(a,b) = a < b ? a : b. min is the result of folding <.

everything is defined in terms of `<`, booleans, and `-`. we know that everything can be defined by `nand`, but can we use that simplicity to enable elegant code?

=== encodings

* a binary coproduct of positive integers can be represented by a single signed integer whose sign determines the interpretation of the absolute value i.e. n is shorthand for +n which contrasts -n which is interpreted as the cons pair (sign,n) where sign∈{+,-}
* if two numbers are always sufficiently small and have fixed point precision, then we can fit them into a common integer, one taking the high bits, the other taking the low bits.

=== integer algebra

TODO

==== symmetries

TODO

=== exploiting bits' multiple interpretation

note the _in bitstrings_; we can encode bitstrs such that certain substrs have useful boolean/integer interpretations. 

shift for expt/log, _ for multiply/divide

TODO: explore modular arithmetic, number theory, combinatronics

the operation (when (p x) (inc x)) can be expressed x=x+p x when p returns 0 or 1.

in double dash, there's a counter for which checkpoints you've hit. just because you hit checkpoints #1 & #3 does not imply that you've hit #2. thus whether you've hit each checkpoint is an independent boolean; thus a 32-bit word can be used to store this value (assuming that a course be broken into 32 pieces, which is pretty damn reasonable.) thus to check whether someone actually _has_ played the course properly (w/o cheating), just test the word against an n-bits full of 1's.

=== what bits can't/don't accomodate

* a type that requires more than a word to encode a single datum of that type, e.g. arbitrary ad-hoc sequences e.g. arbitrary strings
* branching; branchless programming does not concern bit twiddling, though relatedly bit twiddling can often well encode combinations of conditions

one may assume that categorical values must be represented by _arbitrary_ numbers/bitstrings, but this is not true: mnemonic strings can be expressed by words: a word on a 64-bit system can represent a string of 12 ci latin characters, and 6 chars by 32 bits, since ⌈log₂26⌉ = 5, and ⌊64/5⌋ = 12 & ⌊32/5⌋ = 6. thus `int[n]` is a more efficient version of `char[12][n]`.

=== recepies

set nth bit to 1, 0, or complement:

. (1 << n) | x
. ~(1 << n) & x
. (1 << n) ^ x

* trailing 0's to 1's: (x - 1) | x
* -x: ~x + 1
* lowest set bit: x & -x ; (number->string (let ([p 52]) (bitwise-and p (- p))) 2) prints "100". 52 is 110100b.
* masked copy: given bitsets A, B and a mask M, copy bits from B into A where M is set (where M is unset A we have A's value at that bit): (B & M) | (A & ~M)
* swap bits an indices i & j of x: y = ((x >> i) ^ (x >> j)) & 1; x ^= y << a; x ^= y << b
* # of set bits (POPCNT on x86): because x & (x - 1) unsets the lowest set bit, our solution is: [TODO: this solution is obviously wrong] for (c = 0; x != 0; c++) x = x & (x - 1)
* # of set substrings: (+ (& x 1) (/ (popcnt (^ x (>> x 1))) 2))
* next highest number with the same number of set bits: let t = x | (x - 1); nt = ~t in (t + 1) | (((nt & -nt) - 1) >> (bsf(x) + 1)), i.e. let t = trailing(x); nt = ~t in (t + 1) | (lsb(t) - 1)
* toggle case of ascii character (or set case by anding with 1 or 0): c^32
* not bit twiddling, but x∈[a,b] is well expressed by a stack grammar: `x { [ >=a ] [ <=b ] } bi and`, or even better syntax in apl: `(≥a∧≤b)x`.

==== square-and-multiply

TODO
